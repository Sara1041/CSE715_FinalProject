{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sara1041/CSE715_FinalProject/blob/main/VAEProject_19101141.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "mount_drive"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the ZIP file\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_path = '/content/drive/MyDrive/MyDataset.zip'\n",
        "extract_to = '/content/extracted_data'\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to)\n",
        "\n",
        "print(f\"Extracted to: {extract_to}\")\n",
        "print(\"\\nDirectory structure:\")\n",
        "for root, dirs, files in os.walk(extract_to):\n",
        "    level = root.replace(extract_to, '').count(os.sep)\n",
        "    indent = ' ' * 2 * level\n",
        "    print(f\"{indent}{os.path.basename(root)}/\")\n",
        "    subindent = ' ' * 2 * (level + 1)\n",
        "    for file in files[:5]:  # Show first 5 files\n",
        "        print(f\"{subindent}{file}\")\n",
        "    if len(files) > 5:\n",
        "        print(f\"{subindent}... and {len(files)-5} more files\")"
      ],
      "metadata": {
        "id": "extract_zip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install librosa --break-system-packages"
      ],
      "metadata": {
        "id": "install_packages"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Music VAE for Feature Extraction\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import librosa\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "import os\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"LOADING DATASET WITH NEW STRUCTURE\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Find dataset structure\n",
        "dataset_root = os.path.join(extract_to, 'MyDataset')\n",
        "audio_root = os.path.join(dataset_root, 'audio')\n",
        "\n",
        "# Find metadata file (can be CSV or XLSX)\n",
        "metadata_path = None\n",
        "\n",
        "# First check for metadata files directly in MyDataset folder\n",
        "for file in os.listdir(dataset_root):\n",
        "    if file.endswith('.csv') or file.endswith('.xlsx'):\n",
        "        metadata_path = os.path.join(dataset_root, file)\n",
        "        break\n",
        "\n",
        "# If not found, check if there's a Metadata subfolder\n",
        "if metadata_path is None:\n",
        "    metadata_folder = os.path.join(dataset_root, 'Metadata')\n",
        "    if os.path.exists(metadata_folder):\n",
        "        for file in os.listdir(metadata_folder):\n",
        "            if file.endswith('.csv') or file.endswith('.xlsx'):\n",
        "                metadata_path = os.path.join(metadata_folder, file)\n",
        "                break\n",
        "\n",
        "if metadata_path is None:\n",
        "    raise FileNotFoundError(\"No metadata file (.csv or .xlsx) found in MyDataset folder or Metadata subfolder\")\n",
        "\n",
        "# Load metadata\n",
        "if metadata_path.endswith('.xlsx'):\n",
        "    metadata = pd.read_excel(metadata_path)\n",
        "    print(f\" Loaded Excel metadata: {os.path.basename(metadata_path)}\")\n",
        "else:\n",
        "    metadata = pd.read_csv(metadata_path)\n",
        "    print(f\" Loaded CSV metadata: {os.path.basename(metadata_path)}\")\n",
        "\n",
        "print(f\" Found audio folder: {audio_root}\")\n",
        "print(f\"nMetadata shape: {metadata.shape}\")\n",
        "print(\"\\nMetadata columns:\")\n",
        "print(metadata.columns.tolist())\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "print(metadata.head())\n",
        "\n",
        "# Check language distribution\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"DATASET STATISTICS\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\nLanguage distribution:\")\n",
        "print(metadata['language'].value_counts())\n",
        "if 'genre' in metadata.columns:\n",
        "    print(f\"\\nGenre distribution:\")\n",
        "    print(metadata['genre'].value_counts())\n",
        "print(f\"\\nTotal songs: {len(metadata)}\")\n",
        "\n",
        "# VAE Model\n",
        "class MusicVAE(nn.Module):\n",
        "    def __init__(self, input_dim=128, latent_dim=32):\n",
        "        super(MusicVAE, self).__init__()\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 48),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.fc_mu = nn.Linear(48, latent_dim)\n",
        "        self.fc_logvar = nn.Linear(48, latent_dim)\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 48),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(48, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, input_dim),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def encode(self, x):\n",
        "        h = self.encoder(x)\n",
        "        mu = self.fc_mu(h)\n",
        "        logvar = self.fc_logvar(h)\n",
        "        return mu, logvar\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def decode(self, z):\n",
        "        return self.decoder(z)\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        recon = self.decode(z)\n",
        "        return recon, mu, logvar\n",
        "\n",
        "# Loss function\n",
        "def vae_loss(recon_x, x, mu, logvar):\n",
        "    recon_loss = nn.functional.mse_loss(recon_x, x, reduction='sum')\n",
        "    kld = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    return recon_loss + kld\n",
        "\n",
        "# Audio Dataset\n",
        "class AudioDataset(Dataset):\n",
        "    def __init__(self, audio_paths, labels, n_mfcc=128):\n",
        "        self.audio_paths = audio_paths\n",
        "        self.labels = labels\n",
        "        self.n_mfcc = n_mfcc\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.audio_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        audio_path = self.audio_paths[idx]\n",
        "\n",
        "        # Load audio and extract MFCC features\n",
        "        y, sr = librosa.load(audio_path, duration=3.0, sr=22050)\n",
        "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=self.n_mfcc)\n",
        "\n",
        "        # Average over time to get fixed size\n",
        "        mfcc_mean = np.mean(mfcc, axis=1)\n",
        "\n",
        "        return torch.FloatTensor(mfcc_mean), self.labels[idx]\n",
        "\n",
        "# Prepare audio file paths based on directory structure\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PREPARING AUDIO FILES\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "audio_files = []\n",
        "labels = []\n",
        "filenames = []\n",
        "\n",
        "# Process each language folder (lowercase folder names)\n",
        "for lang_folder in ['bangla', 'english']:\n",
        "    lang_path = os.path.join(audio_root, lang_folder)\n",
        "\n",
        "    if not os.path.exists(lang_path):\n",
        "        print(f\"Warning: {lang_path} not found, skipping...\")\n",
        "        continue\n",
        "\n",
        "    files = [f for f in os.listdir(lang_path) if f.endswith(('.mp3', '.wav', '.flac'))]\n",
        "\n",
        "    for file in files[:100]:  # Limit to 100 per language for faster processing\n",
        "        full_path = os.path.join(lang_path, file)\n",
        "        audio_files.append(full_path)\n",
        "        labels.append(0 if lang_folder == 'bangla' else 1)\n",
        "        filenames.append(f\"{lang_folder}/{file}\")\n",
        "\n",
        "    print(f\"   {lang_folder.capitalize()}: {len(files)} files found, using first 100\")\n",
        "\n",
        "print(f\"\\nTotal audio files to process: {len(audio_files)}\")\n",
        "print(f\"  Bangla: {sum([1 for l in labels if l == 0])}\")\n",
        "print(f\"  English: {sum([1 for l in labels if l == 1])}\")\n",
        "\n",
        "# Create dataset and dataloader\n",
        "dataset = AudioDataset(audio_files, labels)\n",
        "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Initialize model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"\\nUsing device: {device}\")\n",
        "\n",
        "model = MusicVAE(input_dim=128, latent_dim=32).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "# Training\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TRAINING VAE\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "num_epochs = 50\n",
        "losses = []\n",
        "\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    epoch_loss = 0\n",
        "    for batch_idx, (data, _) in enumerate(train_loader):\n",
        "        data = data.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        recon, mu, logvar = model(data)\n",
        "        loss = vae_loss(recon, data, mu, logvar)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    avg_loss = epoch_loss / len(train_loader.dataset)\n",
        "    losses.append(avg_loss)\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
        "\n",
        "print(\"\\n Training complete!\")\n",
        "\n",
        "# Extract latent features\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"EXTRACTING LATENT FEATURES\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "model.eval()\n",
        "latent_features = []\n",
        "true_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data, label in dataset:\n",
        "        data = data.unsqueeze(0).to(device)\n",
        "        mu, _ = model.encode(data)\n",
        "        latent_features.append(mu.cpu().numpy().flatten())\n",
        "        true_labels.append(label)\n",
        "\n",
        "latent_features = np.array(latent_features)\n",
        "\n",
        "# Create features dataframe\n",
        "features_df = pd.DataFrame(\n",
        "    latent_features,\n",
        "    columns=[f'feature_{i}' for i in range(latent_features.shape[1])]\n",
        ")\n",
        "\n",
        "features_df['filename'] = filenames\n",
        "features_df['language'] = ['bangla' if l == 0 else 'english' for l in true_labels]\n",
        "\n",
        "# Save features\n",
        "features_df.to_csv('/content/audio_vae_features.csv', index=False)\n",
        "print(f\"\\n Saved latent features: {features_df.shape}\")\n",
        "print(f\"  File: /content/audio_vae_features.csv\")\n",
        "print(\"\\nFeatures preview:\")\n",
        "print(features_df.head())"
      ],
      "metadata": {
        "id": "vae_training"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# K-Means Clustering on VAE Latent Features\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import silhouette_score, davies_bouldin_score, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import os\n",
        "\n",
        "# Create output directory\n",
        "output_dir = '/content/drive/MyDrive/clustering_results'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "print(f\"Output directory: {output_dir}\")\n",
        "\n",
        "# Load features\n",
        "features_df = pd.read_csv('/content/audio_vae_features.csv')\n",
        "\n",
        "print(f\"\\nLoaded features: {features_df.shape}\")\n",
        "print(\"\\nColumns:\", features_df.columns.tolist())\n",
        "print(\"\\nFirst rows:\")\n",
        "print(features_df.head())\n",
        "\n",
        "# Get feature columns\n",
        "feature_cols = [col for col in features_df.columns if col.startswith('feature_')]\n",
        "X = features_df[feature_cols].values\n",
        "\n",
        "print(f\"\\nFeature matrix shape: {X.shape}\")\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Find optimal K using elbow method\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Finding optimal K (Elbow Method)\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "inertias = []\n",
        "silhouette_scores = []\n",
        "k_range = range(2, 11)\n",
        "\n",
        "for k in k_range:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "    labels = kmeans.fit_predict(X_scaled)\n",
        "\n",
        "    inertias.append(kmeans.inertia_)\n",
        "    sil_score = silhouette_score(X_scaled, labels)\n",
        "    silhouette_scores.append(sil_score)\n",
        "\n",
        "    print(f\"K={k}: Inertia={kmeans.inertia_:.2f}, Silhouette={sil_score:.3f}\")\n",
        "\n",
        "# Plot elbow curve\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "ax1.plot(k_range, inertias, 'bo-')\n",
        "ax1.set_xlabel('Number of Clusters (K)')\n",
        "ax1.set_ylabel('Inertia')\n",
        "ax1.set_title('Elbow Method')\n",
        "ax1.grid(True)\n",
        "\n",
        "ax2.plot(k_range, silhouette_scores, 'ro-')\n",
        "ax2.set_xlabel('Number of Clusters (K)')\n",
        "ax2.set_ylabel('Silhouette Score')\n",
        "ax2.set_title('Silhouette Score vs K')\n",
        "ax2.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "save_path = os.path.join(output_dir, 'optimal_k.png')\n",
        "plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "print(f\"\\n Saved: {save_path}\")\n",
        "plt.show()\n",
        "\n",
        "# Perform K-Means with k=2 (bangla vs english)\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"K-Means Clustering (K=2)\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
        "features_df['cluster'] = kmeans.fit_predict(X_scaled)\n",
        "\n",
        "# Clustering metrics\n",
        "sil_score = silhouette_score(X_scaled, features_df['cluster'])\n",
        "db_score = davies_bouldin_score(X_scaled, features_df['cluster'])\n",
        "\n",
        "print(f\"\\nSilhouette Score: {sil_score:.3f}\")\n",
        "print(f\"Davies-Bouldin Score: {db_score:.3f}\")\n",
        "\n",
        "# Compare clusters with actual labels\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Cluster vs Language Distribution\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "crosstab = pd.crosstab(features_df['language'], features_df['cluster'],\n",
        "                       margins=True, margins_name='Total')\n",
        "print(crosstab)\n",
        "\n",
        "# Calculate clustering purity\n",
        "language_numeric = features_df['language'].map({'bangla': 0, 'english': 1})\n",
        "cm = confusion_matrix(language_numeric, features_df['cluster'])\n",
        "purity = np.sum(np.amax(cm, axis=0)) / np.sum(cm)\n",
        "\n",
        "print(f\"\\nCluster Purity: {purity:.3f}\")\n",
        "\n",
        "# Save clustered data\n",
        "output_path = os.path.join(output_dir, 'audio_vae_features_clustered.csv')\n",
        "features_df.to_csv(output_path, index=False)\n",
        "print(f\"\\n Saved clustered features: {output_path}\")"
      ],
      "metadata": {
        "id": "kmeans_clustering"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# t-SNE and UMAP Visualization\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import subprocess\n",
        "import warnings\n",
        "import os\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Install UMAP\n",
        "subprocess.run(['pip', 'install', 'umap-learn', '--break-system-packages'],\n",
        "               capture_output=True)\n",
        "\n",
        "import umap\n",
        "\n",
        "output_dir = '/content/drive/MyDrive/clustering_results'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "print(\"Loading features...\")\n",
        "features_df = pd.read_csv(os.path.join(output_dir, 'audio_vae_features_clustered.csv'))\n",
        "\n",
        "# Load original metadata for genre info\n",
        "dataset_root = os.path.join(extract_to, 'MyDataset')\n",
        "\n",
        "# Find metadata file (CSV or XLSX)\n",
        "metadata_path = None\n",
        "\n",
        "# Check directly in MyDataset folder first\n",
        "for file in os.listdir(dataset_root):\n",
        "    if file.endswith('.csv') or file.endswith('.xlsx'):\n",
        "        metadata_path = os.path.join(dataset_root, file)\n",
        "        break\n",
        "\n",
        "# If not found, check Metadata subfolder\n",
        "if metadata_path is None:\n",
        "    metadata_folder = os.path.join(dataset_root, 'Metadata')\n",
        "    if os.path.exists(metadata_folder):\n",
        "        for file in os.listdir(metadata_folder):\n",
        "            if file.endswith('.csv') or file.endswith('.xlsx'):\n",
        "                metadata_path = os.path.join(metadata_folder, file)\n",
        "                break\n",
        "\n",
        "if metadata_path is None:\n",
        "    print(\"Warning: No metadata file found, skipping genre mapping\")\n",
        "    features_df['genre'] = 'Unknown'\n",
        "else:\n",
        "    # Load metadata (handle both CSV and Excel)\n",
        "    if metadata_path.endswith('.xlsx'):\n",
        "        metadata = pd.read_excel(metadata_path)\n",
        "    else:\n",
        "        metadata = pd.read_csv(metadata_path)\n",
        "\n",
        "    print(f\" Loaded metadata: {os.path.basename(metadata_path)}\")\n",
        "\n",
        "    # Create a mapping from filename to genre\n",
        "    # Extract just the base filename from the metadata 'filenaming' column\n",
        "    metadata['base_filename'] = metadata['filenaming'].apply(lambda x: os.path.basename(x))\n",
        "    genre_map = dict(zip(metadata['base_filename'], metadata['genre']))\n",
        "\n",
        "    # Match with features\n",
        "    features_df['base_filename'] = features_df['filename'].apply(lambda x: os.path.basename(x))\n",
        "    features_df['genre'] = features_df['base_filename'].map(genre_map)\n",
        "    features_df['genre'] = features_df['genre'].fillna('Unknown')\n",
        "\n",
        "print(f\" Loaded {len(features_df)} samples\")\n",
        "print(f\"Columns: {features_df.columns.tolist()}\")\n",
        "\n",
        "# Get feature columns\n",
        "feature_cols = [col for col in features_df.columns if col.startswith('feature_')]\n",
        "X = features_df[feature_cols].values\n",
        "\n",
        "print(f\"\\nFeature matrix shape: {X.shape}\")\n",
        "\n",
        "# Standardize\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# t-SNE\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Running t-SNE...\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "tsne = TSNE(n_components=2, random_state=42, perplexity=30, n_iter=1000)\n",
        "X_tsne = tsne.fit_transform(X_scaled)\n",
        "\n",
        "features_df['tsne_1'] = X_tsne[:, 0]\n",
        "features_df['tsne_2'] = X_tsne[:, 1]\n",
        "\n",
        "print(\" t-SNE complete!\")\n",
        "\n",
        "# UMAP\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Running UMAP...\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "reducer = umap.UMAP(n_components=2, random_state=42, n_neighbors=15, min_dist=0.1)\n",
        "X_umap = reducer.fit_transform(X_scaled)\n",
        "\n",
        "features_df['umap_1'] = X_umap[:, 0]\n",
        "features_df['umap_2'] = X_umap[:, 1]\n",
        "\n",
        "print(\" UMAP complete!\")\n",
        "\n",
        "# Visualization 1: t-SNE with 4 views\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Creating t-SNE visualizations...\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(18, 16))\n",
        "\n",
        "# t-SNE by cluster\n",
        "ax1 = axes[0, 0]\n",
        "scatter = ax1.scatter(features_df['tsne_1'], features_df['tsne_2'],\n",
        "                     c=features_df['cluster'],\n",
        "                     cmap='viridis',\n",
        "                     alpha=0.6,\n",
        "                     edgecolors='k',\n",
        "                     s=100)\n",
        "ax1.set_xlabel('t-SNE Component 1', fontsize=13)\n",
        "ax1.set_ylabel('t-SNE Component 2', fontsize=13)\n",
        "ax1.set_title('t-SNE: Colored by Cluster', fontsize=15, fontweight='bold')\n",
        "ax1.grid(alpha=0.3)\n",
        "plt.colorbar(scatter, ax=ax1, label='Cluster')\n",
        "\n",
        "# t-SNE by language\n",
        "ax2 = axes[0, 1]\n",
        "colors = {'bangla': 'blue', 'english': 'red'}\n",
        "for language in ['bangla', 'english']:\n",
        "    mask = features_df['language'] == language\n",
        "    ax2.scatter(features_df.loc[mask, 'tsne_1'],\n",
        "               features_df.loc[mask, 'tsne_2'],\n",
        "               c=colors[language],\n",
        "               label=language.capitalize(),\n",
        "               alpha=0.6,\n",
        "               edgecolors='k',\n",
        "               s=100)\n",
        "ax2.set_xlabel('t-SNE Component 1', fontsize=13)\n",
        "ax2.set_ylabel('t-SNE Component 2', fontsize=13)\n",
        "ax2.set_title('t-SNE: Colored by Language (Ground Truth)', fontsize=15, fontweight='bold')\n",
        "ax2.legend()\n",
        "ax2.grid(alpha=0.3)\n",
        "\n",
        "# t-SNE by genre\n",
        "ax3 = axes[1, 0]\n",
        "unique_genres = features_df['genre'].unique()\n",
        "genre_colors = plt.cm.tab10(np.linspace(0, 1, len(unique_genres)))\n",
        "for genre, color in zip(unique_genres, genre_colors):\n",
        "    mask = features_df['genre'] == genre\n",
        "    ax3.scatter(features_df.loc[mask, 'tsne_1'],\n",
        "               features_df.loc[mask, 'tsne_2'],\n",
        "               c=[color],\n",
        "               label=genre,\n",
        "               alpha=0.6,\n",
        "               edgecolors='k',\n",
        "               s=100)\n",
        "ax3.set_xlabel('t-SNE Component 1', fontsize=13)\n",
        "ax3.set_ylabel('t-SNE Component 2', fontsize=13)\n",
        "ax3.set_title('t-SNE: Colored by Genre', fontsize=15, fontweight='bold')\n",
        "ax3.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "ax3.grid(alpha=0.3)\n",
        "\n",
        "# Combined view\n",
        "ax4 = axes[1, 1]\n",
        "for language in ['bangla', 'english']:\n",
        "    mask = features_df['language'] == language\n",
        "    marker = 'o' if language == 'bangla' else 's'\n",
        "    for cluster in [0, 1]:\n",
        "        cluster_mask = mask & (features_df['cluster'] == cluster)\n",
        "        ax4.scatter(features_df.loc[cluster_mask, 'tsne_1'],\n",
        "                   features_df.loc[cluster_mask, 'tsne_2'],\n",
        "                   c=colors[language],\n",
        "                   marker=marker,\n",
        "                   label=f\"{language.capitalize()} - Cluster {cluster}\",\n",
        "                   alpha=0.6,\n",
        "                   edgecolors='k',\n",
        "                   s=100)\n",
        "ax4.set_xlabel('t-SNE Component 1', fontsize=13)\n",
        "ax4.set_ylabel('t-SNE Component 2', fontsize=13)\n",
        "ax4.set_title('t-SNE: Language + Cluster', fontsize=15, fontweight='bold')\n",
        "ax4.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "ax4.grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "save_path = os.path.join(output_dir, 'tsne_visualization_4views.png')\n",
        "plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "print(f\" Saved: {save_path}\")\n",
        "plt.show()\n",
        "\n",
        "# Visualization 2: UMAP with 4 views\n",
        "print(\"\\nCreating UMAP visualizations...\")\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(18, 16))\n",
        "\n",
        "# UMAP by cluster\n",
        "ax1 = axes[0, 0]\n",
        "scatter = ax1.scatter(features_df['umap_1'], features_df['umap_2'],\n",
        "                     c=features_df['cluster'],\n",
        "                     cmap='viridis',\n",
        "                     alpha=0.6,\n",
        "                     edgecolors='k',\n",
        "                     s=100)\n",
        "ax1.set_xlabel('UMAP Component 1', fontsize=13)\n",
        "ax1.set_ylabel('UMAP Component 2', fontsize=13)\n",
        "ax1.set_title('UMAP: Colored by Cluster', fontsize=15, fontweight='bold')\n",
        "ax1.grid(alpha=0.3)\n",
        "plt.colorbar(scatter, ax=ax1, label='Cluster')\n",
        "\n",
        "# UMAP by language\n",
        "ax2 = axes[0, 1]\n",
        "for language in ['bangla', 'english']:\n",
        "    mask = features_df['language'] == language\n",
        "    ax2.scatter(features_df.loc[mask, 'umap_1'],\n",
        "               features_df.loc[mask, 'umap_2'],\n",
        "               c=colors[language],\n",
        "               label=language.capitalize(),\n",
        "               alpha=0.6,\n",
        "               edgecolors='k',\n",
        "               s=100)\n",
        "ax2.set_xlabel('UMAP Component 1', fontsize=13)\n",
        "ax2.set_ylabel('UMAP Component 2', fontsize=13)\n",
        "ax2.set_title('UMAP: Colored by Language (Ground Truth)', fontsize=15, fontweight='bold')\n",
        "ax2.legend()\n",
        "ax2.grid(alpha=0.3)\n",
        "\n",
        "# UMAP by genre\n",
        "ax3 = axes[1, 0]\n",
        "for genre, color in zip(unique_genres, genre_colors):\n",
        "    mask = features_df['genre'] == genre\n",
        "    ax3.scatter(features_df.loc[mask, 'umap_1'],\n",
        "               features_df.loc[mask, 'umap_2'],\n",
        "               c=[color],\n",
        "               label=genre,\n",
        "               alpha=0.6,\n",
        "               edgecolors='k',\n",
        "               s=100)\n",
        "ax3.set_xlabel('UMAP Component 1', fontsize=13)\n",
        "ax3.set_ylabel('UMAP Component 2', fontsize=13)\n",
        "ax3.set_title('UMAP: Colored by Genre', fontsize=15, fontweight='bold')\n",
        "ax3.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "ax3.grid(alpha=0.3)\n",
        "\n",
        "# Combined view\n",
        "ax4 = axes[1, 1]\n",
        "for language in ['bangla', 'english']:\n",
        "    mask = features_df['language'] == language\n",
        "    marker = 'o' if language == 'bangla' else 's'\n",
        "    for cluster in [0, 1]:\n",
        "        cluster_mask = mask & (features_df['cluster'] == cluster)\n",
        "        ax4.scatter(features_df.loc[cluster_mask, 'umap_1'],\n",
        "                   features_df.loc[cluster_mask, 'umap_2'],\n",
        "                   c=colors[language],\n",
        "                   marker=marker,\n",
        "                   label=f\"{language.capitalize()} - Cluster {cluster}\",\n",
        "                   alpha=0.6,\n",
        "                   edgecolors='k',\n",
        "                   s=100)\n",
        "ax4.set_xlabel('UMAP Component 1', fontsize=13)\n",
        "ax4.set_ylabel('UMAP Component 2', fontsize=13)\n",
        "ax4.set_title('UMAP: Language + Cluster', fontsize=15, fontweight='bold')\n",
        "ax4.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "ax4.grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "save_path = os.path.join(output_dir, 'umap_visualization_4views.png')\n",
        "plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "print(f\" Saved: {save_path}\")\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\" VISUALIZATION COMPLETE!\")\n",
        "print(\"=\"*50)\n",
        "print(f\"\\nAll visualizations saved to: {output_dir}\")"
      ],
      "metadata": {
        "id": "visualization"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================================\n",
        "# COMPREHENSIVE COMPARISON: VAE vs BASELINE (PCA + K-MEANS)\n",
        "# Metrics: Silhouette Score, Calinski-Harabasz Index, Davies-Bouldin, ARI, NMI\n",
        "# ================================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import (\n",
        "    silhouette_score,\n",
        "    calinski_harabasz_score,\n",
        "    davies_bouldin_score,\n",
        "    adjusted_rand_score,\n",
        "    normalized_mutual_info_score,\n",
        "    confusion_matrix\n",
        ")\n",
        "import librosa\n",
        "import os\n",
        "import time\n",
        "\n",
        "# Create output directory\n",
        "output_dir = '/content/drive/MyDrive/clustering_results'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"VAE vs BASELINE COMPARISON\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 1: LOAD VAE FEATURES\n",
        "# ============================================================================\n",
        "print(\"\\n1. Loading VAE features...\")\n",
        "\n",
        "# Try to load VAE features\n",
        "vae_loaded = False\n",
        "vae_type = \"\"\n",
        "\n",
        "try:\n",
        "    vae_df = pd.read_csv('/content/audio_vae_features.csv')\n",
        "    vae_type = \"Basic VAE\"\n",
        "    vae_loaded = True\n",
        "except:\n",
        "    pass\n",
        "\n",
        "if not vae_loaded:\n",
        "    try:\n",
        "        vae_df = pd.read_csv('/content/audio_conv_vae_features.csv')\n",
        "        vae_type = \"Convolutional VAE\"\n",
        "        vae_loaded = True\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "if not vae_loaded:\n",
        "    try:\n",
        "        vae_df = pd.read_csv('/content/audio_hybrid_vae_features.csv')\n",
        "        vae_type = \"Hybrid VAE\"\n",
        "        vae_loaded = True\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "if not vae_loaded:\n",
        "    print(\"ERROR: No VAE features found! Please run VAE training first.\")\n",
        "    raise FileNotFoundError(\"VAE features not found\")\n",
        "\n",
        "print(f\"   Loaded {vae_type}: {vae_df.shape}\")\n",
        "\n",
        "# Extract VAE features and labels\n",
        "vae_feature_cols = [col for col in vae_df.columns if col.startswith('feature_')]\n",
        "X_vae = vae_df[vae_feature_cols].values\n",
        "y_true = vae_df['language'].map({'bangla': 0, 'english': 1}).values\n",
        "\n",
        "print(f\"  VAE features shape: {X_vae.shape}\")\n",
        "print(f\"  Labels: Bangla={np.sum(y_true==0)}, English={np.sum(y_true==1)}\")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 2: EXTRACT BASELINE FEATURES (Raw MFCC)\n",
        "# ============================================================================\n",
        "print(\"\\n2. Extracting baseline features (MFCC)...\")\n",
        "\n",
        "dataset_root = os.path.join(extract_to, 'MyDataset')\n",
        "audio_root = os.path.join(dataset_root, 'audio')\n",
        "\n",
        "# Get audio files (same ones used for VAE)\n",
        "audio_files = []\n",
        "baseline_labels = []\n",
        "\n",
        "for lang_folder in ['bangla', 'english']:\n",
        "    lang_path = os.path.join(audio_root, lang_folder)\n",
        "\n",
        "    if not os.path.exists(lang_path):\n",
        "        print(f\"  Warning: {lang_path} not found\")\n",
        "        continue\n",
        "\n",
        "    files = [f for f in os.listdir(lang_path) if f.endswith(('.mp3', '.wav', '.flac'))]\n",
        "\n",
        "    for file in files[:len(vae_df)//2]:  # Match VAE dataset size\n",
        "        full_path = os.path.join(lang_path, file)\n",
        "        audio_files.append(full_path)\n",
        "        baseline_labels.append(0 if lang_folder == 'bangla' else 1)\n",
        "\n",
        "print(f\"  Processing {len(audio_files)} audio files...\")\n",
        "\n",
        "# Extract MFCC features\n",
        "mfcc_features = []\n",
        "for i, audio_path in enumerate(audio_files):\n",
        "    try:\n",
        "        y, sr = librosa.load(audio_path, duration=3.0, sr=22050)\n",
        "\n",
        "        # MFCC\n",
        "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=20)\n",
        "        mfcc_mean = np.mean(mfcc, axis=1)\n",
        "        mfcc_std = np.std(mfcc, axis=1)\n",
        "\n",
        "        # Additional features\n",
        "        spectral_centroid = np.mean(librosa.feature.spectral_centroid(y=y, sr=sr))\n",
        "        spectral_rolloff = np.mean(librosa.feature.spectral_rolloff(y=y, sr=sr))\n",
        "        zero_crossing = np.mean(librosa.feature.zero_crossing_rate(y))\n",
        "\n",
        "        # Combine: 20 MFCC means + 20 MFCC stds + 3 spectral = 43 features\n",
        "        features = np.concatenate([mfcc_mean, mfcc_std,\n",
        "                                   [spectral_centroid, spectral_rolloff, zero_crossing]])\n",
        "\n",
        "        mfcc_features.append(features)\n",
        "\n",
        "        if (i + 1) % 50 == 0:\n",
        "            print(f\"    Processed {i+1}/{len(audio_files)} files\")\n",
        "    except Exception as e:\n",
        "        print(f\"    Error processing {audio_path}: {e}\")\n",
        "        mfcc_features.append(np.zeros(43))\n",
        "\n",
        "X_baseline = np.array(mfcc_features)\n",
        "print(f\"   Baseline features shape: {X_baseline.shape}\")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 3: APPLY PCA TO BASELINE FEATURES\n",
        "# ============================================================================\n",
        "print(\"\\n3. Applying PCA to baseline features...\")\n",
        "\n",
        "# Standardize baseline features\n",
        "scaler_baseline = StandardScaler()\n",
        "X_baseline_scaled = scaler_baseline.fit_transform(X_baseline)\n",
        "\n",
        "# Apply PCA with different components\n",
        "pca_results = {}\n",
        "for n_components in [10, 20, 32]:\n",
        "    pca = PCA(n_components=n_components, random_state=42)\n",
        "    X_pca = pca.fit_transform(X_baseline_scaled)\n",
        "\n",
        "    explained_var = np.sum(pca.explained_variance_ratio_)\n",
        "    pca_results[n_components] = {\n",
        "        'features': X_pca,\n",
        "        'explained_variance': explained_var\n",
        "    }\n",
        "    print(f\"  PCA-{n_components}: Explained variance = {explained_var:.3f}\")\n",
        "\n",
        "# Use PCA-32 as main baseline (same dimensionality as basic VAE)\n",
        "X_pca_baseline = pca_results[32]['features']\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 4: CLUSTERING WITH K-MEANS\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"4. Performing K-Means Clustering (K=2)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "results = []\n",
        "\n",
        "# Method 1: VAE + K-Means\n",
        "print(\"\\n[1/3] VAE + K-Means...\")\n",
        "start_time = time.time()\n",
        "\n",
        "scaler_vae = StandardScaler()\n",
        "X_vae_scaled = scaler_vae.fit_transform(X_vae)\n",
        "\n",
        "kmeans_vae = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
        "labels_vae = kmeans_vae.fit_predict(X_vae_scaled)\n",
        "\n",
        "time_vae = time.time() - start_time\n",
        "\n",
        "# Calculate metrics for VAE\n",
        "sil_vae = silhouette_score(X_vae_scaled, labels_vae)\n",
        "ch_vae = calinski_harabasz_score(X_vae_scaled, labels_vae)\n",
        "db_vae = davies_bouldin_score(X_vae_scaled, labels_vae)\n",
        "ari_vae = adjusted_rand_score(y_true, labels_vae)\n",
        "nmi_vae = normalized_mutual_info_score(y_true, labels_vae)\n",
        "\n",
        "# Calculate purity\n",
        "cm_vae = confusion_matrix(y_true, labels_vae)\n",
        "purity_vae = np.sum(np.amax(cm_vae, axis=0)) / np.sum(cm_vae)\n",
        "\n",
        "results.append({\n",
        "    'Method': f'{vae_type} + K-Means',\n",
        "    'Silhouette': sil_vae,\n",
        "    'Calinski-Harabasz': ch_vae,\n",
        "    'Davies-Bouldin': db_vae,\n",
        "    'ARI': ari_vae,\n",
        "    'NMI': nmi_vae,\n",
        "    'Purity': purity_vae,\n",
        "    'Time (s)': time_vae,\n",
        "    'N_Features': X_vae.shape[1]\n",
        "})\n",
        "\n",
        "print(f\"   Silhouette: {sil_vae:.4f}\")\n",
        "print(f\"   Calinski-Harabasz: {ch_vae:.2f}\")\n",
        "print(f\"   Davies-Bouldin: {db_vae:.4f}\")\n",
        "print(f\"   ARI: {ari_vae:.4f}\")\n",
        "print(f\"   Purity: {purity_vae:.4f}\")\n",
        "print(f\"   Time: {time_vae:.3f}s\")\n",
        "\n",
        "# Method 2: PCA-32 + K-Means (Main Baseline)\n",
        "print(\"\\n[2/3] PCA-32 + K-Means...\")\n",
        "start_time = time.time()\n",
        "\n",
        "scaler_pca = StandardScaler()\n",
        "X_pca_scaled = scaler_pca.fit_transform(X_pca_baseline)\n",
        "\n",
        "kmeans_pca = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
        "labels_pca = kmeans_pca.fit_predict(X_pca_scaled)\n",
        "\n",
        "time_pca = time.time() - start_time\n",
        "\n",
        "sil_pca = silhouette_score(X_pca_scaled, labels_pca)\n",
        "ch_pca = calinski_harabasz_score(X_pca_scaled, labels_pca)\n",
        "db_pca = davies_bouldin_score(X_pca_scaled, labels_pca)\n",
        "ari_pca = adjusted_rand_score(y_true, labels_pca)\n",
        "nmi_pca = normalized_mutual_info_score(y_true, labels_pca)\n",
        "\n",
        "cm_pca = confusion_matrix(y_true, labels_pca)\n",
        "purity_pca = np.sum(np.amax(cm_pca, axis=0)) / np.sum(cm_pca)\n",
        "\n",
        "results.append({\n",
        "    'Method': 'PCA-32 + K-Means',\n",
        "    'Silhouette': sil_pca,\n",
        "    'Calinski-Harabasz': ch_pca,\n",
        "    'Davies-Bouldin': db_pca,\n",
        "    'ARI': ari_pca,\n",
        "    'NMI': nmi_pca,\n",
        "    'Purity': purity_pca,\n",
        "    'Time (s)': time_pca,\n",
        "    'N_Features': 32\n",
        "})\n",
        "\n",
        "print(f\"   Silhouette: {sil_pca:.4f}\")\n",
        "print(f\"   Calinski-Harabasz: {ch_pca:.2f}\")\n",
        "print(f\"   Davies-Bouldin: {db_pca:.4f}\")\n",
        "print(f\"   ARI: {ari_pca:.4f}\")\n",
        "print(f\"   Purity: {purity_pca:.4f}\")\n",
        "print(f\"   Time: {time_pca:.3f}s\")\n",
        "\n",
        "# Method 3: Raw MFCC + K-Means (No dimensionality reduction)\n",
        "print(\"\\n[3/3] Raw MFCC + K-Means...\")\n",
        "start_time = time.time()\n",
        "\n",
        "kmeans_raw = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
        "labels_raw = kmeans_raw.fit_predict(X_baseline_scaled)\n",
        "\n",
        "time_raw = time.time() - start_time\n",
        "\n",
        "sil_raw = silhouette_score(X_baseline_scaled, labels_raw)\n",
        "ch_raw = calinski_harabasz_score(X_baseline_scaled, labels_raw)\n",
        "db_raw = davies_bouldin_score(X_baseline_scaled, labels_raw)\n",
        "ari_raw = adjusted_rand_score(y_true, labels_raw)\n",
        "nmi_raw = normalized_mutual_info_score(y_true, labels_raw)\n",
        "\n",
        "cm_raw = confusion_matrix(y_true, labels_raw)\n",
        "purity_raw = np.sum(np.amax(cm_raw, axis=0)) / np.sum(cm_raw)\n",
        "\n",
        "results.append({\n",
        "    'Method': 'Raw MFCC + K-Means',\n",
        "    'Silhouette': sil_raw,\n",
        "    'Calinski-Harabasz': ch_raw,\n",
        "    'Davies-Bouldin': db_raw,\n",
        "    'ARI': ari_raw,\n",
        "    'NMI': nmi_raw,\n",
        "    'Purity': purity_raw,\n",
        "    'Time (s)': time_raw,\n",
        "    'N_Features': 43\n",
        "})\n",
        "\n",
        "print(f\"   Silhouette: {sil_raw:.4f}\")\n",
        "print(f\"   Calinski-Harabasz: {ch_raw:.2f}\")\n",
        "print(f\"   Davies-Bouldin: {db_raw:.4f}\")\n",
        "print(f\"   ARI: {ari_raw:.4f}\")\n",
        "print(f\"   Purity: {purity_raw:.4f}\")\n",
        "print(f\"   Time: {time_raw:.3f}s\")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 5: CREATE COMPARISON DATAFRAME\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"5. Results Summary\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"\\n\" + results_df.to_string(index=False))\n",
        "\n",
        "# Save results\n",
        "results_path = os.path.join(output_dir, 'vae_vs_baseline_comparison.csv')\n",
        "results_df.to_csv(results_path, index=False)\n",
        "print(f\"\\n Saved results: {results_path}\")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 6: VISUALIZATIONS\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"6. Creating Visualizations\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Create figure with multiple subplots\n",
        "fig = plt.figure(figsize=(20, 12))\n",
        "gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
        "\n",
        "methods = results_df['Method'].tolist()\n",
        "colors_method = ['#e74c3c', '#3498db', '#2ecc71']\n",
        "\n",
        "# ===== Plot 1: Silhouette Score Comparison =====\n",
        "ax1 = fig.add_subplot(gs[0, 0])\n",
        "bars1 = ax1.bar(range(len(methods)), results_df['Silhouette'], color=colors_method)\n",
        "ax1.set_xticks(range(len(methods)))\n",
        "ax1.set_xticklabels(methods, rotation=45, ha='right')\n",
        "ax1.set_ylabel('Silhouette Score', fontsize=12, fontweight='bold')\n",
        "ax1.set_title('Silhouette Score\\n(Higher is Better)', fontsize=13, fontweight='bold')\n",
        "ax1.set_ylim([0, max(results_df['Silhouette']) * 1.2])\n",
        "ax1.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Add value labels on bars\n",
        "for i, (bar, val) in enumerate(zip(bars1, results_df['Silhouette'])):\n",
        "    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "            f'{val:.3f}', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "# ===== Plot 2: Calinski-Harabasz Index =====\n",
        "ax2 = fig.add_subplot(gs[0, 1])\n",
        "bars2 = ax2.bar(range(len(methods)), results_df['Calinski-Harabasz'], color=colors_method)\n",
        "ax2.set_xticks(range(len(methods)))\n",
        "ax2.set_xticklabels(methods, rotation=45, ha='right')\n",
        "ax2.set_ylabel('Calinski-Harabasz Index', fontsize=12, fontweight='bold')\n",
        "ax2.set_title('Calinski-Harabasz Index\\n(Higher is Better)', fontsize=13, fontweight='bold')\n",
        "ax2.set_ylim([0, max(results_df['Calinski-Harabasz']) * 1.2])\n",
        "ax2.grid(axis='y', alpha=0.3)\n",
        "\n",
        "for i, (bar, val) in enumerate(zip(bars2, results_df['Calinski-Harabasz'])):\n",
        "    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(results_df['Calinski-Harabasz']) * 0.02,\n",
        "            f'{val:.1f}', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "# ===== Plot 3: Davies-Bouldin Index =====\n",
        "ax3 = fig.add_subplot(gs[0, 2])\n",
        "bars3 = ax3.bar(range(len(methods)), results_df['Davies-Bouldin'], color=colors_method)\n",
        "ax3.set_xticks(range(len(methods)))\n",
        "ax3.set_xticklabels(methods, rotation=45, ha='right')\n",
        "ax3.set_ylabel('Davies-Bouldin Index', fontsize=12, fontweight='bold')\n",
        "ax3.set_title('Davies-Bouldin Index\\n(Lower is Better)', fontsize=13, fontweight='bold')\n",
        "ax3.set_ylim([0, max(results_df['Davies-Bouldin']) * 1.2])\n",
        "ax3.grid(axis='y', alpha=0.3)\n",
        "\n",
        "for i, (bar, val) in enumerate(zip(bars3, results_df['Davies-Bouldin'])):\n",
        "    ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,\n",
        "            f'{val:.3f}', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "# ===== Plot 4: ARI and NMI =====\n",
        "ax4 = fig.add_subplot(gs[1, 0])\n",
        "x = np.arange(len(methods))\n",
        "width = 0.35\n",
        "\n",
        "bars4a = ax4.bar(x - width/2, results_df['ARI'], width, label='ARI', color='#9b59b6')\n",
        "bars4b = ax4.bar(x + width/2, results_df['NMI'], width, label='NMI', color='#f39c12')\n",
        "\n",
        "ax4.set_xticks(x)\n",
        "ax4.set_xticklabels(methods, rotation=45, ha='right')\n",
        "ax4.set_ylabel('Score', fontsize=12, fontweight='bold')\n",
        "ax4.set_title('External Validation Metrics\\n(Higher is Better)', fontsize=13, fontweight='bold')\n",
        "ax4.legend()\n",
        "ax4.grid(axis='y', alpha=0.3)\n",
        "ax4.set_ylim([0, 1.0])\n",
        "\n",
        "# ===== Plot 5: Purity =====\n",
        "ax5 = fig.add_subplot(gs[1, 1])\n",
        "bars5 = ax5.bar(range(len(methods)), results_df['Purity'], color=colors_method)\n",
        "ax5.set_xticks(range(len(methods)))\n",
        "ax5.set_xticklabels(methods, rotation=45, ha='right')\n",
        "ax5.set_ylabel('Purity', fontsize=12, fontweight='bold')\n",
        "ax5.set_title('Cluster Purity\\n(Higher is Better)', fontsize=13, fontweight='bold')\n",
        "ax5.set_ylim([0, 1.0])\n",
        "ax5.grid(axis='y', alpha=0.3)\n",
        "\n",
        "for i, (bar, val) in enumerate(zip(bars5, results_df['Purity'])):\n",
        "    ax5.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,\n",
        "            f'{val:.3f}', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "# ===== Plot 6: Execution Time =====\n",
        "ax6 = fig.add_subplot(gs[1, 2])\n",
        "bars6 = ax6.bar(range(len(methods)), results_df['Time (s)'], color=colors_method)\n",
        "ax6.set_xticks(range(len(methods)))\n",
        "ax6.set_xticklabels(methods, rotation=45, ha='right')\n",
        "ax6.set_ylabel('Time (seconds)', fontsize=12, fontweight='bold')\n",
        "ax6.set_title('Execution Time\\n(Lower is Better)', fontsize=13, fontweight='bold')\n",
        "ax6.set_ylim([0, max(results_df['Time (s)']) * 1.2])\n",
        "ax6.grid(axis='y', alpha=0.3)\n",
        "\n",
        "for i, (bar, val) in enumerate(zip(bars6, results_df['Time (s)'])):\n",
        "    ax6.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(results_df['Time (s)']) * 0.02,\n",
        "            f'{val:.3f}s', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "# ===== Plot 7: Radar Chart =====\n",
        "ax7 = fig.add_subplot(gs[2, :], projection='polar')\n",
        "\n",
        "# Normalize metrics to [0, 1] for radar chart\n",
        "metrics_for_radar = ['Silhouette', 'ARI', 'NMI', 'Purity']\n",
        "angles = np.linspace(0, 2*np.pi, len(metrics_for_radar), endpoint=False).tolist()\n",
        "angles += angles[:1]\n",
        "\n",
        "for i, method in enumerate(methods):\n",
        "    values = results_df.loc[i, metrics_for_radar].tolist()\n",
        "    values += values[:1]\n",
        "    ax7.plot(angles, values, 'o-', linewidth=2, label=method, color=colors_method[i])\n",
        "    ax7.fill(angles, values, alpha=0.15, color=colors_method[i])\n",
        "\n",
        "ax7.set_xticks(angles[:-1])\n",
        "ax7.set_xticklabels(metrics_for_radar, fontsize=11)\n",
        "ax7.set_ylim(0, 1)\n",
        "ax7.set_title('Overall Performance Comparison\\n(All Metrics Normalized)',\n",
        "              fontsize=14, fontweight='bold', pad=20)\n",
        "ax7.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))\n",
        "ax7.grid(True)\n",
        "\n",
        "plt.suptitle('VAE vs Baseline (PCA + K-Means) Comparison',\n",
        "             fontsize=16, fontweight='bold', y=0.98)\n",
        "\n",
        "# Save figure\n",
        "save_path = os.path.join(output_dir, 'vae_vs_baseline_comparison.png')\n",
        "plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "print(f\" Saved visualization: {save_path}\")\n",
        "plt.show()\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 7: DETAILED ANALYSIS\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"7. Detailed Analysis\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\n BEST PERFORMERS:\")\n",
        "print(f\"   Best Silhouette Score: {results_df.loc[results_df['Silhouette'].idxmax(), 'Method']} \"\n",
        "      f\"({results_df['Silhouette'].max():.4f})\")\n",
        "print(f\"   Best Calinski-Harabasz: {results_df.loc[results_df['Calinski-Harabasz'].idxmax(), 'Method']} \"\n",
        "      f\"({results_df['Calinski-Harabasz'].max():.2f})\")\n",
        "print(f\"   Best Davies-Bouldin: {results_df.loc[results_df['Davies-Bouldin'].idxmin(), 'Method']} \"\n",
        "      f\"({results_df['Davies-Bouldin'].min():.4f})\")\n",
        "print(f\"   Best ARI: {results_df.loc[results_df['ARI'].idxmax(), 'Method']} \"\n",
        "      f\"({results_df['ARI'].max():.4f})\")\n",
        "print(f\"   Best Purity: {results_df.loc[results_df['Purity'].idxmax(), 'Method']} \"\n",
        "      f\"({results_df['Purity'].max():.4f})\")\n",
        "print(f\"   Fastest: {results_df.loc[results_df['Time (s)'].idxmin(), 'Method']} \"\n",
        "      f\"({results_df['Time (s)'].min():.3f}s)\")\n",
        "\n",
        "print(\"\\n IMPROVEMENT ANALYSIS:\")\n",
        "# Compare VAE vs PCA\n",
        "vae_idx = 0\n",
        "pca_idx = 1\n",
        "\n",
        "sil_improvement = ((results_df.loc[vae_idx, 'Silhouette'] - results_df.loc[pca_idx, 'Silhouette'])\n",
        "                   / results_df.loc[pca_idx, 'Silhouette'] * 100)\n",
        "ch_improvement = ((results_df.loc[vae_idx, 'Calinski-Harabasz'] - results_df.loc[pca_idx, 'Calinski-Harabasz'])\n",
        "                  / results_df.loc[pca_idx, 'Calinski-Harabasz'] * 100)\n",
        "ari_improvement = ((results_df.loc[vae_idx, 'ARI'] - results_df.loc[pca_idx, 'ARI'])\n",
        "                   / abs(results_df.loc[pca_idx, 'ARI']) * 100 if results_df.loc[pca_idx, 'ARI'] != 0 else 0)\n",
        "\n",
        "print(f\"   VAE vs PCA Silhouette: {sil_improvement:+.1f}%\")\n",
        "print(f\"   VAE vs PCA Calinski-Harabasz: {ch_improvement:+.1f}%\")\n",
        "print(f\"   VAE vs PCA ARI: {ari_improvement:+.1f}%\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\" COMPARISON COMPLETE!\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nResults saved to: {output_dir}\")\n",
        "print(f\"   vae_vs_baseline_comparison.csv\")\n",
        "print(f\"   vae_vs_baseline_comparison.png\")"
      ],
      "metadata": {
        "id": "apHKLROjS4bF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Medium"
      ],
      "metadata": {
        "id": "gWc2aXuESG_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================================\n",
        "# ENHANCED CONVOLUTIONAL VAE FOR AUDIO SPECTROGRAMS\n",
        "# Advanced architecture with skip connections, batch normalization, and dropout\n",
        "# Supports both Mel Spectrograms and MFCC features\n",
        "# ================================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import librosa\n",
        "import librosa.display\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"ENHANCED CONVOLUTIONAL VAE FOR AUDIO FEATURES\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 1: SETUP AND CONFIGURATION\n",
        "# ============================================================================\n",
        "\n",
        "# Configuration\n",
        "class Config:\n",
        "    # Data parameters\n",
        "    SAMPLE_RATE = 22050\n",
        "    DURATION = 3.0  # seconds\n",
        "    N_MELS = 128\n",
        "    N_FFT = 2048\n",
        "    HOP_LENGTH = 512\n",
        "\n",
        "    # Model parameters\n",
        "    LATENT_DIM = 64\n",
        "    BATCH_SIZE = 16\n",
        "    NUM_EPOCHS = 50\n",
        "    LEARNING_RATE = 1e-3\n",
        "    BETA = 1.0  # KL divergence weight\n",
        "\n",
        "    # Training parameters\n",
        "    USE_CUDA = torch.cuda.is_available()\n",
        "    DEVICE = torch.device('cuda' if USE_CUDA else 'cpu')\n",
        "\n",
        "    # Feature type: 'melspectrogram' or 'mfcc'\n",
        "    FEATURE_TYPE = 'melspectrogram'  # Change to 'mfcc' if desired\n",
        "\n",
        "config = Config()\n",
        "\n",
        "print(f\"\\nConfiguration:\")\n",
        "print(f\"  Device: {config.DEVICE}\")\n",
        "print(f\"  Feature Type: {config.FEATURE_TYPE}\")\n",
        "print(f\"  Latent Dimension: {config.LATENT_DIM}\")\n",
        "print(f\"  Input Shape: (1, {config.N_MELS}, 128)\")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 2: ENHANCED CONVOLUTIONAL VAE MODEL\n",
        "# ============================================================================\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    \"\"\"Residual block with skip connection\"\"\"\n",
        "    def __init__(self, channels):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(channels)\n",
        "        self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = self.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class EnhancedConvVAE(nn.Module):\n",
        "    \"\"\"\n",
        "    Enhanced Convolutional VAE with:\n",
        "    - Residual connections\n",
        "    - Batch normalization\n",
        "    - Dropout for regularization\n",
        "    - Skip connections between encoder and decoder\n",
        "    \"\"\"\n",
        "    def __init__(self, latent_dim=64, input_channels=1):\n",
        "        super(EnhancedConvVAE, self).__init__()\n",
        "\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "        # ========== ENCODER ==========\n",
        "        # Input: (batch, 1, 128, 128)\n",
        "\n",
        "        # Block 1: (1, 128, 128) -> (32, 64, 64)\n",
        "        self.enc_conv1 = nn.Sequential(\n",
        "            nn.Conv2d(input_channels, 32, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout2d(0.1)\n",
        "        )\n",
        "        self.enc_res1 = ResidualBlock(32)\n",
        "\n",
        "        # Block 2: (32, 64, 64) -> (64, 32, 32)\n",
        "        self.enc_conv2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout2d(0.1)\n",
        "        )\n",
        "        self.enc_res2 = ResidualBlock(64)\n",
        "\n",
        "        # Block 3: (64, 32, 32) -> (128, 16, 16)\n",
        "        self.enc_conv3 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout2d(0.1)\n",
        "        )\n",
        "        self.enc_res3 = ResidualBlock(128)\n",
        "\n",
        "        # Block 4: (128, 16, 16) -> (256, 8, 8)\n",
        "        self.enc_conv4 = nn.Sequential(\n",
        "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout2d(0.1)\n",
        "        )\n",
        "        self.enc_res4 = ResidualBlock(256)\n",
        "\n",
        "        # Block 5: (256, 8, 8) -> (512, 4, 4)\n",
        "        self.enc_conv5 = nn.Sequential(\n",
        "            nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # Flatten size: 512 * 4 * 4 = 8192\n",
        "        self.flatten_size = 512 * 4 * 4\n",
        "\n",
        "        # Latent space\n",
        "        self.fc_mu = nn.Linear(self.flatten_size, latent_dim)\n",
        "        self.fc_logvar = nn.Linear(self.flatten_size, latent_dim)\n",
        "\n",
        "        # ========== DECODER ==========\n",
        "        self.decoder_fc = nn.Linear(latent_dim, self.flatten_size)\n",
        "\n",
        "        # Block 1: (512, 4, 4) -> (256, 8, 8)\n",
        "        self.dec_conv1 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout2d(0.1)\n",
        "        )\n",
        "        self.dec_res1 = ResidualBlock(256)\n",
        "\n",
        "        # Block 2: (256, 8, 8) -> (128, 16, 16)\n",
        "        self.dec_conv2 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout2d(0.1)\n",
        "        )\n",
        "        self.dec_res2 = ResidualBlock(128)\n",
        "\n",
        "        # Block 3: (128, 16, 16) -> (64, 32, 32)\n",
        "        self.dec_conv3 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout2d(0.1)\n",
        "        )\n",
        "        self.dec_res3 = ResidualBlock(64)\n",
        "\n",
        "        # Block 4: (64, 32, 32) -> (32, 64, 64)\n",
        "        self.dec_conv4 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout2d(0.1)\n",
        "        )\n",
        "        self.dec_res4 = ResidualBlock(32)\n",
        "\n",
        "        # Block 5: (32, 64, 64) -> (1, 128, 128)\n",
        "        self.dec_conv5 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(32, input_channels, kernel_size=4, stride=2, padding=1),\n",
        "            nn.Sigmoid()  # Output in [0, 1]\n",
        "        )\n",
        "\n",
        "    def encode(self, x):\n",
        "        # Encoder with skip connections\n",
        "        h1 = self.enc_conv1(x)\n",
        "        h1 = self.enc_res1(h1)\n",
        "\n",
        "        h2 = self.enc_conv2(h1)\n",
        "        h2 = self.enc_res2(h2)\n",
        "\n",
        "        h3 = self.enc_conv3(h2)\n",
        "        h3 = self.enc_res3(h3)\n",
        "\n",
        "        h4 = self.enc_conv4(h3)\n",
        "        h4 = self.enc_res4(h4)\n",
        "\n",
        "        h5 = self.enc_conv5(h4)\n",
        "\n",
        "        # Flatten\n",
        "        h = h5.view(h5.size(0), -1)\n",
        "\n",
        "        # Latent parameters\n",
        "        mu = self.fc_mu(h)\n",
        "        logvar = self.fc_logvar(h)\n",
        "\n",
        "        return mu, logvar\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def decode(self, z):\n",
        "        h = self.decoder_fc(z)\n",
        "        h = h.view(h.size(0), 512, 4, 4)\n",
        "\n",
        "        h = self.dec_conv1(h)\n",
        "        h = self.dec_res1(h)\n",
        "\n",
        "        h = self.dec_conv2(h)\n",
        "        h = self.dec_res2(h)\n",
        "\n",
        "        h = self.dec_conv3(h)\n",
        "        h = self.dec_res3(h)\n",
        "\n",
        "        h = self.dec_conv4(h)\n",
        "        h = self.dec_res4(h)\n",
        "\n",
        "        h = self.dec_conv5(h)\n",
        "\n",
        "        return h\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        recon = self.decode(z)\n",
        "        return recon, mu, logvar\n",
        "\n",
        "\n",
        "# Loss function with beta parameter\n",
        "def vae_loss(recon_x, x, mu, logvar, beta=1.0):\n",
        "    \"\"\"\n",
        "    VAE loss = Reconstruction loss + beta * KL divergence\n",
        "    \"\"\"\n",
        "    # Reconstruction loss (MSE)\n",
        "    recon_loss = nn.functional.mse_loss(recon_x, x, reduction='sum')\n",
        "\n",
        "    # KL divergence\n",
        "    kld = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "\n",
        "    return recon_loss + beta * kld, recon_loss, kld\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 3: ENHANCED AUDIO DATASET\n",
        "# ============================================================================\n",
        "\n",
        "class AudioSpectrogramDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset for loading audio and converting to spectrograms/MFCC\n",
        "    \"\"\"\n",
        "    def __init__(self, audio_paths, labels, config, feature_type='melspectrogram'):\n",
        "        self.audio_paths = audio_paths\n",
        "        self.labels = labels\n",
        "        self.config = config\n",
        "        self.feature_type = feature_type\n",
        "        self.target_shape = (128, 128)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.audio_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        audio_path = self.audio_paths[idx]\n",
        "\n",
        "        try:\n",
        "            # Load audio\n",
        "            y, sr = librosa.load(audio_path,\n",
        "                                duration=self.config.DURATION,\n",
        "                                sr=self.config.SAMPLE_RATE)\n",
        "\n",
        "            # Generate features based on type\n",
        "            if self.feature_type == 'melspectrogram':\n",
        "                # Mel Spectrogram\n",
        "                mel_spec = librosa.feature.melspectrogram(\n",
        "                    y=y,\n",
        "                    sr=sr,\n",
        "                    n_mels=self.config.N_MELS,\n",
        "                    n_fft=self.config.N_FFT,\n",
        "                    hop_length=self.config.HOP_LENGTH\n",
        "                )\n",
        "                # Convert to dB scale\n",
        "                feature = librosa.power_to_db(mel_spec, ref=np.max)\n",
        "\n",
        "            elif self.feature_type == 'mfcc':\n",
        "                # MFCC\n",
        "                mfcc = librosa.feature.mfcc(\n",
        "                    y=y,\n",
        "                    sr=sr,\n",
        "                    n_mfcc=self.config.N_MELS\n",
        "                )\n",
        "                feature = mfcc\n",
        "\n",
        "            # Normalize to [0, 1]\n",
        "            feature = (feature - feature.min()) / (feature.max() - feature.min() + 1e-8)\n",
        "\n",
        "            # Resize/pad to target shape\n",
        "            if feature.shape[1] < self.target_shape[1]:\n",
        "                pad_width = self.target_shape[1] - feature.shape[1]\n",
        "                feature = np.pad(feature, ((0, 0), (0, pad_width)), mode='constant')\n",
        "            else:\n",
        "                feature = feature[:, :self.target_shape[1]]\n",
        "\n",
        "            # Ensure correct height\n",
        "            if feature.shape[0] < self.target_shape[0]:\n",
        "                pad_height = self.target_shape[0] - feature.shape[0]\n",
        "                feature = np.pad(feature, ((0, pad_height), (0, 0)), mode='constant')\n",
        "            else:\n",
        "                feature = feature[:self.target_shape[0], :]\n",
        "\n",
        "            # Add channel dimension: (1, H, W)\n",
        "            feature = feature.reshape(1, *feature.shape)\n",
        "\n",
        "            return torch.FloatTensor(feature), self.labels[idx]\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {audio_path}: {e}\")\n",
        "            # Return zero tensor on error\n",
        "            return torch.zeros(1, *self.target_shape), self.labels[idx]\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 4: DATA LOADING\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"LOADING AUDIO DATA\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Find dataset\n",
        "dataset_root = os.path.join(extract_to, 'MyDataset')\n",
        "audio_root = os.path.join(dataset_root, 'audio')\n",
        "\n",
        "# Load metadata\n",
        "metadata_path = None\n",
        "for file in os.listdir(dataset_root):\n",
        "    if file.endswith('.csv') or file.endswith('.xlsx'):\n",
        "        metadata_path = os.path.join(dataset_root, file)\n",
        "        break\n",
        "\n",
        "if metadata_path and metadata_path.endswith('.xlsx'):\n",
        "    metadata = pd.read_excel(metadata_path)\n",
        "else:\n",
        "    metadata = pd.read_csv(metadata_path) if metadata_path else None\n",
        "\n",
        "print(f\" Dataset root: {dataset_root}\")\n",
        "print(f\" Audio folder: {audio_root}\")\n",
        "\n",
        "# Collect audio files\n",
        "audio_files = []\n",
        "labels = []\n",
        "filenames = []\n",
        "\n",
        "for lang_folder in ['bangla', 'english']:\n",
        "    lang_path = os.path.join(audio_root, lang_folder)\n",
        "\n",
        "    if not os.path.exists(lang_path):\n",
        "        print(f\"Warning: {lang_path} not found\")\n",
        "        continue\n",
        "\n",
        "    files = [f for f in os.listdir(lang_path) if f.endswith(('.mp3', '.wav', '.flac'))]\n",
        "\n",
        "    # Use up to 100 files per language\n",
        "    for file in files[:100]:\n",
        "        full_path = os.path.join(lang_path, file)\n",
        "        audio_files.append(full_path)\n",
        "        labels.append(0 if lang_folder == 'bangla' else 1)\n",
        "        filenames.append(f\"{lang_folder}/{file}\")\n",
        "\n",
        "    print(f\"   {lang_folder.capitalize()}: {len(files)} files found, using first 100\")\n",
        "\n",
        "print(f\"\\nTotal audio files: {len(audio_files)}\")\n",
        "print(f\"  Bangla: {sum([1 for l in labels if l == 0])}\")\n",
        "print(f\"  English: {sum([1 for l in labels if l == 1])}\")\n",
        "\n",
        "# Create dataset and dataloader\n",
        "dataset = AudioSpectrogramDataset(audio_files, labels, config,\n",
        "                                  feature_type=config.FEATURE_TYPE)\n",
        "train_loader = DataLoader(dataset, batch_size=config.BATCH_SIZE,\n",
        "                          shuffle=True, num_workers=2)\n",
        "\n",
        "print(f\"\\nDataLoader created:\")\n",
        "print(f\"  Batch size: {config.BATCH_SIZE}\")\n",
        "print(f\"  Number of batches: {len(train_loader)}\")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 5: MODEL INITIALIZATION\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"INITIALIZING MODEL\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "model = EnhancedConvVAE(latent_dim=config.LATENT_DIM).to(config.DEVICE)\n",
        "optimizer = optim.Adam(model.parameters(), lr=config.LEARNING_RATE)\n",
        "\n",
        "# Count parameters\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"\\nModel: Enhanced Convolutional VAE\")\n",
        "print(f\"  Total parameters: {total_params:,}\")\n",
        "print(f\"  Trainable parameters: {trainable_params:,}\")\n",
        "print(f\"  Device: {config.DEVICE}\")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 6: TRAINING\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"TRAINING\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "train_losses = []\n",
        "recon_losses = []\n",
        "kl_losses = []\n",
        "\n",
        "model.train()\n",
        "\n",
        "for epoch in range(config.NUM_EPOCHS):\n",
        "    epoch_loss = 0\n",
        "    epoch_recon = 0\n",
        "    epoch_kl = 0\n",
        "\n",
        "    for batch_idx, (data, _) in enumerate(train_loader):\n",
        "        data = data.to(config.DEVICE)\n",
        "\n",
        "        # Forward pass\n",
        "        optimizer.zero_grad()\n",
        "        recon, mu, logvar = model(data)\n",
        "        loss, recon_loss, kl_loss = vae_loss(recon, data, mu, logvar, beta=config.BETA)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_recon += recon_loss.item()\n",
        "        epoch_kl += kl_loss.item()\n",
        "\n",
        "    # Calculate average losses\n",
        "    avg_loss = epoch_loss / len(train_loader.dataset)\n",
        "    avg_recon = epoch_recon / len(train_loader.dataset)\n",
        "    avg_kl = epoch_kl / len(train_loader.dataset)\n",
        "\n",
        "    train_losses.append(avg_loss)\n",
        "    recon_losses.append(avg_recon)\n",
        "    kl_losses.append(avg_kl)\n",
        "\n",
        "    # Print progress\n",
        "    if (epoch + 1) % 5 == 0 or epoch == 0:\n",
        "        print(f\"Epoch [{epoch+1:3d}/{config.NUM_EPOCHS}] \"\n",
        "              f\"Loss: {avg_loss:.4f} | \"\n",
        "              f\"Recon: {avg_recon:.4f} | \"\n",
        "              f\"KL: {avg_kl:.4f}\")\n",
        "\n",
        "print(\"\\n Training complete!\")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 7: VISUALIZATION OF TRAINING\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"CREATING TRAINING VISUALIZATIONS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "output_dir = '/content/drive/MyDrive/clustering_results'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "# Plot 1: Total loss\n",
        "axes[0].plot(train_losses, linewidth=2, color='#e74c3c')\n",
        "axes[0].set_xlabel('Epoch', fontsize=12)\n",
        "axes[0].set_ylabel('Total Loss', fontsize=12)\n",
        "axes[0].set_title('Training Loss', fontsize=14, fontweight='bold')\n",
        "axes[0].grid(alpha=0.3)\n",
        "\n",
        "# Plot 2: Reconstruction loss\n",
        "axes[1].plot(recon_losses, linewidth=2, color='#3498db')\n",
        "axes[1].set_xlabel('Epoch', fontsize=12)\n",
        "axes[1].set_ylabel('Reconstruction Loss', fontsize=12)\n",
        "axes[1].set_title('Reconstruction Loss', fontsize=14, fontweight='bold')\n",
        "axes[1].grid(alpha=0.3)\n",
        "\n",
        "# Plot 3: KL divergence\n",
        "axes[2].plot(kl_losses, linewidth=2, color='#2ecc71')\n",
        "axes[2].set_xlabel('Epoch', fontsize=12)\n",
        "axes[2].set_ylabel('KL Divergence', fontsize=12)\n",
        "axes[2].set_title('KL Divergence', fontsize=14, fontweight='bold')\n",
        "axes[2].grid(alpha=0.3)\n",
        "\n",
        "plt.suptitle('Enhanced Convolutional VAE Training Progress',\n",
        "             fontsize=16, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "\n",
        "save_path = os.path.join(output_dir, 'enhanced_conv_vae_training.png')\n",
        "plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "print(f\" Saved training plot: {save_path}\")\n",
        "plt.show()\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 8: EXTRACT LATENT FEATURES\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"EXTRACTING LATENT FEATURES\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "model.eval()\n",
        "latent_features = []\n",
        "true_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data, label in dataset:\n",
        "        data = data.unsqueeze(0).to(config.DEVICE)\n",
        "        mu, _ = model.encode(data)\n",
        "        latent_features.append(mu.cpu().numpy().flatten())\n",
        "        true_labels.append(label)\n",
        "\n",
        "latent_features = np.array(latent_features)\n",
        "\n",
        "print(f\" Extracted latent features: {latent_features.shape}\")\n",
        "\n",
        "# Create dataframe\n",
        "features_df = pd.DataFrame(\n",
        "    latent_features,\n",
        "    columns=[f'feature_{i}' for i in range(latent_features.shape[1])]\n",
        ")\n",
        "\n",
        "features_df['filename'] = filenames\n",
        "features_df['language'] = ['bangla' if l == 0 else 'english' for l in true_labels]\n",
        "\n",
        "# Save features\n",
        "output_path = '/content/audio_enhanced_conv_vae_features.csv'\n",
        "features_df.to_csv(output_path, index=False)\n",
        "print(f\" Saved features: {output_path}\")\n",
        "print(f\"  Shape: {features_df.shape}\")\n",
        "print(\"\\nPreview:\")\n",
        "print(features_df.head())\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 9: VISUALIZATION OF RECONSTRUCTIONS\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"VISUALIZING RECONSTRUCTIONS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "model.eval()\n",
        "\n",
        "# Get a batch of samples\n",
        "sample_batch, sample_labels = next(iter(DataLoader(dataset, batch_size=8, shuffle=True)))\n",
        "sample_batch = sample_batch.to(config.DEVICE)\n",
        "\n",
        "with torch.no_grad():\n",
        "    reconstructions, _, _ = model(sample_batch)\n",
        "\n",
        "sample_batch = sample_batch.cpu().numpy()\n",
        "reconstructions = reconstructions.cpu().numpy()\n",
        "\n",
        "# Plot original vs reconstructed\n",
        "fig, axes = plt.subplots(4, 4, figsize=(16, 16))\n",
        "\n",
        "for i in range(4):\n",
        "    # Original\n",
        "    axes[i, 0].imshow(sample_batch[i, 0], aspect='auto', origin='lower', cmap='viridis')\n",
        "    axes[i, 0].set_title(f'Original {i+1}', fontweight='bold')\n",
        "    axes[i, 0].axis('off')\n",
        "\n",
        "    # Reconstructed\n",
        "    axes[i, 1].imshow(reconstructions[i, 0], aspect='auto', origin='lower', cmap='viridis')\n",
        "    axes[i, 1].set_title(f'Reconstructed {i+1}', fontweight='bold')\n",
        "    axes[i, 1].axis('off')\n",
        "\n",
        "    # Difference\n",
        "    diff = np.abs(sample_batch[i, 0] - reconstructions[i, 0])\n",
        "    im = axes[i, 2].imshow(diff, aspect='auto', origin='lower', cmap='hot')\n",
        "    axes[i, 2].set_title(f'Difference {i+1}', fontweight='bold')\n",
        "    axes[i, 2].axis('off')\n",
        "    plt.colorbar(im, ax=axes[i, 2], fraction=0.046)\n",
        "\n",
        "    # Next original\n",
        "    if i < 3:\n",
        "        axes[i, 3].imshow(sample_batch[i+4, 0], aspect='auto', origin='lower', cmap='viridis')\n",
        "        axes[i, 3].set_title(f'Original {i+5}', fontweight='bold')\n",
        "        axes[i, 3].axis('off')\n",
        "    else:\n",
        "        axes[i, 3].axis('off')\n",
        "\n",
        "plt.suptitle(f'Enhanced Conv VAE: Original vs Reconstructed {config.FEATURE_TYPE.capitalize()}s',\n",
        "             fontsize=16, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "\n",
        "save_path = os.path.join(output_dir, 'enhanced_conv_vae_reconstructions.png')\n",
        "plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "print(f\" Saved reconstructions: {save_path}\")\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\" ENHANCED CONVOLUTIONAL VAE COMPLETE!\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nFiles saved:\")\n",
        "print(f\"   audio_enhanced_conv_vae_features.csv\")\n",
        "print(f\"   enhanced_conv_vae_training.png\")\n",
        "print(f\"   enhanced_conv_vae_reconstructions.png\")\n",
        "print(f\"\\nAll files saved to: {output_dir}\")"
      ],
      "metadata": {
        "id": "HkCpyeQVSJZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================================\n",
        "# HYBRID VAE: AUDIO SPECTROGRAMS + LYRICS EMBEDDINGS\n",
        "# Multi-modal learning combining acoustic and semantic information\n",
        "# ================================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import librosa\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import subprocess\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"HYBRID VAE: AUDIO + LYRICS EMBEDDINGS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Install sentence-transformers\n",
        "print(\"\\nInstalling sentence-transformers...\")\n",
        "subprocess.run(['pip', 'install', 'sentence-transformers', '--break-system-packages'],\n",
        "               capture_output=True, check=True)\n",
        "print(\" Installation complete\")\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 1: CONFIGURATION\n",
        "# ============================================================================\n",
        "\n",
        "class HybridConfig:\n",
        "    # Audio parameters\n",
        "    SAMPLE_RATE = 22050\n",
        "    DURATION = 3.0\n",
        "    N_MELS = 128\n",
        "    N_FFT = 2048\n",
        "    HOP_LENGTH = 512\n",
        "\n",
        "    # Model parameters\n",
        "    AUDIO_LATENT_DIM = 32\n",
        "    TEXT_LATENT_DIM = 32\n",
        "    COMBINED_LATENT_DIM = 64  # Total latent dimension\n",
        "\n",
        "    # Training parameters\n",
        "    BATCH_SIZE = 16\n",
        "    NUM_EPOCHS = 50\n",
        "    LEARNING_RATE = 1e-3\n",
        "    BETA = 1.0\n",
        "\n",
        "    # Loss weights\n",
        "    AUDIO_RECON_WEIGHT = 1.0\n",
        "    TEXT_RECON_WEIGHT = 0.5\n",
        "\n",
        "    # Device\n",
        "    USE_CUDA = torch.cuda.is_available()\n",
        "    DEVICE = torch.device('cuda' if USE_CUDA else 'cpu')\n",
        "\n",
        "    # Text encoder model\n",
        "    TEXT_MODEL = 'all-MiniLM-L6-v2'  # 384-dim embeddings\n",
        "\n",
        "config = HybridConfig()\n",
        "\n",
        "print(f\"\\nConfiguration:\")\n",
        "print(f\"  Device: {config.DEVICE}\")\n",
        "print(f\"  Audio Latent Dim: {config.AUDIO_LATENT_DIM}\")\n",
        "print(f\"  Text Latent Dim: {config.TEXT_LATENT_DIM}\")\n",
        "print(f\"  Combined Latent Dim: {config.COMBINED_LATENT_DIM}\")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 2: HYBRID VAE MODEL\n",
        "# ============================================================================\n",
        "\n",
        "class HybridVAE(nn.Module):\n",
        "    \"\"\"\n",
        "    Hybrid VAE combining:\n",
        "    1. Audio branch (Convolutional) - processes mel spectrograms\n",
        "    2. Text branch (Fully connected) - processes lyrics embeddings\n",
        "    3. Shared latent space\n",
        "    \"\"\"\n",
        "    def __init__(self, config):\n",
        "        super(HybridVAE, self).__init__()\n",
        "\n",
        "        self.config = config\n",
        "        self.audio_latent_dim = config.AUDIO_LATENT_DIM\n",
        "        self.text_latent_dim = config.TEXT_LATENT_DIM\n",
        "        self.combined_latent_dim = config.COMBINED_LATENT_DIM\n",
        "\n",
        "        # Text embedding dimension (from sentence-transformers)\n",
        "        self.text_input_dim = 384\n",
        "\n",
        "        # ========== AUDIO ENCODER (Convolutional) ==========\n",
        "        self.audio_encoder = nn.Sequential(\n",
        "            # Input: (1, 128, 128)\n",
        "            nn.Conv2d(1, 32, kernel_size=4, stride=2, padding=1),  # (32, 64, 64)\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1),  # (64, 32, 32)\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),  # (128, 16, 16)\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),  # (256, 8, 8)\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.audio_flatten_size = 256 * 8 * 8\n",
        "        self.audio_fc_mu = nn.Linear(self.audio_flatten_size, self.audio_latent_dim)\n",
        "        self.audio_fc_logvar = nn.Linear(self.audio_flatten_size, self.audio_latent_dim)\n",
        "\n",
        "        # ========== TEXT ENCODER (Fully Connected) ==========\n",
        "        self.text_encoder = nn.Sequential(\n",
        "            nn.Linear(self.text_input_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "        )\n",
        "\n",
        "        self.text_fc_mu = nn.Linear(128, self.text_latent_dim)\n",
        "        self.text_fc_logvar = nn.Linear(128, self.text_latent_dim)\n",
        "\n",
        "        # ========== AUDIO DECODER ==========\n",
        "        self.audio_decoder_fc = nn.Linear(self.audio_latent_dim, self.audio_flatten_size)\n",
        "\n",
        "        self.audio_decoder = nn.Sequential(\n",
        "            # Input: (256, 8, 8)\n",
        "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),  # (128, 16, 16)\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),  # (64, 32, 32)\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),  # (32, 64, 64)\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.ConvTranspose2d(32, 1, kernel_size=4, stride=2, padding=1),  # (1, 128, 128)\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        # ========== TEXT DECODER ==========\n",
        "        self.text_decoder = nn.Sequential(\n",
        "            nn.Linear(self.text_latent_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Linear(128, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Linear(256, self.text_input_dim),\n",
        "        )\n",
        "\n",
        "    def encode_audio(self, x):\n",
        "        h = self.audio_encoder(x)\n",
        "        h = h.view(h.size(0), -1)\n",
        "        mu = self.audio_fc_mu(h)\n",
        "        logvar = self.audio_fc_logvar(h)\n",
        "        return mu, logvar\n",
        "\n",
        "    def encode_text(self, x):\n",
        "        h = self.text_encoder(x)\n",
        "        mu = self.text_fc_mu(h)\n",
        "        logvar = self.text_fc_logvar(h)\n",
        "        return mu, logvar\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def decode_audio(self, z):\n",
        "        h = self.audio_decoder_fc(z)\n",
        "        h = h.view(h.size(0), 256, 8, 8)\n",
        "        return self.audio_decoder(h)\n",
        "\n",
        "    def decode_text(self, z):\n",
        "        return self.text_decoder(z)\n",
        "\n",
        "    def forward(self, audio, text):\n",
        "        # Encode both modalities\n",
        "        audio_mu, audio_logvar = self.encode_audio(audio)\n",
        "        text_mu, text_logvar = self.encode_text(text)\n",
        "\n",
        "        # Sample from latent distributions\n",
        "        audio_z = self.reparameterize(audio_mu, audio_logvar)\n",
        "        text_z = self.reparameterize(text_mu, text_logvar)\n",
        "\n",
        "        # Combine latent representations\n",
        "        combined_z = torch.cat([audio_z, text_z], dim=1)\n",
        "\n",
        "        # Decode\n",
        "        audio_recon = self.decode_audio(audio_z)\n",
        "        text_recon = self.decode_text(text_z)\n",
        "\n",
        "        return (audio_recon, text_recon,\n",
        "                audio_mu, audio_logvar,\n",
        "                text_mu, text_logvar,\n",
        "                combined_z)\n",
        "\n",
        "\n",
        "def hybrid_vae_loss(audio_recon, audio, text_recon, text,\n",
        "                    audio_mu, audio_logvar, text_mu, text_logvar,\n",
        "                    audio_weight=1.0, text_weight=0.5, beta=1.0):\n",
        "    \"\"\"\n",
        "    Multi-modal VAE loss\n",
        "    \"\"\"\n",
        "    # Audio reconstruction loss\n",
        "    audio_recon_loss = nn.functional.mse_loss(audio_recon, audio, reduction='sum')\n",
        "\n",
        "    # Text reconstruction loss (cosine similarity)\n",
        "    text_recon_loss = nn.functional.mse_loss(text_recon, text, reduction='sum')\n",
        "\n",
        "    # KL divergence for audio\n",
        "    audio_kld = -0.5 * torch.sum(1 + audio_logvar - audio_mu.pow(2) - audio_logvar.exp())\n",
        "\n",
        "    # KL divergence for text\n",
        "    text_kld = -0.5 * torch.sum(1 + text_logvar - text_mu.pow(2) - text_logvar.exp())\n",
        "\n",
        "    # Combined loss\n",
        "    total_loss = (audio_weight * audio_recon_loss +\n",
        "                  text_weight * text_recon_loss +\n",
        "                  beta * (audio_kld + text_kld))\n",
        "\n",
        "    return total_loss, audio_recon_loss, text_recon_loss, audio_kld, text_kld\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 3: HYBRID DATASET\n",
        "# ============================================================================\n",
        "\n",
        "class HybridAudioTextDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset that loads both audio spectrograms and lyrics embeddings\n",
        "    \"\"\"\n",
        "    def __init__(self, audio_paths, lyrics, labels, config, text_encoder):\n",
        "        self.audio_paths = audio_paths\n",
        "        self.lyrics = lyrics\n",
        "        self.labels = labels\n",
        "        self.config = config\n",
        "        self.text_encoder = text_encoder\n",
        "        self.target_shape = (128, 128)\n",
        "\n",
        "        # Pre-compute text embeddings\n",
        "        print(\"  Encoding lyrics...\")\n",
        "        self.text_embeddings = self.text_encoder.encode(\n",
        "            lyrics,\n",
        "            show_progress_bar=True,\n",
        "            convert_to_numpy=True\n",
        "        )\n",
        "        print(f\"   Text embeddings shape: {self.text_embeddings.shape}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.audio_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        audio_path = self.audio_paths[idx]\n",
        "        text_embedding = self.text_embeddings[idx]\n",
        "\n",
        "        try:\n",
        "            # Load audio and create spectrogram\n",
        "            y, sr = librosa.load(audio_path,\n",
        "                                duration=self.config.DURATION,\n",
        "                                sr=self.config.SAMPLE_RATE)\n",
        "\n",
        "            mel_spec = librosa.feature.melspectrogram(\n",
        "                y=y, sr=sr,\n",
        "                n_mels=self.config.N_MELS,\n",
        "                n_fft=self.config.N_FFT,\n",
        "                hop_length=self.config.HOP_LENGTH\n",
        "            )\n",
        "\n",
        "            mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
        "            mel_spec_norm = (mel_spec_db - mel_spec_db.min()) / (mel_spec_db.max() - mel_spec_db.min() + 1e-8)\n",
        "\n",
        "            # Resize to target shape\n",
        "            if mel_spec_norm.shape[1] < self.target_shape[1]:\n",
        "                pad_width = self.target_shape[1] - mel_spec_norm.shape[1]\n",
        "                mel_spec_norm = np.pad(mel_spec_norm, ((0, 0), (0, pad_width)), mode='constant')\n",
        "            else:\n",
        "                mel_spec_norm = mel_spec_norm[:, :self.target_shape[1]]\n",
        "\n",
        "            mel_spec_norm = mel_spec_norm.reshape(1, *mel_spec_norm.shape)\n",
        "\n",
        "            return (torch.FloatTensor(mel_spec_norm),\n",
        "                    torch.FloatTensor(text_embedding),\n",
        "                    self.labels[idx])\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {audio_path}: {e}\")\n",
        "            return (torch.zeros(1, *self.target_shape),\n",
        "                    torch.FloatTensor(text_embedding),\n",
        "                    self.labels[idx])\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 4: DATA LOADING\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"LOADING DATA\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Find dataset\n",
        "dataset_root = os.path.join(extract_to, 'MyDataset')\n",
        "audio_root = os.path.join(dataset_root, 'audio')\n",
        "\n",
        "# Load metadata\n",
        "metadata_path = None\n",
        "for file in os.listdir(dataset_root):\n",
        "    if file.endswith('.csv') or file.endswith('.xlsx'):\n",
        "        metadata_path = os.path.join(dataset_root, file)\n",
        "        break\n",
        "\n",
        "if metadata_path is None:\n",
        "    raise FileNotFoundError(\"No metadata file found!\")\n",
        "\n",
        "print(f\"Loading metadata from: {os.path.basename(metadata_path)}\")\n",
        "\n",
        "if metadata_path.endswith('.xlsx'):\n",
        "    metadata = pd.read_excel(metadata_path)\n",
        "else:\n",
        "    metadata = pd.read_csv(metadata_path)\n",
        "\n",
        "print(f\" Metadata loaded: {metadata.shape}\")\n",
        "print(f\"  Columns: {metadata.columns.tolist()}\")\n",
        "\n",
        "# Check for lyrics column\n",
        "if 'lyrics' not in metadata.columns:\n",
        "    print(\"\\nWARNING: No 'lyrics' column found in metadata!\")\n",
        "    print(\"Creating dummy lyrics for demonstration...\")\n",
        "    metadata['lyrics'] = metadata.apply(\n",
        "        lambda row: f\"This is a {row['language']} song titled {row.get('song_title', 'unknown')} \"\n",
        "                   f\"by {row.get('singer', 'unknown artist')} in the {row.get('genre', 'unknown')} genre.\",\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "# Collect audio files and match with lyrics\n",
        "audio_files = []\n",
        "lyrics_list = []\n",
        "labels = []\n",
        "filenames = []\n",
        "\n",
        "# Create filename mapping\n",
        "metadata['base_filename'] = metadata['filenaming'].apply(lambda x: os.path.basename(x))\n",
        "filename_to_lyrics = dict(zip(metadata['base_filename'], metadata['lyrics']))\n",
        "filename_to_lang = dict(zip(metadata['base_filename'], metadata['language']))\n",
        "\n",
        "for lang_folder in ['bangla', 'english']:\n",
        "    lang_path = os.path.join(audio_root, lang_folder)\n",
        "\n",
        "    if not os.path.exists(lang_path):\n",
        "        print(f\"Warning: {lang_path} not found\")\n",
        "        continue\n",
        "\n",
        "    files = [f for f in os.listdir(lang_path) if f.endswith(('.mp3', '.wav', '.flac'))]\n",
        "\n",
        "    for file in files[:100]:  # Limit to 100 per language\n",
        "        full_path = os.path.join(lang_path, file)\n",
        "\n",
        "        # Get lyrics from metadata\n",
        "        lyrics = filename_to_lyrics.get(file, f\"Song in {lang_folder} language\")\n",
        "\n",
        "        # Handle missing or NaN lyrics\n",
        "        if pd.isna(lyrics) or lyrics == '':\n",
        "            lyrics = f\"A {lang_folder} song with no lyrics available\"\n",
        "\n",
        "        audio_files.append(full_path)\n",
        "        lyrics_list.append(str(lyrics))\n",
        "        labels.append(0 if lang_folder == 'bangla' else 1)\n",
        "        filenames.append(f\"{lang_folder}/{file}\")\n",
        "\n",
        "    print(f\"   {lang_folder.capitalize()}: {len(files)} files, using first 100\")\n",
        "\n",
        "print(f\"\\nTotal samples: {len(audio_files)}\")\n",
        "print(f\"  Bangla: {sum([1 for l in labels if l == 0])}\")\n",
        "print(f\"  English: {sum([1 for l in labels if l == 1])}\")\n",
        "\n",
        "# Initialize text encoder\n",
        "print(\"\\nInitializing text encoder...\")\n",
        "text_encoder = SentenceTransformer(config.TEXT_MODEL)\n",
        "print(f\" Text encoder loaded: {config.TEXT_MODEL}\")\n",
        "\n",
        "# Create dataset\n",
        "print(\"\\nCreating hybrid dataset...\")\n",
        "dataset = HybridAudioTextDataset(audio_files, lyrics_list, labels, config, text_encoder)\n",
        "train_loader = DataLoader(dataset, batch_size=config.BATCH_SIZE, shuffle=True)\n",
        "\n",
        "print(f\" Dataset created\")\n",
        "print(f\"  Batches: {len(train_loader)}\")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 5: MODEL INITIALIZATION\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"INITIALIZING HYBRID VAE\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "model = HybridVAE(config).to(config.DEVICE)\n",
        "optimizer = optim.Adam(model.parameters(), lr=config.LEARNING_RATE)\n",
        "\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"\\nModel: Hybrid VAE\")\n",
        "print(f\"  Total parameters: {total_params:,}\")\n",
        "print(f\"  Trainable parameters: {trainable_params:,}\")\n",
        "print(f\"  Device: {config.DEVICE}\")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 6: TRAINING\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"TRAINING\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "train_losses = []\n",
        "audio_recon_losses = []\n",
        "text_recon_losses = []\n",
        "audio_kl_losses = []\n",
        "text_kl_losses = []\n",
        "\n",
        "model.train()\n",
        "\n",
        "for epoch in range(config.NUM_EPOCHS):\n",
        "    epoch_loss = 0\n",
        "    epoch_audio_recon = 0\n",
        "    epoch_text_recon = 0\n",
        "    epoch_audio_kl = 0\n",
        "    epoch_text_kl = 0\n",
        "\n",
        "    for batch_idx, (audio, text, _) in enumerate(train_loader):\n",
        "        audio = audio.to(config.DEVICE)\n",
        "        text = text.to(config.DEVICE)\n",
        "\n",
        "        # Forward pass\n",
        "        optimizer.zero_grad()\n",
        "        (audio_recon, text_recon,\n",
        "         audio_mu, audio_logvar,\n",
        "         text_mu, text_logvar,\n",
        "         combined_z) = model(audio, text)\n",
        "\n",
        "        loss, a_recon, t_recon, a_kl, t_kl = hybrid_vae_loss(\n",
        "            audio_recon, audio, text_recon, text,\n",
        "            audio_mu, audio_logvar, text_mu, text_logvar,\n",
        "            audio_weight=config.AUDIO_RECON_WEIGHT,\n",
        "            text_weight=config.TEXT_RECON_WEIGHT,\n",
        "            beta=config.BETA\n",
        "        )\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_audio_recon += a_recon.item()\n",
        "        epoch_text_recon += t_recon.item()\n",
        "        epoch_audio_kl += a_kl.item()\n",
        "        epoch_text_kl += t_kl.item()\n",
        "\n",
        "    # Calculate averages\n",
        "    n_samples = len(train_loader.dataset)\n",
        "    avg_loss = epoch_loss / n_samples\n",
        "    avg_audio_recon = epoch_audio_recon / n_samples\n",
        "    avg_text_recon = epoch_text_recon / n_samples\n",
        "    avg_audio_kl = epoch_audio_kl / n_samples\n",
        "    avg_text_kl = epoch_text_kl / n_samples\n",
        "\n",
        "    train_losses.append(avg_loss)\n",
        "    audio_recon_losses.append(avg_audio_recon)\n",
        "    text_recon_losses.append(avg_text_recon)\n",
        "    audio_kl_losses.append(avg_audio_kl)\n",
        "    text_kl_losses.append(avg_text_kl)\n",
        "\n",
        "    if (epoch + 1) % 5 == 0 or epoch == 0:\n",
        "        print(f\"Epoch [{epoch+1:3d}/{config.NUM_EPOCHS}] \"\n",
        "              f\"Loss: {avg_loss:.4f} | \"\n",
        "              f\"Audio Recon: {avg_audio_recon:.4f} | \"\n",
        "              f\"Text Recon: {avg_text_recon:.4f} | \"\n",
        "              f\"Audio KL: {avg_audio_kl:.4f} | \"\n",
        "              f\"Text KL: {avg_text_kl:.4f}\")\n",
        "\n",
        "print(\"\\n Training complete!\")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 7: EXTRACT COMBINED LATENT FEATURES\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"EXTRACTING HYBRID LATENT FEATURES\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "model.eval()\n",
        "combined_features = []\n",
        "audio_features = []\n",
        "text_features = []\n",
        "true_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for audio, text, label in dataset:\n",
        "        audio = audio.unsqueeze(0).to(config.DEVICE)\n",
        "        text = text.unsqueeze(0).to(config.DEVICE)\n",
        "\n",
        "        # Get latent representations\n",
        "        audio_mu, _ = model.encode_audio(audio)\n",
        "        text_mu, _ = model.encode_text(text)\n",
        "        combined_z = torch.cat([audio_mu, text_mu], dim=1)\n",
        "\n",
        "        combined_features.append(combined_z.cpu().numpy().flatten())\n",
        "        audio_features.append(audio_mu.cpu().numpy().flatten())\n",
        "        text_features.append(text_mu.cpu().numpy().flatten())\n",
        "        true_labels.append(label)\n",
        "\n",
        "combined_features = np.array(combined_features)\n",
        "audio_features = np.array(audio_features)\n",
        "text_features = np.array(text_features)\n",
        "\n",
        "print(f\"  Extracted features:\")\n",
        "print(f\"  Combined: {combined_features.shape}\")\n",
        "print(f\"  Audio only: {audio_features.shape}\")\n",
        "print(f\"  Text only: {text_features.shape}\")\n",
        "\n",
        "# Create dataframes\n",
        "# Combined features\n",
        "combined_df = pd.DataFrame(\n",
        "    combined_features,\n",
        "    columns=[f'feature_{i}' for i in range(combined_features.shape[1])]\n",
        ")\n",
        "combined_df['filename'] = filenames\n",
        "combined_df['language'] = ['bangla' if l == 0 else 'english' for l in true_labels]\n",
        "\n",
        "# Audio-only features\n",
        "audio_df = pd.DataFrame(\n",
        "    audio_features,\n",
        "    columns=[f'feature_{i}' for i in range(audio_features.shape[1])]\n",
        ")\n",
        "audio_df['filename'] = filenames\n",
        "audio_df['language'] = ['bangla' if l == 0 else 'english' for l in true_labels]\n",
        "\n",
        "# Text-only features\n",
        "text_df = pd.DataFrame(\n",
        "    text_features,\n",
        "    columns=[f'feature_{i}' for i in range(text_features.shape[1])]\n",
        ")\n",
        "text_df['filename'] = filenames\n",
        "text_df['language'] = ['bangla' if l == 0 else 'english' for l in true_labels]\n",
        "\n",
        "# Save all versions\n",
        "output_dir = '/content/drive/MyDrive/clustering_results'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "combined_df.to_csv('/content/audio_hybrid_vae_features.csv', index=False)\n",
        "audio_df.to_csv('/content/audio_hybrid_vae_audio_only.csv', index=False)\n",
        "text_df.to_csv('/content/audio_hybrid_vae_text_only.csv', index=False)\n",
        "\n",
        "print(f\"\\n Saved features:\")\n",
        "print(f\"   audio_hybrid_vae_features.csv (combined)\")\n",
        "print(f\"   audio_hybrid_vae_audio_only.csv\")\n",
        "print(f\"   audio_hybrid_vae_text_only.csv\")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 8: TRAINING VISUALIZATION\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"CREATING VISUALIZATIONS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
        "\n",
        "# Total loss\n",
        "axes[0, 0].plot(train_losses, linewidth=2, color='#e74c3c')\n",
        "axes[0, 0].set_xlabel('Epoch')\n",
        "axes[0, 0].set_ylabel('Total Loss')\n",
        "axes[0, 0].set_title('Total Loss', fontweight='bold')\n",
        "axes[0, 0].grid(alpha=0.3)\n",
        "\n",
        "# Audio reconstruction\n",
        "axes[0, 1].plot(audio_recon_losses, linewidth=2, color='#3498db')\n",
        "axes[0, 1].set_xlabel('Epoch')\n",
        "axes[0, 1].set_ylabel('Audio Reconstruction Loss')\n",
        "axes[0, 1].set_title('Audio Reconstruction', fontweight='bold')\n",
        "axes[0, 1].grid(alpha=0.3)\n",
        "\n",
        "# Text reconstruction\n",
        "axes[0, 2].plot(text_recon_losses, linewidth=2, color='#2ecc71')\n",
        "axes[0, 2].set_xlabel('Epoch')\n",
        "axes[0, 2].set_ylabel('Text Reconstruction Loss')\n",
        "axes[0, 2].set_title('Text Reconstruction', fontweight='bold')\n",
        "axes[0, 2].grid(alpha=0.3)\n",
        "\n",
        "# Audio KL\n",
        "axes[1, 0].plot(audio_kl_losses, linewidth=2, color='#9b59b6')\n",
        "axes[1, 0].set_xlabel('Epoch')\n",
        "axes[1, 0].set_ylabel('Audio KL Divergence')\n",
        "axes[1, 0].set_title('Audio KL Divergence', fontweight='bold')\n",
        "axes[1, 0].grid(alpha=0.3)\n",
        "\n",
        "# Text KL\n",
        "axes[1, 1].plot(text_kl_losses, linewidth=2, color='#f39c12')\n",
        "axes[1, 1].set_xlabel('Epoch')\n",
        "axes[1, 1].set_ylabel('Text KL Divergence')\n",
        "axes[1, 1].set_title('Text KL Divergence', fontweight='bold')\n",
        "axes[1, 1].grid(alpha=0.3)\n",
        "\n",
        "# Combined losses\n",
        "axes[1, 2].plot(audio_recon_losses, label='Audio Recon', linewidth=2, color='#3498db')\n",
        "axes[1, 2].plot(text_recon_losses, label='Text Recon', linewidth=2, color='#2ecc71')\n",
        "axes[1, 2].set_xlabel('Epoch')\n",
        "axes[1, 2].set_ylabel('Loss')\n",
        "axes[1, 2].set_title('Reconstruction Comparison', fontweight='bold')\n",
        "axes[1, 2].legend()\n",
        "axes[1, 2].grid(alpha=0.3)\n",
        "\n",
        "plt.suptitle('Hybrid VAE Training Progress (Audio + Lyrics)',\n",
        "             fontsize=16, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "\n",
        "save_path = os.path.join(output_dir, 'hybrid_vae_training.png')\n",
        "plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "print(f\" Saved: {save_path}\")\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(f\"\\nFiles saved:\")\n",
        "print(f\"   audio_hybrid_vae_features.csv (64-dim combined)\")\n",
        "print(f\"   audio_hybrid_vae_audio_only.csv (32-dim)\")\n",
        "print(f\"   audio_hybrid_vae_text_only.csv (32-dim)\")\n",
        "print(f\"   hybrid_vae_training.png\")\n",
        "print(f\"\\nAll files in: {output_dir}\")"
      ],
      "metadata": {
        "id": "EnMVCmu5VLYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clustering Comparison: K-Means, Agglomerative, DBSCAN\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
        "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "import os\n",
        "\n",
        "# Create output directory\n",
        "output_dir = '/content/drive/MyDrive/clustering_results'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Load features (try hybrid first, fallback to basic)\n",
        "try:\n",
        "    features_df = pd.read_csv('/content/audio_hybrid_vae_features.csv')\n",
        "    print(\" Loaded HYBRID VAE features\")\n",
        "except:\n",
        "    try:\n",
        "        features_df = pd.read_csv('/content/audio_conv_vae_features.csv')\n",
        "        print(\" Loaded CONV VAE features\")\n",
        "    except:\n",
        "        features_df = pd.read_csv('/content/audio_vae_features.csv')\n",
        "        print(\" Loaded BASIC VAE features\")\n",
        "\n",
        "print(f\"Shape: {features_df.shape}\")\n",
        "print(f\"Columns: {features_df.columns.tolist()}\")\n",
        "\n",
        "# Get feature columns\n",
        "feature_cols = [col for col in features_df.columns if col.startswith('feature_')]\n",
        "X = features_df[feature_cols].values\n",
        "\n",
        "print(f\"\\nFeature matrix: {X.shape}\")\n",
        "\n",
        "# Standardize\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Ground truth labels (for evaluation)\n",
        "y_true = features_df['language'].map({'bangla': 0, 'english': 1}).values\n",
        "\n",
        "# ========== 1. K-MEANS CLUSTERING ==========\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"K-MEANS CLUSTERING\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Find optimal K\n",
        "print(\"\\nFinding optimal K...\")\n",
        "k_range = range(2, 11)\n",
        "kmeans_metrics = {'k': [], 'inertia': [], 'silhouette': [], 'davies_bouldin': [], 'calinski': []}\n",
        "\n",
        "for k in k_range:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "    labels = kmeans.fit_predict(X_scaled)\n",
        "\n",
        "    kmeans_metrics['k'].append(k)\n",
        "    kmeans_metrics['inertia'].append(kmeans.inertia_)\n",
        "    kmeans_metrics['silhouette'].append(silhouette_score(X_scaled, labels))\n",
        "    kmeans_metrics['davies_bouldin'].append(davies_bouldin_score(X_scaled, labels))\n",
        "    kmeans_metrics['calinski'].append(calinski_harabasz_score(X_scaled, labels))\n",
        "\n",
        "    print(f\"K={k}: Silhouette={kmeans_metrics['silhouette'][-1]:.3f}, DB={kmeans_metrics['davies_bouldin'][-1]:.3f}\")\n",
        "\n",
        "# Best K-Means (K=2)\n",
        "kmeans_best = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
        "kmeans_labels = kmeans_best.fit_predict(X_scaled)\n",
        "features_df['kmeans_cluster'] = kmeans_labels\n",
        "\n",
        "# ========== 2. AGGLOMERATIVE CLUSTERING ==========\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"AGGLOMERATIVE CLUSTERING\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Try different linkages\n",
        "linkages = ['ward', 'complete', 'average', 'single']\n",
        "agg_results = {}\n",
        "\n",
        "for linkage_method in linkages:\n",
        "    agg = AgglomerativeClustering(n_clusters=2, linkage=linkage_method)\n",
        "    labels = agg.fit_predict(X_scaled)\n",
        "\n",
        "    sil = silhouette_score(X_scaled, labels)\n",
        "    db = davies_bouldin_score(X_scaled, labels)\n",
        "\n",
        "    agg_results[linkage_method] = {\n",
        "        'labels': labels,\n",
        "        'silhouette': sil,\n",
        "        'davies_bouldin': db\n",
        "    }\n",
        "\n",
        "    print(f\"{linkage_method.capitalize()}: Silhouette={sil:.3f}, DB={db:.3f}\")\n",
        "\n",
        "# Use best linkage (ward)\n",
        "features_df['agg_cluster'] = agg_results['ward']['labels']\n",
        "\n",
        "# Create dendrogram\n",
        "print(\"\\nCreating dendrogram...\")\n",
        "plt.figure(figsize=(14, 7))\n",
        "linkage_matrix = linkage(X_scaled, method='ward')\n",
        "dendrogram(linkage_matrix, truncate_mode='lastp', p=30, leaf_font_size=10)\n",
        "plt.title('Agglomerative Clustering Dendrogram (Ward Linkage)', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('Sample Index or (Cluster Size)', fontsize=12)\n",
        "plt.ylabel('Distance', fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(output_dir, 'dendrogram.png'), dpi=300, bbox_inches='tight')\n",
        "print(\" Dendrogram saved\")\n",
        "plt.show()\n",
        "\n",
        "# ========== 3. DBSCAN ==========\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"DBSCAN CLUSTERING\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Try different epsilon values\n",
        "eps_range = [0.5, 1.0, 1.5, 2.0, 2.5, 3.0]\n",
        "dbscan_results = {}\n",
        "\n",
        "for eps in eps_range:\n",
        "    dbscan = DBSCAN(eps=eps, min_samples=5)\n",
        "    labels = dbscan.fit_predict(X_scaled)\n",
        "\n",
        "    n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
        "    n_noise = list(labels).count(-1)\n",
        "\n",
        "    # Only calculate metrics if we have valid clusters\n",
        "    if n_clusters > 1 and n_noise < len(labels) * 0.5:\n",
        "        valid_mask = labels != -1\n",
        "        if valid_mask.sum() > 1:\n",
        "            sil = silhouette_score(X_scaled[valid_mask], labels[valid_mask])\n",
        "        else:\n",
        "            sil = -1\n",
        "    else:\n",
        "        sil = -1\n",
        "\n",
        "    dbscan_results[eps] = {\n",
        "        'labels': labels,\n",
        "        'n_clusters': n_clusters,\n",
        "        'n_noise': n_noise,\n",
        "        'silhouette': sil\n",
        "    }\n",
        "\n",
        "    print(f\"eps={eps}: Clusters={n_clusters}, Noise={n_noise}, Silhouette={sil:.3f}\")\n",
        "\n",
        "# Use best eps (around 1.5-2.0)\n",
        "best_eps = 2.0\n",
        "features_df['dbscan_cluster'] = dbscan_results[best_eps]['labels']\n",
        "\n",
        "# ========== COMPARISON METRICS ==========\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"CLUSTERING COMPARISON\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "comparison_data = []\n",
        "\n",
        "# K-Means\n",
        "kmeans_sil = silhouette_score(X_scaled, kmeans_labels)\n",
        "kmeans_db = davies_bouldin_score(X_scaled, kmeans_labels)\n",
        "kmeans_ari = adjusted_rand_score(y_true, kmeans_labels)\n",
        "kmeans_nmi = normalized_mutual_info_score(y_true, kmeans_labels)\n",
        "\n",
        "comparison_data.append({\n",
        "    'Algorithm': 'K-Means',\n",
        "    'Silhouette': kmeans_sil,\n",
        "    'Davies-Bouldin': kmeans_db,\n",
        "    'ARI': kmeans_ari,\n",
        "    'NMI': kmeans_nmi,\n",
        "    'N_Clusters': 2\n",
        "})\n",
        "\n",
        "# Agglomerative\n",
        "agg_labels = features_df['agg_cluster'].values\n",
        "agg_sil = silhouette_score(X_scaled, agg_labels)\n",
        "agg_db = davies_bouldin_score(X_scaled, agg_labels)\n",
        "agg_ari = adjusted_rand_score(y_true, agg_labels)\n",
        "agg_nmi = normalized_mutual_info_score(y_true, agg_labels)\n",
        "\n",
        "comparison_data.append({\n",
        "    'Algorithm': 'Agglomerative',\n",
        "    'Silhouette': agg_sil,\n",
        "    'Davies-Bouldin': agg_db,\n",
        "    'ARI': agg_ari,\n",
        "    'NMI': agg_nmi,\n",
        "    'N_Clusters': 2\n",
        "})\n",
        "\n",
        "# DBSCAN\n",
        "dbscan_labels = features_df['dbscan_cluster'].values\n",
        "valid_mask = dbscan_labels != -1\n",
        "if valid_mask.sum() > 1:\n",
        "    dbscan_sil = silhouette_score(X_scaled[valid_mask], dbscan_labels[valid_mask])\n",
        "    dbscan_db = davies_bouldin_score(X_scaled[valid_mask], dbscan_labels[valid_mask])\n",
        "else:\n",
        "    dbscan_sil = -1\n",
        "    dbscan_db = -1\n",
        "\n",
        "dbscan_ari = adjusted_rand_score(y_true, dbscan_labels)\n",
        "dbscan_nmi = normalized_mutual_info_score(y_true, dbscan_labels)\n",
        "\n",
        "comparison_data.append({\n",
        "    'Algorithm': 'DBSCAN',\n",
        "    'Silhouette': dbscan_sil,\n",
        "    'Davies-Bouldin': dbscan_db,\n",
        "    'ARI': dbscan_ari,\n",
        "    'NMI': dbscan_nmi,\n",
        "    'N_Clusters': dbscan_results[best_eps]['n_clusters']\n",
        "})\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_data)\n",
        "print(\"\\n\", comparison_df)\n",
        "\n",
        "# ========== VISUALIZATIONS ==========\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"CREATING VISUALIZATIONS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# 1. Elbow curve and metrics for K-Means\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "ax1 = axes[0, 0]\n",
        "ax1.plot(kmeans_metrics['k'], kmeans_metrics['inertia'], 'bo-', linewidth=2)\n",
        "ax1.set_xlabel('Number of Clusters (K)', fontsize=12)\n",
        "ax1.set_ylabel('Inertia', fontsize=12)\n",
        "ax1.set_title('K-Means Elbow Curve', fontsize=14, fontweight='bold')\n",
        "ax1.grid(alpha=0.3)\n",
        "\n",
        "ax2 = axes[0, 1]\n",
        "ax2.plot(kmeans_metrics['k'], kmeans_metrics['silhouette'], 'ro-', linewidth=2)\n",
        "ax2.set_xlabel('Number of Clusters (K)', fontsize=12)\n",
        "ax2.set_ylabel('Silhouette Score', fontsize=12)\n",
        "ax2.set_title('K-Means Silhouette Score', fontsize=14, fontweight='bold')\n",
        "ax2.grid(alpha=0.3)\n",
        "\n",
        "ax3 = axes[1, 0]\n",
        "ax3.plot(kmeans_metrics['k'], kmeans_metrics['davies_bouldin'], 'go-', linewidth=2)\n",
        "ax3.set_xlabel('Number of Clusters (K)', fontsize=12)\n",
        "ax3.set_ylabel('Davies-Bouldin Index', fontsize=12)\n",
        "ax3.set_title('K-Means Davies-Bouldin Index', fontsize=14, fontweight='bold')\n",
        "ax3.grid(alpha=0.3)\n",
        "\n",
        "ax4 = axes[1, 1]\n",
        "ax4.plot(kmeans_metrics['k'], kmeans_metrics['calinski'], 'mo-', linewidth=2)\n",
        "ax4.set_xlabel('Number of Clusters (K)', fontsize=12)\n",
        "ax4.set_ylabel('Calinski-Harabasz Score', fontsize=12)\n",
        "ax4.set_title('K-Means Calinski-Harabasz Score', fontsize=14, fontweight='bold')\n",
        "ax4.grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(output_dir, 'kmeans_metrics.png'), dpi=300, bbox_inches='tight')\n",
        "print(\" K-Means metrics saved\")\n",
        "plt.show()\n",
        "\n",
        "# 2. Algorithm comparison bar charts\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "metrics = ['Silhouette', 'Davies-Bouldin', 'ARI', 'NMI']\n",
        "colors = ['#3498db', '#e74c3c', '#2ecc71']\n",
        "\n",
        "for idx, metric in enumerate(metrics):\n",
        "    ax = axes[idx // 2, idx % 2]\n",
        "    values = comparison_df[metric].values\n",
        "    bars = ax.bar(comparison_df['Algorithm'], values, color=colors)\n",
        "    ax.set_ylabel(metric, fontsize=12)\n",
        "    ax.set_title(f'{metric} Comparison', fontsize=14, fontweight='bold')\n",
        "    ax.grid(axis='y', alpha=0.3)\n",
        "\n",
        "    # Add value labels on bars\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                f'{height:.3f}',\n",
        "                ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(output_dir, 'algorithm_comparison.png'), dpi=300, bbox_inches='tight')\n",
        "print(\" Algorithm comparison saved\")\n",
        "plt.show()\n",
        "\n",
        "# 3. Cluster distribution comparison\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "algorithms = ['kmeans_cluster', 'agg_cluster', 'dbscan_cluster']\n",
        "titles = ['K-Means', 'Agglomerative', 'DBSCAN']\n",
        "\n",
        "for idx, (alg, title) in enumerate(zip(algorithms, titles)):\n",
        "    ax = axes[idx]\n",
        "    crosstab = pd.crosstab(features_df['language'], features_df[alg], margins=True)\n",
        "\n",
        "    # Plot as heatmap\n",
        "    sns.heatmap(crosstab.iloc[:-1, :-1], annot=True, fmt='d', cmap='YlOrRd',\n",
        "                ax=ax, cbar_kws={'label': 'Count'})\n",
        "    ax.set_title(f'{title}\\nLanguage vs Cluster', fontsize=13, fontweight='bold')\n",
        "    ax.set_xlabel('Cluster', fontsize=11)\n",
        "    ax.set_ylabel('Language', fontsize=11)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(output_dir, 'cluster_distribution.png'), dpi=300, bbox_inches='tight')\n",
        "print(\" Cluster distribution saved\")\n",
        "plt.show()\n",
        "\n",
        "# 4. DBSCAN noise analysis\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "eps_vals = list(dbscan_results.keys())\n",
        "n_clusters_vals = [dbscan_results[eps]['n_clusters'] for eps in eps_vals]\n",
        "n_noise_vals = [dbscan_results[eps]['n_noise'] for eps in eps_vals]\n",
        "\n",
        "x = np.arange(len(eps_vals))\n",
        "width = 0.35\n",
        "\n",
        "bars1 = ax.bar(x - width/2, n_clusters_vals, width, label='N Clusters', color='#3498db')\n",
        "bars2 = ax.bar(x + width/2, n_noise_vals, width, label='N Noise Points', color='#e74c3c')\n",
        "\n",
        "ax.set_xlabel('Epsilon', fontsize=12)\n",
        "ax.set_ylabel('Count', fontsize=12)\n",
        "ax.set_title('DBSCAN: Clusters and Noise Points vs Epsilon', fontsize=14, fontweight='bold')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(eps_vals)\n",
        "ax.legend()\n",
        "ax.grid(axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(output_dir, 'dbscan_analysis.png'), dpi=300, bbox_inches='tight')\n",
        "print(\" DBSCAN analysis saved\")\n",
        "plt.show()\n",
        "\n",
        "# ========== SAVE RESULTS ==========\n",
        "# Save clustered features\n",
        "features_df.to_csv(os.path.join(output_dir, 'features_all_clusters.csv'), index=False)\n",
        "print(f\"\\n Saved features with all cluster labels\")\n",
        "\n",
        "# Save comparison metrics\n",
        "comparison_df.to_csv(os.path.join(output_dir, 'clustering_comparison.csv'), index=False)\n",
        "print(f\" Saved comparison metrics\")\n",
        "\n",
        "# Save detailed report\n",
        "report_path = os.path.join(output_dir, 'clustering_report.txt')\n",
        "with open(report_path, 'w') as f:\n",
        "    f.write(\"CLUSTERING ALGORITHMS COMPARISON REPORT\\n\")\n",
        "    f.write(\"=\"*60 + \"\\n\\n\")\n",
        "\n",
        "    f.write(\"Dataset Information:\\n\")\n",
        "    f.write(f\"Total samples: {len(features_df)}\\n\")\n",
        "    f.write(f\"Features: {len(feature_cols)}\\n\")\n",
        "    f.write(f\"Languages: Bangla={(y_true==0).sum()}, English={(y_true==1).sum()}\\n\\n\")\n",
        "\n",
        "    f.write(\"=\"*60 + \"\\n\")\n",
        "    f.write(\"CLUSTERING RESULTS\\n\")\n",
        "    f.write(\"=\"*60 + \"\\n\\n\")\n",
        "\n",
        "    f.write(comparison_df.to_string())\n",
        "    f.write(\"\\n\\n\")\n",
        "\n",
        "    f.write(\"=\"*60 + \"\\n\")\n",
        "    f.write(\"INTERPRETATION\\n\")\n",
        "    f.write(\"=\"*60 + \"\\n\\n\")\n",
        "\n",
        "    f.write(\"Silhouette Score: Higher is better (range: -1 to 1)\\n\")\n",
        "    f.write(\"Davies-Bouldin Index: Lower is better\\n\")\n",
        "    f.write(\"ARI (Adjusted Rand Index): Higher is better (range: -1 to 1)\\n\")\n",
        "    f.write(\"NMI (Normalized Mutual Information): Higher is better (range: 0 to 1)\\n\\n\")\n",
        "\n",
        "    f.write(\"Best Algorithm: \")\n",
        "    best_idx = comparison_df['Silhouette'].idxmax()\n",
        "    f.write(f\"{comparison_df.loc[best_idx, 'Algorithm']}\\n\")\n",
        "\n",
        "print(f\" Saved detailed report\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\" ALL CLUSTERING EXPERIMENTS COMPLETE!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nSaved to: {output_dir}\")"
      ],
      "metadata": {
        "id": "Xa9wH8yjV67e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clustering Quality Evaluation: Silhouette, Davies-Bouldin, ARI\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (\n",
        "    silhouette_score,\n",
        "    silhouette_samples,\n",
        "    davies_bouldin_score,\n",
        "    adjusted_rand_score,\n",
        "    normalized_mutual_info_score,\n",
        "    homogeneity_score,\n",
        "    completeness_score,\n",
        "    v_measure_score,\n",
        "    fowlkes_mallows_score,\n",
        "    confusion_matrix\n",
        ")\n",
        "import os\n",
        "\n",
        "# Create output directory\n",
        "output_dir = '/content/drive/MyDrive/clustering_results'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Load features (try hybrid first, fallback to others)\n",
        "try:\n",
        "    features_df = pd.read_csv('/content/audio_hybrid_vae_features.csv')\n",
        "    model_type = \"Hybrid VAE\"\n",
        "except:\n",
        "    try:\n",
        "        features_df = pd.read_csv('/content/audio_conv_vae_features.csv')\n",
        "        model_type = \"Conv VAE\"\n",
        "    except:\n",
        "        features_df = pd.read_csv('/content/audio_vae_features.csv')\n",
        "        model_type = \"Basic VAE\"\n",
        "\n",
        "print(f\" Loaded {model_type} features\")\n",
        "print(f\"Shape: {features_df.shape}\")\n",
        "\n",
        "# Get features and true labels\n",
        "feature_cols = [col for col in features_df.columns if col.startswith('feature_')]\n",
        "X = features_df[feature_cols].values\n",
        "y_true = features_df['language'].map({'bangla': 0, 'english': 1}).values\n",
        "\n",
        "print(f\"Features: {X.shape}\")\n",
        "print(f\"True labels: Bangla={np.sum(y_true==0)}, English={np.sum(y_true==1)}\")\n",
        "\n",
        "# Standardize\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# ========== CLUSTERING WITH K=2 ==========\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PERFORMING K-MEANS CLUSTERING (K=2)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
        "y_pred = kmeans.fit_predict(X_scaled)\n",
        "\n",
        "features_df['cluster'] = y_pred\n",
        "\n",
        "# ========== EVALUATION METRICS ==========\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"CLUSTERING QUALITY METRICS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# 1. Silhouette Score\n",
        "silhouette_avg = silhouette_score(X_scaled, y_pred)\n",
        "silhouette_samples_vals = silhouette_samples(X_scaled, y_pred)\n",
        "\n",
        "print(f\"\\n1. SILHOUETTE SCORE: {silhouette_avg:.4f}\")\n",
        "print(\"   Range: [-1, 1] | Higher is better\")\n",
        "print(\"   Measures how similar samples are to their own cluster vs other clusters\")\n",
        "print(f\"   Interpretation: \", end=\"\")\n",
        "if silhouette_avg > 0.7:\n",
        "    print(\"Excellent separation\")\n",
        "elif silhouette_avg > 0.5:\n",
        "    print(\"Good separation\")\n",
        "elif silhouette_avg > 0.3:\n",
        "    print(\"Moderate separation\")\n",
        "else:\n",
        "    print(\"Weak separation\")\n",
        "\n",
        "# Silhouette per cluster\n",
        "for i in range(2):\n",
        "    cluster_silhouette = silhouette_samples_vals[y_pred == i].mean()\n",
        "    print(f\"   Cluster {i}: {cluster_silhouette:.4f} (n={np.sum(y_pred==i)})\")\n",
        "\n",
        "# 2. Davies-Bouldin Index\n",
        "db_score = davies_bouldin_score(X_scaled, y_pred)\n",
        "\n",
        "print(f\"\\n2. DAVIES-BOULDIN INDEX: {db_score:.4f}\")\n",
        "print(\"   Range: [0, ] | Lower is better\")\n",
        "print(\"   Measures average similarity between each cluster and its most similar cluster\")\n",
        "print(f\"   Interpretation: \", end=\"\")\n",
        "if db_score < 0.5:\n",
        "    print(\"Excellent clustering\")\n",
        "elif db_score < 1.0:\n",
        "    print(\"Good clustering\")\n",
        "elif db_score < 2.0:\n",
        "    print(\"Moderate clustering\")\n",
        "else:\n",
        "    print(\"Poor clustering\")\n",
        "\n",
        "# 3. Adjusted Rand Index (with true labels)\n",
        "ari_score = adjusted_rand_score(y_true, y_pred)\n",
        "\n",
        "print(f\"\\n3. ADJUSTED RAND INDEX (ARI): {ari_score:.4f}\")\n",
        "print(\"   Range: [-1, 1] | Higher is better (1 = perfect match)\")\n",
        "print(\"   Measures similarity between true and predicted labels\")\n",
        "print(f\"   Interpretation: \", end=\"\")\n",
        "if ari_score > 0.9:\n",
        "    print(\"Excellent agreement\")\n",
        "elif ari_score > 0.7:\n",
        "    print(\"Good agreement\")\n",
        "elif ari_score > 0.5:\n",
        "    print(\"Moderate agreement\")\n",
        "elif ari_score > 0.3:\n",
        "    print(\"Weak agreement\")\n",
        "else:\n",
        "    print(\"Very weak agreement\")\n",
        "\n",
        "# 4. Additional Metrics with True Labels\n",
        "nmi_score = normalized_mutual_info_score(y_true, y_pred)\n",
        "homogeneity = homogeneity_score(y_true, y_pred)\n",
        "completeness = completeness_score(y_true, y_pred)\n",
        "v_measure = v_measure_score(y_true, y_pred)\n",
        "fmi_score = fowlkes_mallows_score(y_true, y_pred)\n",
        "\n",
        "print(f\"\\n4. ADDITIONAL METRICS (with true labels):\")\n",
        "print(f\"   Normalized Mutual Information (NMI): {nmi_score:.4f}\")\n",
        "print(f\"   Homogeneity: {homogeneity:.4f} (each cluster contains only one class)\")\n",
        "print(f\"   Completeness: {completeness:.4f} (all members of class in same cluster)\")\n",
        "print(f\"   V-Measure: {v_measure:.4f} (harmonic mean of homogeneity & completeness)\")\n",
        "print(f\"   Fowlkes-Mallows Index: {fmi_score:.4f}\")\n",
        "\n",
        "# ========== CONFUSION MATRIX ==========\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"CONFUSION MATRIX\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "print(\"\\nPredicted vs True:\")\n",
        "print(pd.DataFrame(cm,\n",
        "                   columns=['Cluster 0', 'Cluster 1'],\n",
        "                   index=['Bangla (True)', 'English (True)']))\n",
        "\n",
        "# Calculate purity\n",
        "purity = np.sum(np.amax(cm, axis=0)) / np.sum(cm)\n",
        "print(f\"\\nCluster Purity: {purity:.4f}\")\n",
        "print(f\"   (Percentage of correctly clustered samples)\")\n",
        "\n",
        "# ========== VISUALIZATIONS ==========\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"CREATING EVALUATION VISUALIZATIONS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# 1. Silhouette Analysis\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Silhouette plot\n",
        "y_lower = 10\n",
        "colors = ['#3498db', '#e74c3c']\n",
        "\n",
        "for i in range(2):\n",
        "    cluster_silhouette_vals = silhouette_samples_vals[y_pred == i]\n",
        "    cluster_silhouette_vals.sort()\n",
        "\n",
        "    size_cluster_i = cluster_silhouette_vals.shape[0]\n",
        "    y_upper = y_lower + size_cluster_i\n",
        "\n",
        "    ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
        "                      0, cluster_silhouette_vals,\n",
        "                      facecolor=colors[i], edgecolor=colors[i], alpha=0.7)\n",
        "\n",
        "    ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i), fontsize=12, fontweight='bold')\n",
        "    y_lower = y_upper + 10\n",
        "\n",
        "ax1.set_xlabel(\"Silhouette Coefficient\", fontsize=12)\n",
        "ax1.set_ylabel(\"Cluster\", fontsize=12)\n",
        "ax1.set_title(f'Silhouette Analysis (Score: {silhouette_avg:.3f})', fontsize=14, fontweight='bold')\n",
        "ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\", linewidth=2, label=f'Average: {silhouette_avg:.3f}')\n",
        "ax1.legend()\n",
        "ax1.set_yticks([])\n",
        "ax1.grid(alpha=0.3, axis='x')\n",
        "\n",
        "# Silhouette distribution\n",
        "for i in range(2):\n",
        "    cluster_silhouette_vals = silhouette_samples_vals[y_pred == i]\n",
        "    ax2.hist(cluster_silhouette_vals, bins=30, alpha=0.6,\n",
        "             label=f'Cluster {i}', color=colors[i], edgecolor='black')\n",
        "\n",
        "ax2.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\", linewidth=2, label=f'Average: {silhouette_avg:.3f}')\n",
        "ax2.set_xlabel(\"Silhouette Coefficient\", fontsize=12)\n",
        "ax2.set_ylabel(\"Frequency\", fontsize=12)\n",
        "ax2.set_title('Silhouette Score Distribution', fontsize=14, fontweight='bold')\n",
        "ax2.legend()\n",
        "ax2.grid(alpha=0.3, axis='y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(output_dir, 'silhouette_analysis.png'), dpi=300, bbox_inches='tight')\n",
        "print(\" Silhouette analysis saved\")\n",
        "plt.show()\n",
        "\n",
        "# 2. Metrics Summary Bar Chart\n",
        "fig, ax = plt.subplots(figsize=(12, 7))\n",
        "\n",
        "metrics_dict = {\n",
        "    'Silhouette\\nScore': silhouette_avg,\n",
        "    'ARI': ari_score,\n",
        "    'NMI': nmi_score,\n",
        "    'Homogeneity': homogeneity,\n",
        "    'Completeness': completeness,\n",
        "    'V-Measure': v_measure,\n",
        "    'FMI': fmi_score,\n",
        "    'Purity': purity\n",
        "}\n",
        "\n",
        "# Note: Davies-Bouldin is inverted for visualization (lower is better)\n",
        "# So we show 1/(1+DB) to make it comparable\n",
        "db_normalized = 1 / (1 + db_score)\n",
        "metrics_dict['DB Index\\n(normalized)'] = db_normalized\n",
        "\n",
        "names = list(metrics_dict.keys())\n",
        "values = list(metrics_dict.values())\n",
        "colors_list = plt.cm.viridis(np.linspace(0, 1, len(names)))\n",
        "\n",
        "bars = ax.bar(names, values, color=colors_list, edgecolor='black', linewidth=1.5)\n",
        "\n",
        "# Add value labels\n",
        "for bar, val in zip(bars, values):\n",
        "    height = bar.get_height()\n",
        "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
        "            f'{val:.3f}',\n",
        "            ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
        "\n",
        "ax.set_ylabel('Score', fontsize=13)\n",
        "ax.set_title(f'Clustering Quality Metrics Summary\\n({model_type})',\n",
        "             fontsize=15, fontweight='bold')\n",
        "ax.set_ylim([0, 1.1])\n",
        "ax.grid(axis='y', alpha=0.3)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(output_dir, 'metrics_summary.png'), dpi=300, bbox_inches='tight')\n",
        "print(\" Metrics summary saved\")\n",
        "plt.show()\n",
        "\n",
        "# 3. Confusion Matrix Heatmap\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Cluster 0', 'Cluster 1'],\n",
        "            yticklabels=['Bangla', 'English'],\n",
        "            cbar_kws={'label': 'Count'},\n",
        "            linewidths=2, linecolor='black',\n",
        "            ax=ax, annot_kws={'size': 16, 'weight': 'bold'})\n",
        "\n",
        "ax.set_xlabel('Predicted Cluster', fontsize=13)\n",
        "ax.set_ylabel('True Language', fontsize=13)\n",
        "ax.set_title(f'Confusion Matrix\\nPurity: {purity:.3f}, ARI: {ari_score:.3f}',\n",
        "             fontsize=15, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(output_dir, 'confusion_matrix_detailed.png'), dpi=300, bbox_inches='tight')\n",
        "print(\" Confusion matrix saved\")\n",
        "plt.show()\n",
        "\n",
        "# 4. Cluster Distribution by Language\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Stacked bar chart\n",
        "crosstab = pd.crosstab(features_df['language'], features_df['cluster'], normalize='index') * 100\n",
        "\n",
        "crosstab.plot(kind='bar', stacked=True, ax=axes[0],\n",
        "              color=['#3498db', '#e74c3c'],\n",
        "              edgecolor='black', linewidth=1.5)\n",
        "axes[0].set_xlabel('True Language', fontsize=12)\n",
        "axes[0].set_ylabel('Percentage', fontsize=12)\n",
        "axes[0].set_title('Cluster Distribution per Language\\n(Normalized)', fontsize=14, fontweight='bold')\n",
        "axes[0].legend(title='Cluster', labels=['Cluster 0', 'Cluster 1'])\n",
        "axes[0].set_xticklabels(['Bangla', 'English'], rotation=0)\n",
        "axes[0].grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Grouped bar chart\n",
        "crosstab_counts = pd.crosstab(features_df['language'], features_df['cluster'])\n",
        "crosstab_counts.plot(kind='bar', ax=axes[1],\n",
        "                     color=['#3498db', '#e74c3c'],\n",
        "                     edgecolor='black', linewidth=1.5)\n",
        "axes[1].set_xlabel('True Language', fontsize=12)\n",
        "axes[1].set_ylabel('Count', fontsize=12)\n",
        "axes[1].set_title('Cluster Distribution per Language\\n(Counts)', fontsize=14, fontweight='bold')\n",
        "axes[1].legend(title='Cluster', labels=['Cluster 0', 'Cluster 1'])\n",
        "axes[1].set_xticklabels(['Bangla', 'English'], rotation=0)\n",
        "axes[1].grid(axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(output_dir, 'cluster_distribution_detailed.png'), dpi=300, bbox_inches='tight')\n",
        "print(\" Cluster distribution saved\")\n",
        "plt.show()\n",
        "\n",
        "# ========== SAVE DETAILED REPORT ==========\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"SAVING DETAILED EVALUATION REPORT\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "report_path = os.path.join(output_dir, 'evaluation_report.txt')\n",
        "with open(report_path, 'w') as f:\n",
        "    f.write(\"=\"*70 + \"\\n\")\n",
        "    f.write(\"CLUSTERING QUALITY EVALUATION REPORT\\n\")\n",
        "    f.write(\"=\"*70 + \"\\n\\n\")\n",
        "\n",
        "    f.write(f\"Model: {model_type}\\n\")\n",
        "    f.write(f\"Total Samples: {len(features_df)}\\n\")\n",
        "    f.write(f\"Features: {len(feature_cols)}\\n\")\n",
        "    f.write(f\"Algorithm: K-Means (K=2)\\n\\n\")\n",
        "\n",
        "    f.write(\"=\"*70 + \"\\n\")\n",
        "    f.write(\"TRUE LABEL DISTRIBUTION\\n\")\n",
        "    f.write(\"=\"*70 + \"\\n\")\n",
        "    f.write(f\"Bangla: {np.sum(y_true==0)} ({np.sum(y_true==0)/len(y_true)*100:.1f}%)\\n\")\n",
        "    f.write(f\"English: {np.sum(y_true==1)} ({np.sum(y_true==1)/len(y_true)*100:.1f}%)\\n\\n\")\n",
        "\n",
        "    f.write(\"=\"*70 + \"\\n\")\n",
        "    f.write(\"CLUSTERING QUALITY METRICS\\n\")\n",
        "    f.write(\"=\"*70 + \"\\n\\n\")\n",
        "\n",
        "    f.write(\"1. INTERNAL METRICS (without true labels)\\n\")\n",
        "    f.write(\"-\" * 70 + \"\\n\")\n",
        "    f.write(f\"Silhouette Score:      {silhouette_avg:.4f}  (Higher is better, range: [-1, 1])\\n\")\n",
        "    f.write(f\"Davies-Bouldin Index:  {db_score:.4f}  (Lower is better, range: [0, ])\\n\\n\")\n",
        "\n",
        "    f.write(\"2. EXTERNAL METRICS (with true labels)\\n\")\n",
        "    f.write(\"-\" * 70 + \"\\n\")\n",
        "    f.write(f\"Adjusted Rand Index:           {ari_score:.4f}  (Higher is better, range: [-1, 1])\\n\")\n",
        "    f.write(f\"Normalized Mutual Info:        {nmi_score:.4f}  (Higher is better, range: [0, 1])\\n\")\n",
        "    f.write(f\"Homogeneity:                   {homogeneity:.4f}  (Higher is better, range: [0, 1])\\n\")\n",
        "    f.write(f\"Completeness:                  {completeness:.4f}  (Higher is better, range: [0, 1])\\n\")\n",
        "    f.write(f\"V-Measure:                     {v_measure:.4f}  (Higher is better, range: [0, 1])\\n\")\n",
        "    f.write(f\"Fowlkes-Mallows Index:         {fmi_score:.4f}  (Higher is better, range: [0, 1])\\n\")\n",
        "    f.write(f\"Purity:                        {purity:.4f}  (Higher is better, range: [0, 1])\\n\\n\")\n",
        "\n",
        "    f.write(\"=\"*70 + \"\\n\")\n",
        "    f.write(\"CONFUSION MATRIX\\n\")\n",
        "    f.write(\"=\"*70 + \"\\n\\n\")\n",
        "    f.write(\"              Cluster 0    Cluster 1\\n\")\n",
        "    f.write(f\"Bangla        {cm[0,0]:6d}       {cm[0,1]:6d}\\n\")\n",
        "    f.write(f\"English       {cm[1,0]:6d}       {cm[1,1]:6d}\\n\\n\")\n",
        "\n",
        "    f.write(\"=\"*70 + \"\\n\")\n",
        "    f.write(\"INTERPRETATION\\n\")\n",
        "    f.write(\"=\"*70 + \"\\n\\n\")\n",
        "\n",
        "    f.write(\"Silhouette Score:\\n\")\n",
        "    f.write(\"  > 0.7: Excellent    > 0.5: Good    > 0.3: Moderate    < 0.3: Weak\\n\\n\")\n",
        "\n",
        "    f.write(\"Davies-Bouldin Index:\\n\")\n",
        "    f.write(\"  < 0.5: Excellent    < 1.0: Good    < 2.0: Moderate    > 2.0: Poor\\n\\n\")\n",
        "\n",
        "    f.write(\"Adjusted Rand Index:\\n\")\n",
        "    f.write(\"  > 0.9: Excellent    > 0.7: Good    > 0.5: Moderate    < 0.3: Weak\\n\\n\")\n",
        "\n",
        "    f.write(\"=\"*70 + \"\\n\")\n",
        "    f.write(\"SUMMARY\\n\")\n",
        "    f.write(\"=\"*70 + \"\\n\\n\")\n",
        "\n",
        "    overall_score = (silhouette_avg + ari_score + nmi_score + purity) / 4\n",
        "    f.write(f\"Overall Quality Score: {overall_score:.4f}\\n\")\n",
        "    f.write(f\"(Average of key metrics)\\n\\n\")\n",
        "\n",
        "    if overall_score > 0.8:\n",
        "        f.write(\"Clustering Quality: EXCELLENT\\n\")\n",
        "    elif overall_score > 0.6:\n",
        "        f.write(\"Clustering Quality: GOOD\\n\")\n",
        "    elif overall_score > 0.4:\n",
        "        f.write(\"Clustering Quality: MODERATE\\n\")\n",
        "    else:\n",
        "        f.write(\"Clustering Quality: POOR\\n\")\n",
        "\n",
        "print(f\" Detailed report saved to: {report_path}\")\n",
        "\n",
        "# Save metrics to CSV\n",
        "metrics_df = pd.DataFrame({\n",
        "    'Metric': ['Silhouette Score', 'Davies-Bouldin Index', 'Adjusted Rand Index',\n",
        "               'Normalized Mutual Info', 'Homogeneity', 'Completeness',\n",
        "               'V-Measure', 'Fowlkes-Mallows Index', 'Purity'],\n",
        "    'Value': [silhouette_avg, db_score, ari_score, nmi_score,\n",
        "              homogeneity, completeness, v_measure, fmi_score, purity],\n",
        "    'Range': ['[-1, 1]', '[0, ]', '[-1, 1]', '[0, 1]',\n",
        "              '[0, 1]', '[0, 1]', '[0, 1]', '[0, 1]', '[0, 1]'],\n",
        "    'Interpretation': ['Higher better', 'Lower better', 'Higher better',\n",
        "                      'Higher better', 'Higher better', 'Higher better',\n",
        "                      'Higher better', 'Higher better', 'Higher better']\n",
        "})\n",
        "\n",
        "metrics_csv = os.path.join(output_dir, 'evaluation_metrics.csv')\n",
        "metrics_df.to_csv(metrics_csv, index=False)\n",
        "print(f\" Metrics saved to CSV: {metrics_csv}\")\n"
      ],
      "metadata": {
        "id": "NxiSgS-haMGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Comprehensive Comparison: VAE Methods vs Baselines\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import (\n",
        "    silhouette_score,\n",
        "    davies_bouldin_score,\n",
        "    adjusted_rand_score,\n",
        "    normalized_mutual_info_score\n",
        ")\n",
        "from sklearn.manifold import TSNE\n",
        "import librosa\n",
        "import os\n",
        "\n",
        "# Create output directory\n",
        "output_dir = '/content/drive/MyDrive/clustering_results'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"COMPREHENSIVE VAE COMPARISON ANALYSIS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# ========== LOAD ALL AVAILABLE METHODS ==========\n",
        "print(\"\\n1. Loading all available feature sets...\")\n",
        "\n",
        "methods = {}\n",
        "\n",
        "# Try to load all VAE variants\n",
        "vae_files = {\n",
        "    'Basic VAE': '/content/audio_vae_features.csv',\n",
        "    'Conv VAE': '/content/audio_conv_vae_features.csv',\n",
        "    'Hybrid VAE': '/content/audio_hybrid_vae_features.csv'\n",
        "}\n",
        "\n",
        "for name, path in vae_files.items():\n",
        "    try:\n",
        "        df = pd.read_csv(path)\n",
        "        methods[name] = df\n",
        "        print(f\"   {name}: {df.shape}\")\n",
        "    except:\n",
        "        print(f\"   {name}: Not found\")\n",
        "\n",
        "if len(methods) == 0:\n",
        "    print(\"\\n No VAE features found! Please run VAE feature extraction first.\")\n",
        "    exit()\n",
        "\n",
        "# ========== CREATE BASELINE FEATURES ==========\n",
        "print(\"\\n2. Creating baseline features from raw audio...\")\n",
        "\n",
        "# Load metadata to get audio paths\n",
        "dataset_folder = '/content/extracted_data/MyDataset'\n",
        "audio_folder = os.path.join(dataset_folder, 'audio')\n",
        "\n",
        "# Get audio files\n",
        "audio_files = []\n",
        "labels = []\n",
        "filenames = []\n",
        "\n",
        "bangla_folder = os.path.join(audio_folder, 'bangla')\n",
        "english_folder = os.path.join(audio_folder, 'english')\n",
        "\n",
        "for f in os.listdir(bangla_folder)[:50]:  # Limit to match VAE\n",
        "    if f.endswith(('.mp3', '.wav', '.flac')):\n",
        "        audio_files.append(os.path.join(bangla_folder, f))\n",
        "        labels.append('bangla')\n",
        "        filenames.append(f'bangla/{f}')\n",
        "\n",
        "for f in os.listdir(english_folder)[:50]:  # Limit to match VAE\n",
        "    if f.endswith(('.mp3', '.wav', '.flac')):\n",
        "        audio_files.append(os.path.join(english_folder, f))\n",
        "        labels.append('english')\n",
        "        filenames.append(f'english/{f}')\n",
        "\n",
        "print(f\"  Processing {len(audio_files)} audio files...\")\n",
        "\n",
        "# ===== Baseline 1: Raw MFCC Statistics =====\n",
        "print(\"  Creating Baseline 1: Raw MFCC Statistics...\")\n",
        "mfcc_features = []\n",
        "\n",
        "for audio_path in audio_files:\n",
        "    try:\n",
        "        y, sr = librosa.load(audio_path, duration=3.0, sr=22050)\n",
        "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=20)\n",
        "\n",
        "        # Statistical features: mean and std of each MFCC coefficient\n",
        "        mfcc_mean = np.mean(mfcc, axis=1)\n",
        "        mfcc_std = np.std(mfcc, axis=1)\n",
        "        features = np.concatenate([mfcc_mean, mfcc_std])  # 40 features\n",
        "\n",
        "        mfcc_features.append(features)\n",
        "    except:\n",
        "        mfcc_features.append(np.zeros(40))\n",
        "\n",
        "mfcc_df = pd.DataFrame(mfcc_features, columns=[f'mfcc_{i}' for i in range(40)])\n",
        "mfcc_df['filename'] = filenames\n",
        "mfcc_df['language'] = labels\n",
        "methods['Baseline: MFCC'] = mfcc_df\n",
        "\n",
        "print(f\"   Baseline 1: MFCC Statistics ({mfcc_df.shape})\")\n",
        "\n",
        "# ===== Baseline 2: Spectral Features =====\n",
        "print(\"  Creating Baseline 2: Spectral Features...\")\n",
        "spectral_features = []\n",
        "\n",
        "for audio_path in audio_files:\n",
        "    try:\n",
        "        y, sr = librosa.load(audio_path, duration=3.0, sr=22050)\n",
        "\n",
        "        # Spectral features\n",
        "        spectral_centroid = np.mean(librosa.feature.spectral_centroid(y=y, sr=sr))\n",
        "        spectral_rolloff = np.mean(librosa.feature.spectral_rolloff(y=y, sr=sr))\n",
        "        spectral_bandwidth = np.mean(librosa.feature.spectral_bandwidth(y=y, sr=sr))\n",
        "        zero_crossing_rate = np.mean(librosa.feature.zero_crossing_rate(y))\n",
        "\n",
        "        # Chroma features\n",
        "        chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
        "        chroma_mean = np.mean(chroma, axis=1)\n",
        "\n",
        "        # Combine features (16 features total)\n",
        "        features = np.concatenate([[spectral_centroid, spectral_rolloff,\n",
        "                                   spectral_bandwidth, zero_crossing_rate],\n",
        "                                  chroma_mean])\n",
        "\n",
        "        spectral_features.append(features)\n",
        "    except:\n",
        "        spectral_features.append(np.zeros(16))\n",
        "\n",
        "spectral_df = pd.DataFrame(spectral_features, columns=[f'spectral_{i}' for i in range(16)])\n",
        "spectral_df['filename'] = filenames\n",
        "spectral_df['language'] = labels\n",
        "methods['Baseline: Spectral'] = spectral_df\n",
        "\n",
        "print(f\"   Baseline 2: Spectral Features ({spectral_df.shape})\")\n",
        "\n",
        "# ===== Baseline 3: Combined Hand-crafted =====\n",
        "print(\"  Creating Baseline 3: Combined Hand-crafted Features...\")\n",
        "\n",
        "combined_features = np.concatenate([mfcc_features, spectral_features], axis=1)\n",
        "combined_df = pd.DataFrame(combined_features,\n",
        "                          columns=[f'combined_{i}' for i in range(56)])\n",
        "combined_df['filename'] = filenames\n",
        "combined_df['language'] = labels\n",
        "methods['Baseline: Combined'] = combined_df\n",
        "\n",
        "print(f\"   Baseline 3: Combined Features ({combined_df.shape})\")\n",
        "\n",
        "# ========== EVALUATE ALL METHODS ==========\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"3. Evaluating clustering performance for all methods...\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "results = []\n",
        "\n",
        "for method_name, df in methods.items():\n",
        "    print(f\"\\n  Evaluating: {method_name}\")\n",
        "\n",
        "    # Get features\n",
        "    feature_cols = [col for col in df.columns if col not in ['filename', 'language', 'audio_path']]\n",
        "    X = df[feature_cols].values\n",
        "    y_true = df['language'].map({'bangla': 0, 'english': 1}).values\n",
        "\n",
        "    # Standardize\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    # K-Means clustering\n",
        "    kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
        "    y_pred = kmeans.fit_predict(X_scaled)\n",
        "\n",
        "    # Calculate metrics\n",
        "    silhouette = silhouette_score(X_scaled, y_pred)\n",
        "    davies_bouldin = davies_bouldin_score(X_scaled, y_pred)\n",
        "    ari = adjusted_rand_score(y_true, y_pred)\n",
        "    nmi = normalized_mutual_info_score(y_true, y_pred)\n",
        "\n",
        "    # Confusion matrix for purity\n",
        "    cm = np.zeros((2, 2))\n",
        "    for i in range(len(y_true)):\n",
        "        cm[y_true[i], y_pred[i]] += 1\n",
        "    purity = np.sum(np.amax(cm, axis=0)) / np.sum(cm)\n",
        "\n",
        "    # PCA for dimensionality analysis\n",
        "    pca = PCA()\n",
        "    pca.fit(X_scaled)\n",
        "    variance_90 = np.argmax(np.cumsum(pca.explained_variance_ratio_) >= 0.90) + 1\n",
        "    variance_95 = np.argmax(np.cumsum(pca.explained_variance_ratio_) >= 0.95) + 1\n",
        "\n",
        "    results.append({\n",
        "        'Method': method_name,\n",
        "        'N_Features': X.shape[1],\n",
        "        'Silhouette': silhouette,\n",
        "        'Davies-Bouldin': davies_bouldin,\n",
        "        'ARI': ari,\n",
        "        'NMI': nmi,\n",
        "        'Purity': purity,\n",
        "        'PCA_90%': variance_90,\n",
        "        'PCA_95%': variance_95,\n",
        "        'Type': 'VAE' if 'VAE' in method_name else 'Baseline'\n",
        "    })\n",
        "\n",
        "    print(f\"    Silhouette: {silhouette:.4f} | ARI: {ari:.4f} | Purity: {purity:.4f}\")\n",
        "\n",
        "# Create results dataframe\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df = results_df.sort_values('Silhouette', ascending=False)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"RESULTS SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "print(results_df.to_string(index=False))\n",
        "\n",
        "# ========== ANALYSIS ==========\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"4. Analyzing why VAE methods perform better/worse...\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Separate VAE and baseline results\n",
        "vae_results = results_df[results_df['Type'] == 'VAE']\n",
        "baseline_results = results_df[results_df['Type'] == 'Baseline']\n",
        "\n",
        "print(\"\\nVAE Methods - Average Performance:\")\n",
        "print(f\"  Silhouette:      {vae_results['Silhouette'].mean():.4f}\")\n",
        "print(f\"  ARI:             {vae_results['ARI'].mean():.4f}\")\n",
        "print(f\"  Davies-Bouldin:  {vae_results['Davies-Bouldin'].mean():.4f}\")\n",
        "\n",
        "print(\"\\nBaseline Methods - Average Performance:\")\n",
        "print(f\"  Silhouette:      {baseline_results['Silhouette'].mean():.4f}\")\n",
        "print(f\"  ARI:             {baseline_results['ARI'].mean():.4f}\")\n",
        "print(f\"  Davies-Bouldin:  {baseline_results['Davies-Bouldin'].mean():.4f}\")\n",
        "\n",
        "print(\"\\nKEY INSIGHTS:\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "# Best method\n",
        "best_method = results_df.iloc[0]\n",
        "print(f\"\\n1. BEST PERFORMING METHOD: {best_method['Method']}\")\n",
        "print(f\"   Silhouette: {best_method['Silhouette']:.4f}\")\n",
        "print(f\"   ARI: {best_method['ARI']:.4f}\")\n",
        "print(f\"   Why it works:\")\n",
        "if 'Hybrid' in best_method['Method']:\n",
        "    print(\"   - Combines audio AND text information\")\n",
        "    print(\"   - Captures both acoustic and semantic patterns\")\n",
        "    print(\"   - Multi-modal learning improves separation\")\n",
        "elif 'Conv' in best_method['Method']:\n",
        "    print(\"   - Convolutional layers capture local patterns in spectrograms\")\n",
        "    print(\"   - Hierarchical feature learning\")\n",
        "    print(\"   - Better than statistical aggregation\")\n",
        "elif 'Basic' in best_method['Method']:\n",
        "    print(\"   - Learned representations vs hand-crafted\")\n",
        "    print(\"   - Non-linear transformations\")\n",
        "    print(\"   - Optimized for reconstruction\")\n",
        "else:\n",
        "    print(\"   - Hand-crafted features work well for this task\")\n",
        "    print(\"   - Domain knowledge encoded\")\n",
        "\n",
        "print(\"\\n2. DIMENSIONALITY COMPARISON:\")\n",
        "for _, row in results_df.iterrows():\n",
        "    print(f\"   {row['Method']:25s}: {row['N_Features']:3d} features  {row['PCA_90%']:3d} PCs (90% var)\")\n",
        "\n",
        "\n",
        "\n",
        "# ========== VISUALIZATIONS ==========\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"5. Creating comparison visualizations...\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# 1. Performance Comparison Bar Charts\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "metrics = ['Silhouette', 'ARI', 'NMI', 'Purity']\n",
        "colors_map = {'VAE': '#3498db', 'Baseline': '#e74c3c'}\n",
        "\n",
        "for idx, metric in enumerate(metrics):\n",
        "    ax = axes[idx // 2, idx % 2]\n",
        "\n",
        "    data = results_df.sort_values(metric, ascending=False)\n",
        "    colors = [colors_map[t] for t in data['Type']]\n",
        "\n",
        "    bars = ax.barh(data['Method'], data[metric], color=colors, edgecolor='black', linewidth=1.5)\n",
        "    ax.set_xlabel(metric, fontsize=12)\n",
        "    ax.set_title(f'{metric} Comparison', fontsize=14, fontweight='bold')\n",
        "    ax.grid(axis='x', alpha=0.3)\n",
        "\n",
        "    # Add value labels\n",
        "    for bar, val in zip(bars, data[metric]):\n",
        "        width = bar.get_width()\n",
        "        ax.text(width, bar.get_y() + bar.get_height()/2.,\n",
        "                f'{val:.3f}',\n",
        "                ha='left', va='center', fontsize=10, fontweight='bold')\n",
        "\n",
        "# Add legend\n",
        "from matplotlib.patches import Patch\n",
        "legend_elements = [Patch(facecolor='#3498db', edgecolor='black', label='VAE Methods'),\n",
        "                   Patch(facecolor='#e74c3c', edgecolor='black', label='Baseline Methods')]\n",
        "fig.legend(handles=legend_elements, loc='upper center', ncol=2, fontsize=12, frameon=True)\n",
        "\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
        "plt.savefig(os.path.join(output_dir, 'method_comparison.png'), dpi=300, bbox_inches='tight')\n",
        "print(\"   Method comparison saved\")\n",
        "plt.show()\n",
        "\n",
        "# 2. Dimensionality Analysis\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Feature count vs performance\n",
        "ax1.scatter(results_df['N_Features'], results_df['Silhouette'],\n",
        "           s=200, alpha=0.7, c=[colors_map[t] for t in results_df['Type']],\n",
        "           edgecolors='black', linewidth=2)\n",
        "\n",
        "for _, row in results_df.iterrows():\n",
        "    ax1.annotate(row['Method'].replace('Baseline: ', 'B:').replace(' VAE', ''),\n",
        "                (row['N_Features'], row['Silhouette']),\n",
        "                fontsize=9, ha='center', va='bottom')\n",
        "\n",
        "ax1.set_xlabel('Number of Features', fontsize=13)\n",
        "ax1.set_ylabel('Silhouette Score', fontsize=13)\n",
        "ax1.set_title('Feature Dimensionality vs Performance', fontsize=15, fontweight='bold')\n",
        "ax1.grid(alpha=0.3)\n",
        "\n",
        "# PCA variance\n",
        "ax2.bar(results_df['Method'], results_df['PCA_90%'],\n",
        "       color=[colors_map[t] for t in results_df['Type']],\n",
        "       edgecolor='black', linewidth=1.5)\n",
        "ax2.set_ylabel('N Components (90% variance)', fontsize=12)\n",
        "ax2.set_title('Effective Dimensionality (PCA)', fontsize=14, fontweight='bold')\n",
        "ax2.grid(axis='y', alpha=0.3)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(output_dir, 'dimensionality_analysis.png'), dpi=300, bbox_inches='tight')\n",
        "print(\"   Dimensionality analysis saved\")\n",
        "plt.show()\n",
        "\n",
        "# 3. Radar Chart for Multi-metric Comparison\n",
        "fig, ax = plt.subplots(figsize=(12, 12), subplot_kw=dict(projection='polar'))\n",
        "\n",
        "# Normalize metrics to 0-1 scale\n",
        "metrics_normalized = results_df[['Silhouette', 'ARI', 'NMI', 'Purity']].copy()\n",
        "metrics_normalized['Davies-Bouldin'] = 1 / (1 + results_df['Davies-Bouldin'])  # Invert DB\n",
        "\n",
        "angles = np.linspace(0, 2 * np.pi, 5, endpoint=False).tolist()\n",
        "angles += angles[:1]\n",
        "\n",
        "for idx, row in results_df.iterrows():\n",
        "    values = metrics_normalized.iloc[idx].tolist()\n",
        "    values += values[:1]\n",
        "\n",
        "    color = colors_map[row['Type']]\n",
        "    ax.plot(angles, values, 'o-', linewidth=2, label=row['Method'], color=color, alpha=0.7)\n",
        "    ax.fill(angles, values, alpha=0.15, color=color)\n",
        "\n",
        "ax.set_xticks(angles[:-1])\n",
        "ax.set_xticklabels(['Silhouette', 'ARI', 'NMI', 'Purity', 'DB (inv)'], fontsize=11)\n",
        "ax.set_ylim(0, 1)\n",
        "ax.set_title('Multi-Metric Performance Comparison', fontsize=16, fontweight='bold', pad=20)\n",
        "ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1), fontsize=10)\n",
        "ax.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(output_dir, 'radar_comparison.png'), dpi=300, bbox_inches='tight')\n",
        "print(\"   Radar comparison saved\")\n",
        "plt.show()\n",
        "\n",
        "# 4. Davies-Bouldin Comparison (lower is better)\n",
        "fig, ax = plt.subplots(figsize=(12, 7))\n",
        "\n",
        "data = results_df.sort_values('Davies-Bouldin')\n",
        "colors = [colors_map[t] for t in data['Type']]\n",
        "\n",
        "bars = ax.barh(data['Method'], data['Davies-Bouldin'], color=colors,\n",
        "              edgecolor='black', linewidth=1.5)\n",
        "\n",
        "ax.set_xlabel('Davies-Bouldin Index (Lower is Better)', fontsize=13)\n",
        "ax.set_title('Davies-Bouldin Index Comparison', fontsize=15, fontweight='bold')\n",
        "ax.grid(axis='x', alpha=0.3)\n",
        "ax.axvline(x=1.0, color='green', linestyle='--', linewidth=2, label='Good (<1.0)')\n",
        "\n",
        "for bar, val in zip(bars, data['Davies-Bouldin']):\n",
        "    width = bar.get_width()\n",
        "    ax.text(width, bar.get_y() + bar.get_height()/2.,\n",
        "            f'{val:.3f}',\n",
        "            ha='left', va='center', fontsize=10, fontweight='bold')\n",
        "\n",
        "ax.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(output_dir, 'davies_bouldin_comparison.png'), dpi=300, bbox_inches='tight')\n",
        "print(\"   Davies-Bouldin comparison saved\")\n",
        "plt.show()\n",
        "\n",
        "# ========== SAVE DETAILED REPORT ==========\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"6. Saving comprehensive analysis report...\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "report_path = os.path.join(output_dir, 'comparison_analysis_report.txt')\n",
        "with open(report_path, 'w') as f:\n",
        "    f.write(\"=\"*80 + \"\\n\")\n",
        "    f.write(\"COMPREHENSIVE VAE VS BASELINE COMPARISON ANALYSIS\\n\")\n",
        "    f.write(\"=\"*80 + \"\\n\\n\")\n",
        "\n",
        "    f.write(\"METHODS EVALUATED:\\n\")\n",
        "    f.write(\"-\" * 80 + \"\\n\")\n",
        "    for method in results_df['Method']:\n",
        "        f.write(f\"   {method}\\n\")\n",
        "    f.write(\"\\n\")\n",
        "\n",
        "    f.write(\"=\"*80 + \"\\n\")\n",
        "    f.write(\"PERFORMANCE RANKING (by Silhouette Score)\\n\")\n",
        "    f.write(\"=\"*80 + \"\\n\\n\")\n",
        "\n",
        "    for idx, row in results_df.iterrows():\n",
        "        f.write(f\"{idx+1}. {row['Method']}\\n\")\n",
        "        f.write(f\"   Silhouette: {row['Silhouette']:.4f} | \")\n",
        "        f.write(f\"ARI: {row['ARI']:.4f} | \")\n",
        "        f.write(f\"NMI: {row['NMI']:.4f} | \")\n",
        "        f.write(f\"Purity: {row['Purity']:.4f}\\n\")\n",
        "        f.write(f\"   Features: {row['N_Features']}  PCA 90%: {row['PCA_90%']}\\n\\n\")\n",
        "\n",
        "    f.write(\"=\"*80 + \"\\n\")\n",
        "    f.write(\"VAE vs BASELINE COMPARISON\\n\")\n",
        "    f.write(\"=\"*80 + \"\\n\\n\")\n",
        "\n",
        "    f.write(\"VAE Methods Average:\\n\")\n",
        "    f.write(f\"  Silhouette: {vae_results['Silhouette'].mean():.4f}\\n\")\n",
        "    f.write(f\"  ARI:        {vae_results['ARI'].mean():.4f}\\n\")\n",
        "    f.write(f\"  NMI:        {vae_results['NMI'].mean():.4f}\\n\\n\")\n",
        "\n",
        "    f.write(\"Baseline Methods Average:\\n\")\n",
        "    f.write(f\"  Silhouette: {baseline_results['Silhouette'].mean():.4f}\\n\")\n",
        "    f.write(f\"  ARI:        {baseline_results['ARI'].mean():.4f}\\n\")\n",
        "    f.write(f\"  NMI:        {baseline_results['NMI'].mean():.4f}\\n\\n\")\n",
        "\n",
        "    improvement = ((vae_results['Silhouette'].mean() - baseline_results['Silhouette'].mean()) /\n",
        "                   baseline_results['Silhouette'].mean() * 100)\n",
        "    f.write(f\"VAE Improvement over Baselines: {improvement:+.1f}%\\n\\n\")\n",
        "\n",
        "\n",
        "\n",
        "print(f\"   Report saved to: {report_path}\")\n",
        "\n",
        "# Save comparison table\n",
        "results_df.to_csv(os.path.join(output_dir, 'method_comparison_table.csv'), index=False)\n",
        "print(f\"   Comparison table saved\")"
      ],
      "metadata": {
        "id": "8UUTTbzTbTPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hard"
      ],
      "metadata": {
        "id": "6iJhQ1IhcLek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ========== Beta-VAE Model ==========\n",
        "class BetaVAE(nn.Module):\n",
        "    \"\"\"\n",
        "    Beta-VAE: VAE with adjustable beta parameter for disentanglement\n",
        "    Higher beta = more disentangled latent representations\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim=128, latent_dim=32):\n",
        "        super(BetaVAE, self).__init__()\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 48),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.fc_mu = nn.Linear(48, latent_dim)\n",
        "        self.fc_logvar = nn.Linear(48, latent_dim)\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 48),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(48, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, input_dim),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def encode(self, x):\n",
        "        h = self.encoder(x)\n",
        "        mu = self.fc_mu(h)\n",
        "        logvar = self.fc_logvar(h)\n",
        "        return mu, logvar\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def decode(self, z):\n",
        "        return self.decoder(z)\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        recon = self.decode(z)\n",
        "        return recon, mu, logvar\n",
        "\n",
        "def beta_vae_loss(recon_x, x, mu, logvar, beta=4.0):\n",
        "    \"\"\"\n",
        "    Beta-VAE loss with adjustable beta parameter\n",
        "    beta=1.0: Standard VAE\n",
        "    beta>1.0: Encourages disentanglement\n",
        "    \"\"\"\n",
        "    recon_loss = nn.functional.mse_loss(recon_x, x, reduction='sum')\n",
        "    kld = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    return recon_loss + beta * kld\n",
        "\n",
        "# ========== Audio Dataset ==========\n",
        "class AudioDataset(Dataset):\n",
        "    def __init__(self, audio_paths, labels, n_mfcc=128):\n",
        "        self.audio_paths = audio_paths\n",
        "        self.labels = labels\n",
        "        self.n_mfcc = n_mfcc\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.audio_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        audio_path = self.audio_paths[idx]\n",
        "\n",
        "        y, sr = librosa.load(audio_path, duration=3.0, sr=22050)\n",
        "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=self.n_mfcc)\n",
        "        mfcc_mean = np.mean(mfcc, axis=1)\n",
        "\n",
        "        return torch.FloatTensor(mfcc_mean)\n",
        "\n",
        "# Get audio files\n",
        "bangla_folder = os.path.join(audio_folder, 'bangla')\n",
        "english_folder = os.path.join(audio_folder, 'english')\n",
        "\n",
        "audio_files = []\n",
        "labels = []\n",
        "\n",
        "if os.path.exists(bangla_folder):\n",
        "    bangla_files = [os.path.join(bangla_folder, f) for f in os.listdir(bangla_folder)\n",
        "                    if f.endswith(('.mp3', '.wav', '.flac'))]\n",
        "    audio_files.extend(bangla_files)\n",
        "    labels.extend([0] * len(bangla_files))\n",
        "\n",
        "if os.path.exists(english_folder):\n",
        "    english_files = [os.path.join(english_folder, f) for f in os.listdir(english_folder)\n",
        "                     if f.endswith(('.mp3', '.wav', '.flac'))]\n",
        "    audio_files.extend(english_files)\n",
        "    labels.extend([1] * len(english_files))\n",
        "\n",
        "print(f\"\\nTotal audio files: {len(audio_files)}\")\n",
        "print(f\"Bangla: {labels.count(0)}, English: {labels.count(1)}\")\n",
        "\n",
        "sample_size = min(100, len(audio_files))\n",
        "audio_sample = audio_files[:sample_size]\n",
        "labels_sample = labels[:sample_size]\n",
        "\n",
        "print(f\"Using {sample_size} files for training\")\n",
        "\n",
        "# Create dataset\n",
        "dataset = AudioDataset(audio_sample, labels_sample)\n",
        "train_loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "# ========== Train with Different Beta Values ==========\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Training Beta-VAE with Different Beta Values\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "beta_values = [1.0, 2.0, 4.0, 8.0]\n",
        "models = {}\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "print(f\"Device: {device}\")\n",
        "\n",
        "for beta in beta_values:\n",
        "    print(f\"\\n--- Training with Beta={beta} ---\")\n",
        "\n",
        "    model = BetaVAE(input_dim=128, latent_dim=32).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    epochs = 10\n",
        "    train_losses = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "\n",
        "        for batch_idx, data in enumerate(train_loader):\n",
        "            data = data.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            recon_batch, mu, logvar = model(data)\n",
        "            loss = beta_vae_loss(recon_batch, data, mu, logvar, beta=beta)\n",
        "            loss.backward()\n",
        "            train_loss += loss.item()\n",
        "            optimizer.step()\n",
        "\n",
        "        avg_loss = train_loss / len(train_loader.dataset)\n",
        "        train_losses.append(avg_loss)\n",
        "\n",
        "        if (epoch + 1) % 2 == 0:\n",
        "            print(f'Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}')\n",
        "\n",
        "    models[beta] = {\n",
        "        'model': model,\n",
        "        'losses': train_losses\n",
        "    }\n",
        "\n",
        "    print(f\" Beta={beta} training complete!\")\n",
        "\n",
        "# ========== Extract Features for Each Beta ==========\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Extracting Features\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "all_features = {}\n",
        "\n",
        "for beta in beta_values:\n",
        "    print(f\"\\nExtracting features for Beta={beta}...\")\n",
        "    model = models[beta]['model']\n",
        "    model.eval()\n",
        "\n",
        "    features = []\n",
        "    paths = []\n",
        "    labels_list = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for audio_path, label in zip(audio_sample, labels_sample):\n",
        "            try:\n",
        "                y, sr = librosa.load(audio_path, duration=3.0, sr=22050)\n",
        "                mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=128)\n",
        "                mfcc_mean = np.mean(mfcc, axis=1)\n",
        "\n",
        "                x = torch.FloatTensor(mfcc_mean).unsqueeze(0).to(device)\n",
        "                mu, _ = model.encode(x)\n",
        "\n",
        "                features.append(mu.cpu().numpy().flatten())\n",
        "                paths.append(audio_path)\n",
        "                labels_list.append('bangla' if label == 0 else 'english')\n",
        "            except Exception as e:\n",
        "                print(f\"Error: {e}\")\n",
        "\n",
        "    features_df = pd.DataFrame(features, columns=[f'feature_{i}' for i in range(32)])\n",
        "    features_df['audio_path'] = paths\n",
        "    features_df['filename'] = [os.path.basename(p) for p in paths]\n",
        "    features_df['language'] = labels_list\n",
        "\n",
        "    all_features[beta] = features_df\n",
        "\n",
        "    # Save\n",
        "    csv_path = f'/content/audio_beta{int(beta)}_vae_features.csv'\n",
        "    features_df.to_csv(csv_path, index=False)\n",
        "    print(f\" Saved: {csv_path}\")\n",
        "\n",
        "# ========== Visualization ==========\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Creating Visualizations\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# 1. Training curves\n",
        "fig, ax = plt.subplots(figsize=(12, 7))\n",
        "\n",
        "for beta in beta_values:\n",
        "    losses = models[beta]['losses']\n",
        "    ax.plot(losses, marker='o', linewidth=2, label=f'={beta}')\n",
        "\n",
        "ax.set_xlabel('Epoch', fontsize=13)\n",
        "ax.set_ylabel('Loss', fontsize=13)\n",
        "ax.set_title('Beta-VAE Training Loss for Different  Values', fontsize=15, fontweight='bold')\n",
        "ax.legend(fontsize=12)\n",
        "ax.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig('/content/drive/MyDrive/clustering_results/beta_vae_training.png', dpi=300, bbox_inches='tight')\n",
        "print(\" Training curves saved\")\n",
        "plt.show()\n",
        "\n",
        "# 2. Latent space comparison\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 14))\n",
        "\n",
        "for idx, beta in enumerate(beta_values):\n",
        "    ax = axes[idx // 2, idx % 2]\n",
        "\n",
        "    features_df = all_features[beta]\n",
        "    X = features_df[[f'feature_{i}' for i in range(32)]].values\n",
        "\n",
        "    pca = PCA(n_components=2)\n",
        "    X_pca = pca.fit_transform(X)\n",
        "\n",
        "    colors = {'bangla': 'blue', 'english': 'red'}\n",
        "    for language in ['bangla', 'english']:\n",
        "        mask = features_df['language'] == language\n",
        "        ax.scatter(X_pca[mask, 0], X_pca[mask, 1],\n",
        "                  c=colors[language],\n",
        "                  label=language.capitalize(),\n",
        "                  alpha=0.6,\n",
        "                  edgecolors='k',\n",
        "                  s=100)\n",
        "\n",
        "    var_explained = pca.explained_variance_ratio_.sum()\n",
        "    ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%})', fontsize=12)\n",
        "    ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%})', fontsize=12)\n",
        "    ax.set_title(f'={beta} (Var explained: {var_explained:.2%})', fontsize=14, fontweight='bold')\n",
        "    ax.legend(fontsize=11)\n",
        "    ax.grid(alpha=0.3)\n",
        "\n",
        "plt.suptitle('Latent Space Visualization: Different  Values', fontsize=16, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.savefig('/content/drive/MyDrive/clustering_results/beta_vae_latent_space.png', dpi=300, bbox_inches='tight')\n",
        "print(\" Latent space visualization saved\")\n",
        "plt.show()\n",
        "\n",
        "# 3. Clustering evaluation\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score, adjusted_rand_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "results = []\n",
        "\n",
        "for beta in beta_values:\n",
        "    features_df = all_features[beta]\n",
        "    X = features_df[[f'feature_{i}' for i in range(32)]].values\n",
        "    y_true = features_df['language'].map({'bangla': 0, 'english': 1}).values\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
        "    y_pred = kmeans.fit_predict(X_scaled)\n",
        "\n",
        "    sil = silhouette_score(X_scaled, y_pred)\n",
        "    ari = adjusted_rand_score(y_true, y_pred)\n",
        "\n",
        "    results.append({\n",
        "        'Beta': beta,\n",
        "        'Silhouette': sil,\n",
        "        'ARI': ari\n",
        "    })\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "ax1.plot(results_df['Beta'], results_df['Silhouette'], 'bo-', linewidth=2, markersize=10)\n",
        "ax1.set_xlabel(' Value', fontsize=13)\n",
        "ax1.set_ylabel('Silhouette Score', fontsize=13)\n",
        "ax1.set_title('Clustering Quality vs ', fontsize=15, fontweight='bold')\n",
        "ax1.grid(alpha=0.3)\n",
        "\n",
        "ax2.plot(results_df['Beta'], results_df['ARI'], 'ro-', linewidth=2, markersize=10)\n",
        "ax2.set_xlabel(' Value', fontsize=13)\n",
        "ax2.set_ylabel('Adjusted Rand Index', fontsize=13)\n",
        "ax2.set_title('ARI vs ', fontsize=15, fontweight='bold')\n",
        "ax2.grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('/content/drive/MyDrive/clustering_results/beta_vae_metrics.png', dpi=300, bbox_inches='tight')\n",
        "print(\" Metrics comparison saved\")\n",
        "plt.show()\n",
        "\n",
        "# Save models\n",
        "for beta in beta_values:\n",
        "    model_path = f'/content/drive/MyDrive/clustering_results/beta{int(beta)}_vae_model.pth'\n",
        "    torch.save(models[beta]['model'].state_dict(), model_path)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\" Beta-VAE Complete!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nTrained with  values: {beta_values}\")\n",
        "print(f\"\\nBest performing : {results_df.loc[results_df['Silhouette'].idxmax(), 'Beta']}\")\n",
        "print(f\"\\nOutputs:\")"
      ],
      "metadata": {
        "id": "Uq5nDLS-cNQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score, adjusted_rand_score, normalized_mutual_info_score\n",
        "from sklearn.decomposition import PCA\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import librosa\n",
        "\n",
        "# Install sentence-transformers\n",
        "import subprocess\n",
        "subprocess.run(['pip', 'install', 'sentence-transformers'], capture_output=True)\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# ========== Multi-Modal Feature Extractor ==========\n",
        "class MultiModalFeatureExtractor:\n",
        "    \"\"\"\n",
        "    Extracts and combines features from multiple modalities:\n",
        "    1. Audio features (MFCC)\n",
        "    2. Lyrics embeddings (text)\n",
        "    3. Genre embeddings (categorical)\n",
        "    \"\"\"\n",
        "    def __init__(self, text_encoder_model='all-MiniLM-L6-v2'):\n",
        "        self.text_encoder = SentenceTransformer(text_encoder_model)\n",
        "        self.genre_encoder = LabelEncoder()\n",
        "\n",
        "    def extract_audio_features(self, audio_path, n_mfcc=20):\n",
        "        \"\"\"Extract MFCC features from audio\"\"\"\n",
        "        y, sr = librosa.load(audio_path, duration=3.0, sr=22050)\n",
        "\n",
        "        # MFCC\n",
        "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
        "        mfcc_mean = np.mean(mfcc, axis=1)\n",
        "        mfcc_std = np.std(mfcc, axis=1)\n",
        "\n",
        "        # Spectral features\n",
        "        spectral_centroid = np.mean(librosa.feature.spectral_centroid(y=y, sr=sr))\n",
        "        spectral_rolloff = np.mean(librosa.feature.spectral_rolloff(y=y, sr=sr))\n",
        "        zero_crossing = np.mean(librosa.feature.zero_crossing_rate(y))\n",
        "\n",
        "        # Tempo\n",
        "        tempo, _ = librosa.beat.beat_track(y=y, sr=sr)\n",
        "\n",
        "        # Combine: 20 MFCC means + 20 MFCC stds + 4 spectral = 44 features\n",
        "        features = np.concatenate([mfcc_mean, mfcc_std,\n",
        "                                   [spectral_centroid, spectral_rolloff,\n",
        "                                    zero_crossing, tempo]])\n",
        "        return features\n",
        "\n",
        "    def extract_lyrics_features(self, lyrics_list):\n",
        "        \"\"\"Extract embeddings from lyrics using sentence-transformers\"\"\"\n",
        "        print(\"Encoding lyrics...\")\n",
        "        embeddings = self.text_encoder.encode(lyrics_list, show_progress_bar=True)\n",
        "        return embeddings\n",
        "\n",
        "    def extract_genre_features(self, genre_list, fit=True):\n",
        "        \"\"\"Extract one-hot encoded genre features\"\"\"\n",
        "        if fit:\n",
        "            self.genre_encoder.fit(genre_list)\n",
        "\n",
        "        genre_encoded = self.genre_encoder.transform(genre_list)\n",
        "        n_genres = len(self.genre_encoder.classes_)\n",
        "\n",
        "        # One-hot encode\n",
        "        genre_onehot = np.zeros((len(genre_list), n_genres))\n",
        "        genre_onehot[np.arange(len(genre_list)), genre_encoded] = 1\n",
        "\n",
        "        return genre_onehot\n",
        "\n",
        "# ========== Load Data ==========\n",
        "dataset_folder = '/content/extracted_data/MyDataset'\n",
        "audio_folder = os.path.join(dataset_folder, 'audio')\n",
        "metadata = pd.read_excel(os.path.join(dataset_folder, 'metadata.xlsx'))\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Loading Audio Files\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "bangla_folder = os.path.join(audio_folder, 'bangla')\n",
        "english_folder = os.path.join(audio_folder, 'english')\n",
        "\n",
        "audio_files = []\n",
        "labels = []\n",
        "filenames = []\n",
        "\n",
        "for f in os.listdir(bangla_folder):\n",
        "    if f.endswith(('.mp3', '.wav', '.flac')):\n",
        "        audio_files.append(os.path.join(bangla_folder, f))\n",
        "        labels.append('bangla')\n",
        "        filenames.append(f'bangla/{f}')\n",
        "\n",
        "for f in os.listdir(english_folder):\n",
        "    if f.endswith(('.mp3', '.wav', '.flac')):\n",
        "        audio_files.append(os.path.join(english_folder, f))\n",
        "        labels.append('english')\n",
        "        filenames.append(f'english/{f}')\n",
        "\n",
        "# Create dataframe\n",
        "audio_df = pd.DataFrame({\n",
        "    'filename': filenames,\n",
        "    'audio_path': audio_files,\n",
        "    'language': labels\n",
        "})\n",
        "\n",
        "# Merge with metadata\n",
        "# Clean column names (safe)\n",
        "metadata.columns = metadata.columns.str.strip().str.lower()\n",
        "\n",
        "# Merge correctly\n",
        "audio_df = audio_df.merge(\n",
        "    metadata[['filenaming', 'lyrics', 'genre']],\n",
        "    left_on='filename',\n",
        "    right_on='filenaming',\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "# Drop duplicate column\n",
        "audio_df.drop(columns=['filenaming'], inplace=True)\n",
        "\n",
        "audio_df['lyrics'] = audio_df['lyrics'].fillna('no lyrics available')\n",
        "audio_df['genre'] = audio_df['genre'].fillna('Unknown')\n",
        "audio_df['lyrics'] = audio_df['lyrics'].fillna('no lyrics available')\n",
        "audio_df['genre'] = audio_df['genre'].fillna('Unknown')\n",
        "\n",
        "sample_size = min(100, len(audio_df))\n",
        "audio_sample = audio_df.iloc[:sample_size]\n",
        "\n",
        "print(f\"Total samples: {len(audio_sample)}\")\n",
        "print(f\"Languages: Bangla={sum(audio_sample['language']=='bangla')}, English={sum(audio_sample['language']=='english')}\")\n",
        "print(f\"Genres: {audio_sample['genre'].value_counts().to_dict()}\")\n",
        "\n",
        "# ========== Extract Multi-Modal Features ==========\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Extracting Multi-Modal Features\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "extractor = MultiModalFeatureExtractor()\n",
        "\n",
        "# 1. Audio features\n",
        "print(\"\\n1. Extracting audio features...\")\n",
        "audio_features = []\n",
        "for audio_path in audio_sample['audio_path']:\n",
        "    try:\n",
        "        features = extractor.extract_audio_features(audio_path)\n",
        "        audio_features.append(features)\n",
        "    except:\n",
        "        audio_features.append(np.zeros(44))\n",
        "\n",
        "audio_features = np.array(audio_features)\n",
        "print(f\"   Audio features: {audio_features.shape}\")\n",
        "\n",
        "# 2. Lyrics features\n",
        "print(\"\\n2. Extracting lyrics features...\")\n",
        "lyrics_features = extractor.extract_lyrics_features(audio_sample['lyrics'].tolist())\n",
        "print(f\"   Lyrics features: {lyrics_features.shape}\")\n",
        "\n",
        "# 3. Genre features\n",
        "print(\"\\n3. Extracting genre features...\")\n",
        "genre_features = extractor.extract_genre_features(audio_sample['genre'].tolist())\n",
        "print(f\"   Genre features: {genre_features.shape}\")\n",
        "print(f\"   Genres: {extractor.genre_encoder.classes_}\")\n",
        "\n",
        "# ========== Create Feature Combinations ==========\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Creating Feature Combinations\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Standardize each modality\n",
        "scaler_audio = StandardScaler()\n",
        "scaler_lyrics = StandardScaler()\n",
        "scaler_genre = StandardScaler()\n",
        "\n",
        "audio_scaled = scaler_audio.fit_transform(audio_features)\n",
        "lyrics_scaled = scaler_lyrics.fit_transform(lyrics_features)\n",
        "genre_scaled = scaler_genre.fit_transform(genre_features)\n",
        "\n",
        "feature_combinations = {\n",
        "    'Audio Only': audio_scaled,\n",
        "    'Lyrics Only': lyrics_scaled,\n",
        "    'Genre Only': genre_scaled,\n",
        "    'Audio + Lyrics': np.concatenate([audio_scaled, lyrics_scaled], axis=1),\n",
        "    'Audio + Genre': np.concatenate([audio_scaled, genre_scaled], axis=1),\n",
        "    'Lyrics + Genre': np.concatenate([lyrics_scaled, genre_scaled], axis=1),\n",
        "    'All Modalities': np.concatenate([audio_scaled, lyrics_scaled, genre_scaled], axis=1)\n",
        "}\n",
        "\n",
        "for name, features in feature_combinations.items():\n",
        "    print(f\"   {name}: {features.shape}\")\n",
        "\n",
        "# ========== Clustering Evaluation ==========\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Evaluating Clustering Performance\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "y_true = audio_sample['language'].map({'bangla': 0, 'english': 1}).values\n",
        "\n",
        "results = []\n",
        "\n",
        "for name, X in feature_combinations.items():\n",
        "    print(f\"\\nClustering with: {name}\")\n",
        "\n",
        "    # K-Means\n",
        "    kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
        "    y_pred = kmeans.fit_predict(X)\n",
        "\n",
        "    # Metrics\n",
        "    sil = silhouette_score(X, y_pred)\n",
        "    ari = adjusted_rand_score(y_true, y_pred)\n",
        "    nmi = normalized_mutual_info_score(y_true, y_pred)\n",
        "\n",
        "    # Purity\n",
        "    cm = np.zeros((2, 2))\n",
        "    for i in range(len(y_true)):\n",
        "        cm[y_true[i], y_pred[i]] += 1\n",
        "    purity = np.sum(np.amax(cm, axis=0)) / np.sum(cm)\n",
        "\n",
        "    results.append({\n",
        "        'Combination': name,\n",
        "        'N_Features': X.shape[1],\n",
        "        'Silhouette': sil,\n",
        "        'ARI': ari,\n",
        "        'NMI': nmi,\n",
        "        'Purity': purity\n",
        "    })\n",
        "\n",
        "    print(f\"  Silhouette: {sil:.4f} | ARI: {ari:.4f} | Purity: {purity:.4f}\")\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df = results_df.sort_values('Silhouette', ascending=False)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"RESULTS SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "print(results_df.to_string(index=False))\n",
        "\n",
        "# ========== Visualizations ==========\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Creating Visualizations\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "output_dir = '/content/drive/MyDrive/clustering_results'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# 1. Performance comparison\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "metrics = ['Silhouette', 'ARI', 'NMI', 'Purity']\n",
        "colors = plt.cm.viridis(np.linspace(0, 1, len(results_df)))\n",
        "\n",
        "for idx, metric in enumerate(metrics):\n",
        "    ax = axes[idx // 2, idx % 2]\n",
        "\n",
        "    data = results_df.sort_values(metric, ascending=True)\n",
        "    bars = ax.barh(data['Combination'], data[metric], color=colors, edgecolor='black', linewidth=1.5)\n",
        "\n",
        "    ax.set_xlabel(metric, fontsize=12)\n",
        "    ax.set_title(f'{metric} Comparison', fontsize=14, fontweight='bold')\n",
        "    ax.grid(axis='x', alpha=0.3)\n",
        "\n",
        "    for bar, val in zip(bars, data[metric]):\n",
        "        width = bar.get_width()\n",
        "        ax.text(width, bar.get_y() + bar.get_height()/2.,\n",
        "                f'{val:.3f}',\n",
        "                ha='left', va='center', fontsize=10, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(output_dir, 'multimodal_comparison.png'), dpi=300, bbox_inches='tight')\n",
        "print(\" Performance comparison saved\")\n",
        "plt.show()\n",
        "\n",
        "# 2. Feature space visualization (PCA)\n",
        "fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
        "\n",
        "for idx, (name, X) in enumerate(feature_combinations.items()):\n",
        "    ax = axes[idx // 4, idx % 4]\n",
        "\n",
        "    # PCA to 2D\n",
        "    pca = PCA(n_components=2)\n",
        "    X_pca = pca.fit_transform(X)\n",
        "\n",
        "    colors_map = {'bangla': 'blue', 'english': 'red'}\n",
        "    for language in ['bangla', 'english']:\n",
        "        mask = audio_sample['language'] == language\n",
        "        ax.scatter(X_pca[mask, 0], X_pca[mask, 1],\n",
        "                  c=colors_map[language],\n",
        "                  label=language.capitalize(),\n",
        "                  alpha=0.6,\n",
        "                  edgecolors='k',\n",
        "                  s=80)\n",
        "\n",
        "    var_explained = pca.explained_variance_ratio_.sum()\n",
        "    ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%})', fontsize=10)\n",
        "    ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%})', fontsize=10)\n",
        "    ax.set_title(f'{name}\\n(Var: {var_explained:.1%})', fontsize=11, fontweight='bold')\n",
        "    ax.legend(fontsize=9)\n",
        "    ax.grid(alpha=0.3)\n",
        "\n",
        "plt.suptitle('Multi-Modal Feature Space Comparison', fontsize=16, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(output_dir, 'multimodal_pca.png'), dpi=300, bbox_inches='tight')\n",
        "print(\" PCA visualization saved\")\n",
        "plt.show()\n",
        "\n",
        "# 3. Modality contribution analysis - FIXED\n",
        "fig, ax = plt.subplots(figsize=(12, 7))\n",
        "\n",
        "single_modality = results_df[results_df['Combination'].str.contains('Only')]\n",
        "multi_modality = results_df[~results_df['Combination'].str.contains('Only')]\n",
        "\n",
        "x = np.arange(len(multi_modality))\n",
        "width = 0.35\n",
        "\n",
        "# Calculate average and repeat\n",
        "single_avg = single_modality['Silhouette'].mean()\n",
        "single_values = [single_avg] * len(multi_modality)\n",
        "\n",
        "ax.bar(x - width/2, single_values, width,\n",
        "       label=f'Single Modality Avg ({single_avg:.3f})',\n",
        "       color='lightcoral', edgecolor='black')\n",
        "ax.bar(x + width/2, multi_modality['Silhouette'].values, width,\n",
        "       label='Multi-Modal', color='skyblue', edgecolor='black')\n",
        "\n",
        "ax.set_xlabel('Feature Combination', fontsize=12)\n",
        "ax.set_ylabel('Silhouette Score', fontsize=12)\n",
        "ax.set_title('Single vs Multi-Modal Clustering Performance', fontsize=14, fontweight='bold')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(multi_modality['Combination'], rotation=45, ha='right')\n",
        "ax.legend()\n",
        "ax.grid(axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(output_dir, 'modality_contribution.png'), dpi=300, bbox_inches='tight')\n",
        "print(\" Modality contribution saved\")\n",
        "plt.show()\n",
        "\n",
        "# 4. Feature dimensionality vs performance\n",
        "fig, ax = plt.subplots(figsize=(12, 7))\n",
        "\n",
        "ax.scatter(results_df['N_Features'], results_df['Silhouette'],\n",
        "          s=300, alpha=0.7, c=range(len(results_df)),\n",
        "          cmap='viridis', edgecolors='black', linewidth=2)\n",
        "\n",
        "for _, row in results_df.iterrows():\n",
        "    ax.annotate(row['Combination'],\n",
        "                (row['N_Features'], row['Silhouette']),\n",
        "                fontsize=10, ha='center', va='bottom')\n",
        "\n",
        "ax.set_xlabel('Number of Features', fontsize=13)\n",
        "ax.set_ylabel('Silhouette Score', fontsize=13)\n",
        "ax.set_title('Feature Dimensionality vs Clustering Performance', fontsize=15, fontweight='bold')\n",
        "ax.grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(output_dir, 'dimensionality_vs_performance.png'), dpi=300, bbox_inches='tight')\n",
        "print(\" Dimensionality analysis saved\")\n",
        "plt.show()\n",
        "\n",
        "# ========== Save Results ==========\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Saving Results\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Save best features\n",
        "best_combo = results_df.iloc[0]['Combination']\n",
        "best_features = feature_combinations[best_combo]\n",
        "\n",
        "features_df = pd.DataFrame(best_features,\n",
        "                          columns=[f'feature_{i}' for i in range(best_features.shape[1])])\n",
        "features_df['filename'] = audio_sample['filename'].values\n",
        "features_df['language'] = audio_sample['language'].values\n",
        "features_df['genre'] = audio_sample['genre'].values\n",
        "\n",
        "output_path = os.path.join(output_dir, 'multimodal_features.csv')\n",
        "features_df.to_csv(output_path, index=False)\n",
        "print(f\" Best features saved: {output_path}\")\n",
        "\n",
        "# Save comparison results\n",
        "results_csv = os.path.join(output_dir, 'multimodal_comparison_results.csv')\n",
        "results_df.to_csv(results_csv, index=False)\n",
        "print(f\" Comparison results saved: {results_csv}\")\n",
        "\n",
        "# Save detailed report\n",
        "report_path = os.path.join(output_dir, 'multimodal_report.txt')\n",
        "with open(report_path, 'w') as f:\n",
        "    f.write(\"=\"*70 + \"\\n\")\n",
        "    f.write(\"MULTI-MODAL CLUSTERING REPORT\\n\")\n",
        "    f.write(\"=\"*70 + \"\\n\\n\")\n",
        "\n",
        "    f.write(\"MODALITIES:\\n\")\n",
        "    f.write(f\"  1. Audio: {audio_features.shape[1]} features (MFCC + spectral)\\n\")\n",
        "    f.write(f\"  2. Lyrics: {lyrics_features.shape[1]} features (sentence embeddings)\\n\")\n",
        "    f.write(f\"  3. Genre: {genre_features.shape[1]} features (one-hot encoded)\\n\\n\")\n",
        "\n",
        "    f.write(\"=\"*70 + \"\\n\")\n",
        "    f.write(\"PERFORMANCE RANKING\\n\")\n",
        "    f.write(\"=\"*70 + \"\\n\\n\")\n",
        "\n",
        "    for idx, row in results_df.iterrows():\n",
        "        f.write(f\"{idx+1}. {row['Combination']}\\n\")\n",
        "        f.write(f\"   Features: {row['N_Features']}\\n\")\n",
        "        f.write(f\"   Silhouette: {row['Silhouette']:.4f}\\n\")\n",
        "        f.write(f\"   ARI: {row['ARI']:.4f}\\n\")\n",
        "        f.write(f\"   NMI: {row['NMI']:.4f}\\n\")\n",
        "        f.write(f\"   Purity: {row['Purity']:.4f}\\n\\n\")\n",
        "\n",
        "    f.write(\"=\"*70 + \"\\n\")\n",
        "    f.write(\"KEY FINDINGS\\n\")\n",
        "    f.write(\"=\"*70 + \"\\n\\n\")\n",
        "\n",
        "    best = results_df.iloc[0]\n",
        "    f.write(f\"Best Combination: {best['Combination']}\\n\")\n",
        "    f.write(f\"Performance: {best['Silhouette']:.4f} (Silhouette)\\n\\n\")\n",
        "\n",
        "    f.write(\"INSIGHTS:\\n\")\n",
        "    if 'All' in best['Combination']:\n",
        "        f.write(\"   Combining all modalities provides best performance\\n\")\n",
        "        f.write(\"   Audio, lyrics, and genre are complementary\\n\")\n",
        "    elif 'Audio + Lyrics' in best['Combination']:\n",
        "        f.write(\"   Audio and lyrics together capture most information\\n\")\n",
        "        f.write(\"   Genre may be redundant or less informative\\n\")\n",
        "\n",
        "    avg_single = results_df[results_df['Combination'].str.contains('Only')]['Silhouette'].mean()\n",
        "    avg_multi = results_df[~results_df['Combination'].str.contains('Only')]['Silhouette'].mean()\n",
        "    improvement = ((avg_multi - avg_single) / avg_single) * 100\n",
        "\n",
        "    f.write(f\"\\n   Multi-modal avg: {avg_multi:.4f}\\n\")\n",
        "    f.write(f\"   Single-modal avg: {avg_single:.4f}\\n\")\n",
        "    f.write(f\"   Improvement: {improvement:+.1f}%\\n\")\n",
        "\n",
        "print(f\" Detailed report saved: {report_path}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\" MULTI-MODAL CLUSTERING COMPLETE!\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\nBest combination: {results_df.iloc[0]['Combination']}\")\n",
        "print(f\"Best score: {results_df.iloc[0]['Silhouette']:.4f}\")\n",
        "print(f\"\\nAll results saved to: {output_dir}\")"
      ],
      "metadata": {
        "id": "BUxhpj_McQdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Quantitative Clustering Evaluation: Silhouette, NMI, ARI, Purity\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (\n",
        "    silhouette_score,\n",
        "    silhouette_samples,\n",
        "    normalized_mutual_info_score,\n",
        "    adjusted_rand_score,\n",
        "    confusion_matrix\n",
        ")\n",
        "from sklearn.decomposition import PCA\n",
        "import os\n",
        "\n",
        "# Create output directory\n",
        "output_dir = '/content/drive/MyDrive/clustering_results'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"QUANTITATIVE CLUSTERING EVALUATION\")\n",
        "print(\"Metrics: Silhouette Score, NMI, ARI, Cluster Purity\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# ========== Load All Available Feature Sets ==========\n",
        "print(\"\\n1. Loading feature sets...\")\n",
        "\n",
        "feature_sets = {}\n",
        "\n",
        "# Try all possible feature files\n",
        "files_to_try = {\n",
        "    'Basic VAE': '/content/audio_vae_features.csv',\n",
        "    'Conv VAE': '/content/audio_conv_vae_features.csv',\n",
        "    'Hybrid VAE': '/content/audio_hybrid_vae_features.csv',\n",
        "    'Beta-VAE (=1)': '/content/audio_beta1_vae_features.csv',\n",
        "    'Beta-VAE (=4)': '/content/audio_beta4_vae_features.csv',\n",
        "    'Multi-Modal': os.path.join(output_dir, 'multimodal_features.csv')\n",
        "}\n",
        "\n",
        "for name, path in files_to_try.items():\n",
        "    try:\n",
        "        df = pd.read_csv(path)\n",
        "        feature_sets[name] = df\n",
        "        print(f\"   {name}: {df.shape}\")\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "if len(feature_sets) == 0:\n",
        "    print(\"\\n No feature sets found!\")\n",
        "    exit()\n",
        "\n",
        "print(f\"\\nTotal feature sets loaded: {len(feature_sets)}\")\n",
        "\n",
        "# ========== Define Evaluation Functions ==========\n",
        "\n",
        "def calculate_cluster_purity(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Calculate cluster purity\n",
        "    Purity = (1/N) * sum(max_j |w_k  c_j|)\n",
        "    \"\"\"\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    return np.sum(np.amax(cm, axis=0)) / np.sum(cm)\n",
        "\n",
        "def evaluate_clustering(X, y_true, method_name):\n",
        "    \"\"\"\n",
        "    Comprehensive clustering evaluation\n",
        "    \"\"\"\n",
        "    # Standardize\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    # K-Means clustering\n",
        "    kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
        "    y_pred = kmeans.fit_predict(X_scaled)\n",
        "\n",
        "    # Calculate all metrics\n",
        "    metrics = {\n",
        "        'Method': method_name,\n",
        "        'N_Features': X.shape[1],\n",
        "        'N_Samples': X.shape[0]\n",
        "    }\n",
        "\n",
        "    # 1. Silhouette Score\n",
        "    silhouette_avg = silhouette_score(X_scaled, y_pred)\n",
        "    silhouette_samples_vals = silhouette_samples(X_scaled, y_pred)\n",
        "\n",
        "    metrics['Silhouette_Score'] = silhouette_avg\n",
        "    metrics['Silhouette_Cluster_0'] = silhouette_samples_vals[y_pred == 0].mean()\n",
        "    metrics['Silhouette_Cluster_1'] = silhouette_samples_vals[y_pred == 1].mean()\n",
        "\n",
        "    # 2. Normalized Mutual Information\n",
        "    nmi = normalized_mutual_info_score(y_true, y_pred)\n",
        "    metrics['NMI'] = nmi\n",
        "\n",
        "    # 3. Adjusted Rand Index\n",
        "    ari = adjusted_rand_score(y_true, y_pred)\n",
        "    metrics['ARI'] = ari\n",
        "\n",
        "    # 4. Cluster Purity\n",
        "    purity = calculate_cluster_purity(y_true, y_pred)\n",
        "    metrics['Purity'] = purity\n",
        "\n",
        "    # Additional info\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    metrics['CM_00'] = cm[0, 0]  # Bangla in Cluster 0\n",
        "    metrics['CM_01'] = cm[0, 1]  # Bangla in Cluster 1\n",
        "    metrics['CM_10'] = cm[1, 0]  # English in Cluster 0\n",
        "    metrics['CM_11'] = cm[1, 1]  # English in Cluster 1\n",
        "\n",
        "    return metrics, y_pred\n",
        "\n",
        "# ========== Evaluate All Methods ==========\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"2. Evaluating all methods...\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "all_results = []\n",
        "predictions = {}\n",
        "\n",
        "for method_name, df in feature_sets.items():\n",
        "    print(f\"\\n{method_name}:\")\n",
        "\n",
        "    # Get features\n",
        "    feature_cols = [col for col in df.columns\n",
        "                   if col.startswith('feature_') or col.startswith('mfcc_') or col.startswith('spectral_')]\n",
        "    X = df[feature_cols].values\n",
        "\n",
        "    # Get true labels\n",
        "    y_true = df['language'].map({'bangla': 0, 'english': 1}).values\n",
        "\n",
        "    # Evaluate\n",
        "    metrics, y_pred = evaluate_clustering(X, y_true, method_name)\n",
        "    all_results.append(metrics)\n",
        "    predictions[method_name] = y_pred\n",
        "\n",
        "    # Print summary\n",
        "    print(f\"  Silhouette: {metrics['Silhouette_Score']:.4f}\")\n",
        "    print(f\"  NMI:        {metrics['NMI']:.4f}\")\n",
        "    print(f\"  ARI:        {metrics['ARI']:.4f}\")\n",
        "    print(f\"  Purity:     {metrics['Purity']:.4f}\")\n",
        "\n",
        "# Create results dataframe\n",
        "results_df = pd.DataFrame(all_results)\n",
        "\n",
        "# ========== DETAILED ANALYSIS ==========\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"3. RESULTS SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Sort by each metric\n",
        "print(\"\\n--- Ranked by Silhouette Score ---\")\n",
        "print(results_df[['Method', 'Silhouette_Score', 'NMI', 'ARI', 'Purity']].sort_values(\n",
        "    'Silhouette_Score', ascending=False).to_string(index=False))\n",
        "\n",
        "print(\"\\n--- Ranked by NMI ---\")\n",
        "print(results_df[['Method', 'NMI', 'Silhouette_Score', 'ARI', 'Purity']].sort_values(\n",
        "    'NMI', ascending=False).to_string(index=False))\n",
        "\n",
        "print(\"\\n--- Ranked by ARI ---\")\n",
        "print(results_df[['Method', 'ARI', 'Silhouette_Score', 'NMI', 'Purity']].sort_values(\n",
        "    'ARI', ascending=False).to_string(index=False))\n",
        "\n",
        "print(\"\\n--- Ranked by Purity ---\")\n",
        "print(results_df[['Method', 'Purity', 'Silhouette_Score', 'NMI', 'ARI']].sort_values(\n",
        "    'Purity', ascending=False).to_string(index=False))\n",
        "\n",
        "# ========== STATISTICAL SUMMARY ==========\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"4. STATISTICAL SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "metrics_summary = results_df[['Silhouette_Score', 'NMI', 'ARI', 'Purity']].describe()\n",
        "print(metrics_summary)\n",
        "\n",
        "# Best and worst performers\n",
        "print(\"\\n--- Best Performers ---\")\n",
        "best_sil = results_df.loc[results_df['Silhouette_Score'].idxmax()]\n",
        "best_nmi = results_df.loc[results_df['NMI'].idxmax()]\n",
        "best_ari = results_df.loc[results_df['ARI'].idxmax()]\n",
        "best_purity = results_df.loc[results_df['Purity'].idxmax()]\n",
        "\n",
        "print(f\"Best Silhouette: {best_sil['Method']} ({best_sil['Silhouette_Score']:.4f})\")\n",
        "print(f\"Best NMI:        {best_nmi['Method']} ({best_nmi['NMI']:.4f})\")\n",
        "print(f\"Best ARI:        {best_ari['Method']} ({best_ari['ARI']:.4f})\")\n",
        "print(f\"Best Purity:     {best_purity['Method']} ({best_purity['Purity']:.4f})\")\n",
        "\n",
        "# Overall best (average rank)\n",
        "results_df['Avg_Score'] = results_df[['Silhouette_Score', 'NMI', 'ARI', 'Purity']].mean(axis=1)\n",
        "best_overall = results_df.loc[results_df['Avg_Score'].idxmax()]\n",
        "print(f\"\\nOverall Best:    {best_overall['Method']} (Avg: {best_overall['Avg_Score']:.4f})\")\n",
        "\n",
        "# ========== VISUALIZATIONS ==========\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"5. Creating visualizations...\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# 1. Four metrics comparison\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "metrics_to_plot = ['Silhouette_Score', 'NMI', 'ARI', 'Purity']\n",
        "metric_names = ['Silhouette Score', 'Normalized Mutual Information',\n",
        "                'Adjusted Rand Index', 'Cluster Purity']\n",
        "colors = ['#3498db', '#e74c3c', '#2ecc71', '#f39c12']\n",
        "\n",
        "for idx, (metric, name, color) in enumerate(zip(metrics_to_plot, metric_names, colors)):\n",
        "    ax = axes[idx // 2, idx % 2]\n",
        "\n",
        "    data = results_df.sort_values(metric, ascending=True)\n",
        "    bars = ax.barh(data['Method'], data[metric], color=color,\n",
        "                   edgecolor='black', linewidth=1.5, alpha=0.8)\n",
        "\n",
        "    ax.set_xlabel(name, fontsize=12, fontweight='bold')\n",
        "    ax.set_title(f'{name} Comparison', fontsize=14, fontweight='bold')\n",
        "    ax.grid(axis='x', alpha=0.3)\n",
        "    ax.set_xlim([0, 1.0])\n",
        "\n",
        "    # Add value labels\n",
        "    for bar, val in zip(bars, data[metric]):\n",
        "        width = bar.get_width()\n",
        "        ax.text(width + 0.01, bar.get_y() + bar.get_height()/2.,\n",
        "                f'{val:.3f}',\n",
        "                ha='left', va='center', fontsize=10, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(output_dir, 'quantitative_evaluation.png'), dpi=300, bbox_inches='tight')\n",
        "print(\"   Four metrics comparison saved\")\n",
        "plt.show()\n",
        "\n",
        "# 2. Radar chart for all methods\n",
        "from math import pi\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 12), subplot_kw=dict(projection='polar'))\n",
        "\n",
        "categories = ['Silhouette', 'NMI', 'ARI', 'Purity']\n",
        "N = len(categories)\n",
        "\n",
        "angles = [n / float(N) * 2 * pi for n in range(N)]\n",
        "angles += angles[:1]\n",
        "\n",
        "colors_map = plt.cm.tab10(np.linspace(0, 1, len(results_df)))\n",
        "\n",
        "for idx, row in results_df.iterrows():\n",
        "    values = [row['Silhouette_Score'], row['NMI'], row['ARI'], row['Purity']]\n",
        "    values += values[:1]\n",
        "\n",
        "    ax.plot(angles, values, 'o-', linewidth=2, label=row['Method'],\n",
        "            color=colors_map[idx], alpha=0.7)\n",
        "    ax.fill(angles, values, alpha=0.15, color=colors_map[idx])\n",
        "\n",
        "ax.set_xticks(angles[:-1])\n",
        "ax.set_xticklabels(categories, fontsize=13, fontweight='bold')\n",
        "ax.set_ylim(0, 1)\n",
        "ax.set_title('Multi-Metric Performance Comparison',\n",
        "             fontsize=16, fontweight='bold', pad=30)\n",
        "ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1), fontsize=10)\n",
        "ax.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(output_dir, 'metrics_radar_chart.png'), dpi=300, bbox_inches='tight')\n",
        "print(\"   Radar chart saved\")\n",
        "plt.show()\n",
        "\n",
        "# 3. Correlation heatmap between metrics\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "\n",
        "corr_matrix = results_df[['Silhouette_Score', 'NMI', 'ARI', 'Purity']].corr()\n",
        "\n",
        "sns.heatmap(corr_matrix, annot=True, fmt='.3f', cmap='coolwarm',\n",
        "            center=0, square=True, linewidths=2, cbar_kws={\"shrink\": 0.8},\n",
        "            xticklabels=['Silhouette', 'NMI', 'ARI', 'Purity'],\n",
        "            yticklabels=['Silhouette', 'NMI', 'ARI', 'Purity'],\n",
        "            ax=ax, annot_kws={'size': 14, 'weight': 'bold'})\n",
        "\n",
        "ax.set_title('Metric Correlation Matrix', fontsize=16, fontweight='bold', pad=15)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(output_dir, 'metric_correlation.png'), dpi=300, bbox_inches='tight')\n",
        "print(\"   Correlation heatmap saved\")\n",
        "plt.show()\n",
        "\n",
        "# 4. Confusion matrices\n",
        "n_methods = len(feature_sets)\n",
        "n_cols = 3\n",
        "n_rows = (n_methods + n_cols - 1) // n_cols\n",
        "\n",
        "fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5*n_rows))\n",
        "axes = axes.flatten() if n_methods > 1 else [axes]\n",
        "\n",
        "for idx, (method_name, row) in enumerate(results_df.iterrows()):\n",
        "    ax = axes[idx]\n",
        "\n",
        "    cm = np.array([[row['CM_00'], row['CM_01']],\n",
        "                   [row['CM_10'], row['CM_11']]])\n",
        "\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=['Cluster 0', 'Cluster 1'],\n",
        "                yticklabels=['Bangla', 'English'],\n",
        "                cbar=False, ax=ax,\n",
        "                annot_kws={'size': 14, 'weight': 'bold'})\n",
        "\n",
        "    ax.set_title(f\"{row['Method']}\\nPurity: {row['Purity']:.3f}\",\n",
        "                fontsize=12, fontweight='bold')\n",
        "\n",
        "# Hide empty subplots\n",
        "for idx in range(len(feature_sets), len(axes)):\n",
        "    axes[idx].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(output_dir, 'confusion_matrices.png'), dpi=300, bbox_inches='tight')\n",
        "print(\"   Confusion matrices saved\")\n",
        "plt.show()\n",
        "\n",
        "# 5. Silhouette analysis for best method\n",
        "best_method_name = best_overall['Method']\n",
        "best_df = feature_sets[best_method_name]\n",
        "feature_cols = [col for col in best_df.columns\n",
        "               if col.startswith('feature_') or col.startswith('mfcc_') or col.startswith('spectral_')]\n",
        "X = best_df[feature_cols].values\n",
        "y_true = best_df['language'].map({'bangla': 0, 'english': 1}).values\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
        "y_pred = kmeans.fit_predict(X_scaled)\n",
        "silhouette_vals = silhouette_samples(X_scaled, y_pred)\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Silhouette plot\n",
        "y_lower = 10\n",
        "colors_sil = ['#3498db', '#e74c3c']\n",
        "\n",
        "for i in range(2):\n",
        "    cluster_silhouette_vals = silhouette_vals[y_pred == i]\n",
        "    cluster_silhouette_vals.sort()\n",
        "\n",
        "    size_cluster_i = cluster_silhouette_vals.shape[0]\n",
        "    y_upper = y_lower + size_cluster_i\n",
        "\n",
        "    ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
        "                      0, cluster_silhouette_vals,\n",
        "                      facecolor=colors_sil[i], edgecolor=colors_sil[i], alpha=0.7)\n",
        "\n",
        "    ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i),\n",
        "            fontsize=14, fontweight='bold')\n",
        "    y_lower = y_upper + 10\n",
        "\n",
        "silhouette_avg = silhouette_score(X_scaled, y_pred)\n",
        "ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\", linewidth=2)\n",
        "ax1.set_xlabel(\"Silhouette Coefficient\", fontsize=13)\n",
        "ax1.set_ylabel(\"Cluster\", fontsize=13)\n",
        "ax1.set_title(f'Silhouette Plot: {best_method_name}\\n(Score: {silhouette_avg:.3f})',\n",
        "             fontsize=14, fontweight='bold')\n",
        "ax1.set_yticks([])\n",
        "ax1.grid(alpha=0.3, axis='x')\n",
        "\n",
        "# Distribution\n",
        "for i in range(2):\n",
        "    cluster_silhouette_vals = silhouette_vals[y_pred == i]\n",
        "    ax2.hist(cluster_silhouette_vals, bins=30, alpha=0.6,\n",
        "            label=f'Cluster {i}', color=colors_sil[i], edgecolor='black')\n",
        "\n",
        "ax2.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\", linewidth=2,\n",
        "           label=f'Average: {silhouette_avg:.3f}')\n",
        "ax2.set_xlabel(\"Silhouette Coefficient\", fontsize=13)\n",
        "ax2.set_ylabel(\"Frequency\", fontsize=13)\n",
        "ax2.set_title('Silhouette Distribution', fontsize=14, fontweight='bold')\n",
        "ax2.legend(fontsize=11)\n",
        "ax2.grid(alpha=0.3, axis='y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(output_dir, 'best_method_silhouette.png'), dpi=300, bbox_inches='tight')\n",
        "print(\"   Best method silhouette analysis saved\")\n",
        "plt.show()\n",
        "\n",
        "# ========== SAVE RESULTS ==========\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"6. Saving results...\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Save full results\n",
        "results_csv = os.path.join(output_dir, 'quantitative_evaluation_results.csv')\n",
        "results_df.to_csv(results_csv, index=False)\n",
        "print(f\"   Results saved: {results_csv}\")\n",
        "\n",
        "# Save detailed report\n",
        "report_path = os.path.join(output_dir, 'quantitative_evaluation_report.txt')\n",
        "with open(report_path, 'w') as f:\n",
        "    f.write(\"=\"*80 + \"\\n\")\n",
        "    f.write(\"QUANTITATIVE CLUSTERING EVALUATION REPORT\\n\")\n",
        "    f.write(\"=\"*80 + \"\\n\\n\")\n",
        "\n",
        "    f.write(\"METRICS EVALUATED:\\n\")\n",
        "    f.write(\"-\" * 80 + \"\\n\")\n",
        "    f.write(\"1. Silhouette Score\\n\")\n",
        "    f.write(\"   - Range: [-1, 1]\\n\")\n",
        "    f.write(\"   - Interpretation: Higher is better\\n\")\n",
        "    f.write(\"   - Measures: How similar samples are to their own cluster vs others\\n\\n\")\n",
        "\n",
        "    f.write(\"2. Normalized Mutual Information (NMI)\\n\")\n",
        "    f.write(\"   - Range: [0, 1]\\n\")\n",
        "    f.write(\"   - Interpretation: Higher is better\\n\")\n",
        "    f.write(\"   - Measures: Mutual information between true and predicted labels\\n\\n\")\n",
        "\n",
        "    f.write(\"3. Adjusted Rand Index (ARI)\\n\")\n",
        "    f.write(\"   - Range: [-1, 1]\\n\")\n",
        "    f.write(\"   - Interpretation: Higher is better (1 = perfect match)\\n\")\n",
        "    f.write(\"   - Measures: Similarity between true and predicted clustering\\n\\n\")\n",
        "\n",
        "    f.write(\"4. Cluster Purity\\n\")\n",
        "    f.write(\"   - Range: [0, 1]\\n\")\n",
        "    f.write(\"   - Interpretation: Higher is better\\n\")\n",
        "    f.write(\"   - Measures: Percentage of correctly clustered samples\\n\\n\")\n",
        "\n",
        "    f.write(\"=\"*80 + \"\\n\")\n",
        "    f.write(\"RESULTS SUMMARY\\n\")\n",
        "    f.write(\"=\"*80 + \"\\n\\n\")\n",
        "\n",
        "    f.write(results_df[['Method', 'Silhouette_Score', 'NMI', 'ARI', 'Purity']].to_string(index=False))\n",
        "    f.write(\"\\n\\n\")\n",
        "\n",
        "    f.write(\"=\"*80 + \"\\n\")\n",
        "    f.write(\"BEST PERFORMERS\\n\")\n",
        "    f.write(\"=\"*80 + \"\\n\\n\")\n",
        "\n",
        "    f.write(f\"Best Silhouette Score: {best_sil['Method']} ({best_sil['Silhouette_Score']:.4f})\\n\")\n",
        "    f.write(f\"Best NMI:              {best_nmi['Method']} ({best_nmi['NMI']:.4f})\\n\")\n",
        "    f.write(f\"Best ARI:              {best_ari['Method']} ({best_ari['ARI']:.4f})\\n\")\n",
        "    f.write(f\"Best Purity:           {best_purity['Method']} ({best_purity['Purity']:.4f})\\n\\n\")\n",
        "    f.write(f\"Overall Best:          {best_overall['Method']} (Avg: {best_overall['Avg_Score']:.4f})\\n\\n\")\n",
        "\n",
        "    f.write(\"=\"*80 + \"\\n\")\n",
        "    f.write(\"STATISTICAL SUMMARY\\n\")\n",
        "    f.write(\"=\"*80 + \"\\n\\n\")\n",
        "    f.write(metrics_summary.to_string())\n",
        "    f.write(\"\\n\\n\")\n",
        "\n",
        "    f.write(\"=\"*80 + \"\\n\")\n",
        "    f.write(\"METRIC CORRELATIONS\\n\")\n",
        "    f.write(\"=\"*80 + \"\\n\\n\")\n",
        "    f.write(corr_matrix.to_string())\n",
        "    f.write(\"\\n\\n\")\n",
        "\n",
        "    f.write(\"=\"*80 + \"\\n\")\n",
        "    f.write(\"KEY INSIGHTS\\n\")\n",
        "    f.write(\"=\"*80 + \"\\n\\n\")\n",
        "\n",
        "    # Calculate insights\n",
        "    high_corr = corr_matrix.abs().values[np.triu_indices_from(corr_matrix.values, k=1)].max()\n",
        "\n",
        "    f.write(f\" Tested {len(feature_sets)} different methods\\n\")\n",
        "    f.write(f\" Average Silhouette Score: {results_df['Silhouette_Score'].mean():.4f}\\n\")\n",
        "    f.write(f\" Average NMI: {results_df['NMI'].mean():.4f}\\n\")\n",
        "    f.write(f\" Average ARI: {results_df['ARI'].mean():.4f}\\n\")\n",
        "    f.write(f\" Average Purity: {results_df['Purity'].mean():.4f}\\n\\n\")\n",
        "\n",
        "    f.write(f\" Highest metric correlation: {high_corr:.3f}\\n\")\n",
        "    f.write(f\" Best overall method: {best_overall['Method']}\\n\")\n",
        "\n",
        "    if best_overall['Silhouette_Score'] > 0.5 and best_overall['ARI'] > 0.5:\n",
        "        f.write(f\" Clustering quality: GOOD to EXCELLENT\\n\")\n",
        "    elif best_overall['Silhouette_Score'] > 0.3 and best_overall['ARI'] > 0.3:\n",
        "        f.write(f\" Clustering quality: MODERATE\\n\")\n",
        "    else:\n",
        "        f.write(f\" Clustering quality: WEAK\\n\")\n",
        "\n",
        "print(f\"   Detailed report saved: {report_path}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\" QUANTITATIVE EVALUATION COMPLETE!\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nEvaluated {len(feature_sets)} methods\")\n",
        "print(f\"Best overall: {best_overall['Method']}\")\n",
        "print(f\"  - Silhouette: {best_overall['Silhouette_Score']:.4f}\")\n",
        "print(f\"  - NMI:        {best_overall['NMI']:.4f}\")\n",
        "print(f\"  - ARI:        {best_overall['ARI']:.4f}\")\n",
        "print(f\"  - Purity:     {best_overall['Purity']:.4f}\")\n",
        "print(f\"\\nAll results saved to: {output_dir}\")"
      ],
      "metadata": {
        "id": "UUz9lTX9fJ3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Comprehensive VAE Visualizations: Latent Space, Distributions, Reconstructions\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.cluster import KMeans\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import librosa\n",
        "import librosa.display\n",
        "import os\n",
        "\n",
        "output_dir = '/content/drive/MyDrive/clustering_results/visualizations'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"COMPREHENSIVE VAE VISUALIZATIONS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# ========== Load Data ==========\n",
        "print(\"\\n1. Loading VAE features and metadata...\")\n",
        "\n",
        "# Try to load features\n",
        "try:\n",
        "    features_df = pd.read_csv('/content/audio_hybrid_vae_features.csv')\n",
        "    model_type = \"Hybrid VAE\"\n",
        "    latent_dim = 64\n",
        "except:\n",
        "    try:\n",
        "        features_df = pd.read_csv('/content/audio_conv_vae_features.csv')\n",
        "        model_type = \"Conv VAE\"\n",
        "        latent_dim = 64\n",
        "    except:\n",
        "        features_df = pd.read_csv('/content/audio_vae_features.csv')\n",
        "        model_type = \"Basic VAE\"\n",
        "        latent_dim = 32\n",
        "\n",
        "print(f\" Loaded {model_type}\")\n",
        "print(f\"Shape: {features_df.shape}\")\n",
        "\n",
        "# Load metadata\n",
        "dataset_folder = '/content/extracted_data/MyDataset'\n",
        "metadata = pd.read_excel(os.path.join(dataset_folder, 'metadata.xlsx'))\n",
        "\n",
        "# Merge for genre info\n",
        "features_df = features_df.merge(\n",
        "    metadata[['filenaming', 'genre']],\n",
        "    left_on='filename',\n",
        "    right_on='filenaming',\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "# clean up\n",
        "features_df.drop(columns=['filenaming'], inplace=True)\n",
        "\n",
        "features_df['genre'] = features_df['genre'].fillna('Unknown')\n",
        "\n",
        "print(f\"Languages: {features_df['language'].value_counts().to_dict()}\")\n",
        "print(f\"Genres: {features_df['genre'].value_counts().to_dict()}\")\n",
        "\n",
        "# Get feature matrix\n",
        "feature_cols = [col for col in features_df.columns if col.startswith('feature_')]\n",
        "X = features_df[feature_cols].values\n",
        "\n",
        "print(f\"Feature matrix: {X.shape}\")\n",
        "\n",
        "# ========== 1. LATENT SPACE VISUALIZATIONS ==========\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"2. Creating Latent Space Visualizations\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Standardize\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# PCA\n",
        "print(\"  Computing PCA...\")\n",
        "pca = PCA(n_components=min(10, X.shape[1]))\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "# t-SNE\n",
        "print(\"  Computing t-SNE...\")\n",
        "tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
        "X_tsne = tsne.fit_transform(X_scaled)\n",
        "\n",
        "# K-Means for clusters\n",
        "kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
        "clusters = kmeans.fit_predict(X_scaled)\n",
        "\n",
        "# === Visualization 1: Multi-view Latent Space ===\n",
        "fig = plt.figure(figsize=(20, 15))\n",
        "gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
        "\n",
        "colors_lang = {'bangla': '#3498db', 'english': '#e74c3c'}\n",
        "colors_cluster = ['#2ecc71', '#9b59b6']\n",
        "\n",
        "# Row 1: PCA views\n",
        "ax1 = fig.add_subplot(gs[0, 0])\n",
        "for lang in ['bangla', 'english']:\n",
        "    mask = features_df['language'] == lang\n",
        "    ax1.scatter(X_pca[mask, 0], X_pca[mask, 1],\n",
        "               c=colors_lang[lang], label=lang.capitalize(),\n",
        "               alpha=0.6, s=80, edgecolors='k')\n",
        "ax1.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%})', fontsize=11)\n",
        "ax1.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%})', fontsize=11)\n",
        "ax1.set_title('PCA: Colored by Language', fontsize=13, fontweight='bold')\n",
        "ax1.legend()\n",
        "ax1.grid(alpha=0.3)\n",
        "\n",
        "ax2 = fig.add_subplot(gs[0, 1])\n",
        "for i in range(2):\n",
        "    mask = clusters == i\n",
        "    ax2.scatter(X_pca[mask, 0], X_pca[mask, 1],\n",
        "               c=colors_cluster[i], label=f'Cluster {i}',\n",
        "               alpha=0.6, s=80, edgecolors='k')\n",
        "ax2.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%})', fontsize=11)\n",
        "ax2.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%})', fontsize=11)\n",
        "ax2.set_title('PCA: Colored by Cluster', fontsize=13, fontweight='bold')\n",
        "ax2.legend()\n",
        "ax2.grid(alpha=0.3)\n",
        "\n",
        "ax3 = fig.add_subplot(gs[0, 2])\n",
        "genres = features_df['genre'].unique()\n",
        "genre_colors = plt.cm.Set3(np.linspace(0, 1, len(genres)))\n",
        "for genre, color in zip(genres, genre_colors):\n",
        "    mask = features_df['genre'] == genre\n",
        "    ax3.scatter(X_pca[mask, 0], X_pca[mask, 1],\n",
        "               c=[color], label=genre,\n",
        "               alpha=0.6, s=80, edgecolors='k')\n",
        "ax3.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%})', fontsize=11)\n",
        "ax3.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%})', fontsize=11)\n",
        "ax3.set_title('PCA: Colored by Genre', fontsize=13, fontweight='bold')\n",
        "ax3.legend(fontsize=8, loc='best')\n",
        "ax3.grid(alpha=0.3)\n",
        "\n",
        "# Row 2: t-SNE views\n",
        "ax4 = fig.add_subplot(gs[1, 0])\n",
        "for lang in ['bangla', 'english']:\n",
        "    mask = features_df['language'] == lang\n",
        "    ax4.scatter(X_tsne[mask, 0], X_tsne[mask, 1],\n",
        "               c=colors_lang[lang], label=lang.capitalize(),\n",
        "               alpha=0.6, s=80, edgecolors='k')\n",
        "ax4.set_xlabel('t-SNE 1', fontsize=11)\n",
        "ax4.set_ylabel('t-SNE 2', fontsize=11)\n",
        "ax4.set_title('t-SNE: Colored by Language', fontsize=13, fontweight='bold')\n",
        "ax4.legend()\n",
        "ax4.grid(alpha=0.3)\n",
        "\n",
        "ax5 = fig.add_subplot(gs[1, 1])\n",
        "for i in range(2):\n",
        "    mask = clusters == i\n",
        "    ax5.scatter(X_tsne[mask, 0], X_tsne[mask, 1],\n",
        "               c=colors_cluster[i], label=f'Cluster {i}',\n",
        "               alpha=0.6, s=80, edgecolors='k')\n",
        "ax5.set_xlabel('t-SNE 1', fontsize=11)\n",
        "ax5.set_ylabel('t-SNE 2', fontsize=11)\n",
        "ax5.set_title('t-SNE: Colored by Cluster', fontsize=13, fontweight='bold')\n",
        "ax5.legend()\n",
        "ax5.grid(alpha=0.3)\n",
        "\n",
        "ax6 = fig.add_subplot(gs[1, 2])\n",
        "for genre, color in zip(genres, genre_colors):\n",
        "    mask = features_df['genre'] == genre\n",
        "    ax6.scatter(X_tsne[mask, 0], X_tsne[mask, 1],\n",
        "               c=[color], label=genre,\n",
        "               alpha=0.6, s=80, edgecolors='k')\n",
        "ax6.set_xlabel('t-SNE 1', fontsize=11)\n",
        "ax6.set_ylabel('t-SNE 2', fontsize=11)\n",
        "ax6.set_title('t-SNE: Colored by Genre', fontsize=13, fontweight='bold')\n",
        "ax6.legend(fontsize=8, loc='best')\n",
        "ax6.grid(alpha=0.3)\n",
        "\n",
        "# Row 3: PCA variance and feature distributions\n",
        "ax7 = fig.add_subplot(gs[2, 0])\n",
        "var_explained = pca.explained_variance_ratio_[:10]\n",
        "cumsum_var = np.cumsum(var_explained)\n",
        "ax7.bar(range(1, len(var_explained)+1), var_explained, alpha=0.7, color='skyblue', edgecolor='black')\n",
        "ax7.plot(range(1, len(var_explained)+1), cumsum_var, 'ro-', linewidth=2, markersize=8)\n",
        "ax7.set_xlabel('Principal Component', fontsize=11)\n",
        "ax7.set_ylabel('Variance Explained', fontsize=11)\n",
        "ax7.set_title('PCA Variance Explained', fontsize=13, fontweight='bold')\n",
        "ax7.grid(alpha=0.3, axis='y')\n",
        "ax7.legend(['Cumulative', 'Individual'], fontsize=10)\n",
        "\n",
        "# First two latent dimensions distribution\n",
        "ax8 = fig.add_subplot(gs[2, 1])\n",
        "for lang in ['bangla', 'english']:\n",
        "    mask = features_df['language'] == lang\n",
        "    ax8.hist(X[:, 0][mask], bins=30, alpha=0.5, label=lang.capitalize(), edgecolor='black')\n",
        "ax8.set_xlabel('First Latent Dimension', fontsize=11)\n",
        "ax8.set_ylabel('Frequency', fontsize=11)\n",
        "ax8.set_title('Latent Dimension 1 Distribution', fontsize=13, fontweight='bold')\n",
        "ax8.legend()\n",
        "ax8.grid(alpha=0.3, axis='y')\n",
        "\n",
        "ax9 = fig.add_subplot(gs[2, 2])\n",
        "for lang in ['bangla', 'english']:\n",
        "    mask = features_df['language'] == lang\n",
        "    ax9.hist(X[:, 1][mask], bins=30, alpha=0.5, label=lang.capitalize(), edgecolor='black')\n",
        "ax9.set_xlabel('Second Latent Dimension', fontsize=11)\n",
        "ax9.set_ylabel('Frequency', fontsize=11)\n",
        "ax9.set_title('Latent Dimension 2 Distribution', fontsize=13, fontweight='bold')\n",
        "ax9.legend()\n",
        "ax9.grid(alpha=0.3, axis='y')\n",
        "\n",
        "plt.suptitle(f'{model_type}: Latent Space Analysis', fontsize=18, fontweight='bold', y=0.995)\n",
        "plt.savefig(os.path.join(output_dir, 'latent_space_comprehensive.png'), dpi=300, bbox_inches='tight')\n",
        "print(\"   Comprehensive latent space visualization saved\")\n",
        "plt.show()\n",
        "\n",
        "# ========== 2. CLUSTER DISTRIBUTIONS ==========\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"3. Creating Cluster Distribution Visualizations\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "\n",
        "# Language distribution\n",
        "ax1 = axes[0, 0]\n",
        "lang_counts = features_df['language'].value_counts()\n",
        "bars = ax1.bar(lang_counts.index, lang_counts.values,\n",
        "               color=['#3498db', '#e74c3c'], edgecolor='black', linewidth=2)\n",
        "ax1.set_ylabel('Count', fontsize=12)\n",
        "ax1.set_title('Distribution by Language', fontsize=14, fontweight='bold')\n",
        "ax1.grid(alpha=0.3, axis='y')\n",
        "for bar, val in zip(bars, lang_counts.values):\n",
        "    ax1.text(bar.get_x() + bar.get_width()/2., bar.get_height(),\n",
        "            f'{val}', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
        "\n",
        "# Genre distribution\n",
        "ax2 = axes[0, 1]\n",
        "genre_counts = features_df['genre'].value_counts()\n",
        "bars = ax2.bar(range(len(genre_counts)), genre_counts.values,\n",
        "               color=plt.cm.Set3(np.linspace(0, 1, len(genre_counts))),\n",
        "               edgecolor='black', linewidth=2)\n",
        "ax2.set_xticks(range(len(genre_counts)))\n",
        "ax2.set_xticklabels(genre_counts.index, rotation=45, ha='right')\n",
        "ax2.set_ylabel('Count', fontsize=12)\n",
        "ax2.set_title('Distribution by Genre', fontsize=14, fontweight='bold')\n",
        "ax2.grid(alpha=0.3, axis='y')\n",
        "for bar, val in zip(bars, genre_counts.values):\n",
        "    ax2.text(bar.get_x() + bar.get_width()/2., bar.get_height(),\n",
        "            f'{val}', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
        "\n",
        "# Cluster distribution\n",
        "ax3 = axes[0, 2]\n",
        "cluster_counts = pd.Series(clusters).value_counts().sort_index()\n",
        "bars = ax3.bar(cluster_counts.index, cluster_counts.values,\n",
        "               color=['#2ecc71', '#9b59b6'], edgecolor='black', linewidth=2)\n",
        "ax3.set_xlabel('Cluster', fontsize=12)\n",
        "ax3.set_ylabel('Count', fontsize=12)\n",
        "ax3.set_title('Distribution by Cluster', fontsize=14, fontweight='bold')\n",
        "ax3.grid(alpha=0.3, axis='y')\n",
        "for bar, val in zip(bars, cluster_counts.values):\n",
        "    ax3.text(bar.get_x() + bar.get_width()/2., bar.get_height(),\n",
        "            f'{val}', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
        "\n",
        "# Language vs Cluster (stacked)\n",
        "ax4 = axes[1, 0]\n",
        "crosstab = pd.crosstab(features_df['language'], clusters)\n",
        "crosstab.plot(kind='bar', stacked=True, ax=ax4,\n",
        "              color=['#2ecc71', '#9b59b6'], edgecolor='black', linewidth=1.5)\n",
        "ax4.set_xlabel('Language', fontsize=12)\n",
        "ax4.set_ylabel('Count', fontsize=12)\n",
        "ax4.set_title('Language vs Cluster', fontsize=14, fontweight='bold')\n",
        "ax4.set_xticklabels(ax4.get_xticklabels(), rotation=0)\n",
        "ax4.legend(title='Cluster', labels=['Cluster 0', 'Cluster 1'])\n",
        "ax4.grid(alpha=0.3, axis='y')\n",
        "\n",
        "# Genre vs Language (heatmap)\n",
        "ax5 = axes[1, 1]\n",
        "genre_lang = pd.crosstab(features_df['genre'], features_df['language'])\n",
        "sns.heatmap(genre_lang, annot=True, fmt='d', cmap='YlOrRd',\n",
        "            ax=ax5, cbar_kws={'label': 'Count'}, linewidths=2)\n",
        "ax5.set_title('Genre vs Language', fontsize=14, fontweight='bold')\n",
        "ax5.set_xlabel('Language', fontsize=12)\n",
        "ax5.set_ylabel('Genre', fontsize=12)\n",
        "\n",
        "# Genre vs Cluster (heatmap)\n",
        "ax6 = axes[1, 2]\n",
        "features_df['cluster'] = clusters\n",
        "genre_cluster = pd.crosstab(features_df['genre'], features_df['cluster'])\n",
        "sns.heatmap(genre_cluster, annot=True, fmt='d', cmap='Blues',\n",
        "            ax=ax6, cbar_kws={'label': 'Count'}, linewidths=2)\n",
        "ax6.set_title('Genre vs Cluster', fontsize=14, fontweight='bold')\n",
        "ax6.set_xlabel('Cluster', fontsize=12)\n",
        "ax6.set_ylabel('Genre', fontsize=12)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(output_dir, 'cluster_distributions.png'), dpi=300, bbox_inches='tight')\n",
        "print(\"   Cluster distribution visualization saved\")\n",
        "plt.show()\n",
        "\n",
        "# ========== 3. VAE RECONSTRUCTIONS ==========\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"4. Creating VAE Reconstruction Examples\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Load audio samples for reconstruction visualization\n",
        "audio_folder = os.path.join(dataset_folder, 'audio')\n",
        "bangla_folder = os.path.join(audio_folder, 'bangla')\n",
        "english_folder = os.path.join(audio_folder, 'english')\n",
        "\n",
        "# Select sample files\n",
        "sample_files = []\n",
        "sample_labels = []\n",
        "\n",
        "bangla_files = [f for f in os.listdir(bangla_folder) if f.endswith('.mp3')][:2]\n",
        "english_files = [f for f in os.listdir(english_folder) if f.endswith('.mp3')][:2]\n",
        "\n",
        "for f in bangla_files:\n",
        "    sample_files.append(os.path.join(bangla_folder, f))\n",
        "    sample_labels.append('Bangla')\n",
        "\n",
        "for f in english_files:\n",
        "    sample_files.append(os.path.join(english_folder, f))\n",
        "    sample_labels.append('English')\n",
        "\n",
        "print(f\"  Visualizing {len(sample_files)} audio samples...\")\n",
        "\n",
        "# Create spectrograms\n",
        "fig, axes = plt.subplots(len(sample_files), 3, figsize=(18, 4*len(sample_files)))\n",
        "\n",
        "for idx, (audio_path, label) in enumerate(zip(sample_files, sample_labels)):\n",
        "    # Load audio\n",
        "    y, sr = librosa.load(audio_path, duration=3.0, sr=22050)\n",
        "\n",
        "    # Original spectrogram\n",
        "    D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)\n",
        "    img1 = librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='hz',\n",
        "                                     ax=axes[idx, 0], cmap='viridis')\n",
        "    axes[idx, 0].set_title(f'{label} - Original Spectrogram', fontsize=12, fontweight='bold')\n",
        "    axes[idx, 0].set_ylabel('Frequency (Hz)', fontsize=10)\n",
        "\n",
        "    # MFCC representation\n",
        "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=20)\n",
        "    img2 = librosa.display.specshow(mfcc, sr=sr, x_axis='time',\n",
        "                                     ax=axes[idx, 1], cmap='coolwarm')\n",
        "    axes[idx, 1].set_title(f'{label} - MFCC Features', fontsize=12, fontweight='bold')\n",
        "    axes[idx, 1].set_ylabel('MFCC Coefficient', fontsize=10)\n",
        "\n",
        "    # Mel spectrogram (reconstruction target)\n",
        "    mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
        "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
        "    img3 = librosa.display.specshow(mel_spec_db, sr=sr, x_axis='time', y_axis='mel',\n",
        "                                     ax=axes[idx, 2], cmap='magma')\n",
        "    axes[idx, 2].set_title(f'{label} - Mel Spectrogram', fontsize=12, fontweight='bold')\n",
        "    axes[idx, 2].set_ylabel('Mel Frequency', fontsize=10)\n",
        "\n",
        "    # Add colorbars\n",
        "    plt.colorbar(img1, ax=axes[idx, 0], format='%+2.0f dB')\n",
        "    plt.colorbar(img2, ax=axes[idx, 1])\n",
        "    plt.colorbar(img3, ax=axes[idx, 2], format='%+2.0f dB')\n",
        "\n",
        "plt.suptitle('Audio Representations: Original  Features  Reconstruction Target',\n",
        "             fontsize=16, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(output_dir, 'vae_reconstructions.png'), dpi=300, bbox_inches='tight')\n",
        "print(\"   VAE reconstruction examples saved\")\n",
        "plt.show()\n",
        "\n",
        "# ========== 4. LATENT SPACE DENSITY ==========\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"5. Creating Latent Space Density Plots\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
        "\n",
        "# PCA density\n",
        "ax1 = axes[0]\n",
        "for lang in ['bangla', 'english']:\n",
        "    mask = features_df['language'] == lang\n",
        "    ax1.scatter(X_pca[mask, 0], X_pca[mask, 1],\n",
        "               c=colors_lang[lang], label=lang.capitalize(),\n",
        "               alpha=0.3, s=50)\n",
        "\n",
        "    # Add contour for density\n",
        "    from scipy.stats import gaussian_kde\n",
        "    xy = np.vstack([X_pca[mask, 0], X_pca[mask, 1]])\n",
        "    z = gaussian_kde(xy)(xy)\n",
        "    idx = z.argsort()\n",
        "    x, y, z = X_pca[mask, 0][idx], X_pca[mask, 1][idx], z[idx]\n",
        "    ax1.scatter(x, y, c=z, s=50, cmap='Reds' if lang == 'english' else 'Blues', alpha=0.6)\n",
        "\n",
        "ax1.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%})', fontsize=12)\n",
        "ax1.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%})', fontsize=12)\n",
        "ax1.set_title('PCA: Density Plot', fontsize=14, fontweight='bold')\n",
        "ax1.grid(alpha=0.3)\n",
        "\n",
        "# t-SNE density\n",
        "ax2 = axes[1]\n",
        "for lang in ['bangla', 'english']:\n",
        "    mask = features_df['language'] == lang\n",
        "    ax2.scatter(X_tsne[mask, 0], X_tsne[mask, 1],\n",
        "               c=colors_lang[lang], label=lang.capitalize(),\n",
        "               alpha=0.3, s=50)\n",
        "\n",
        "    xy = np.vstack([X_tsne[mask, 0], X_tsne[mask, 1]])\n",
        "    z = gaussian_kde(xy)(xy)\n",
        "    idx = z.argsort()\n",
        "    x, y, z = X_tsne[mask, 0][idx], X_tsne[mask, 1][idx], z[idx]\n",
        "    ax2.scatter(x, y, c=z, s=50, cmap='Reds' if lang == 'english' else 'Blues', alpha=0.6)\n",
        "\n",
        "ax2.set_xlabel('t-SNE 1', fontsize=12)\n",
        "ax2.set_ylabel('t-SNE 2', fontsize=12)\n",
        "ax2.set_title('t-SNE: Density Plot', fontsize=14, fontweight='bold')\n",
        "ax2.grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(output_dir, 'latent_space_density.png'), dpi=300, bbox_inches='tight')\n",
        "print(\"   Latent space density plots saved\")\n",
        "plt.show()\n",
        "\n",
        "# ========== 5. FEATURE CORRELATION MATRIX ==========\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"6. Creating Feature Correlation Analysis\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Select first 16 features for visualization\n",
        "n_features_viz = min(16, X.shape[1])\n",
        "X_subset = X[:, :n_features_viz]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 10))\n",
        "\n",
        "corr_matrix = np.corrcoef(X_subset.T)\n",
        "sns.heatmap(corr_matrix, annot=False, cmap='coolwarm', center=0,\n",
        "            square=True, linewidths=0.5, cbar_kws={\"shrink\": 0.8},\n",
        "            xticklabels=[f'F{i}' for i in range(n_features_viz)],\n",
        "            yticklabels=[f'F{i}' for i in range(n_features_viz)],\n",
        "            ax=ax)\n",
        "\n",
        "ax.set_title(f'Latent Feature Correlation Matrix (First {n_features_viz} features)',\n",
        "             fontsize=15, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(output_dir, 'feature_correlation.png'), dpi=300, bbox_inches='tight')\n",
        "print(\"   Feature correlation matrix saved\")\n",
        "plt.show()\n",
        "\n",
        "# ========== SUMMARY REPORT ==========\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"7. Generating Summary Report\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "report_path = os.path.join(output_dir, 'visualization_report.txt')\n",
        "with open(report_path, 'w') as f:\n",
        "    f.write(\"=\"*80 + \"\\n\")\n",
        "    f.write(\"VAE VISUALIZATION SUMMARY REPORT\\n\")\n",
        "    f.write(\"=\"*80 + \"\\n\\n\")\n",
        "\n",
        "    f.write(f\"Model Type: {model_type}\\n\")\n",
        "    f.write(f\"Total Samples: {len(features_df)}\\n\")\n",
        "    f.write(f\"Latent Dimensions: {latent_dim}\\n\\n\")\n",
        "\n",
        "    f.write(\"=\"*80 + \"\\n\")\n",
        "    f.write(\"LANGUAGE DISTRIBUTION\\n\")\n",
        "    f.write(\"=\"*80 + \"\\n\")\n",
        "    f.write(str(features_df['language'].value_counts()) + \"\\n\\n\")\n",
        "\n",
        "    f.write(\"=\"*80 + \"\\n\")\n",
        "    f.write(\"GENRE DISTRIBUTION\\n\")\n",
        "    f.write(\"=\"*80 + \"\\n\")\n",
        "    f.write(str(features_df['genre'].value_counts()) + \"\\n\\n\")\n",
        "\n",
        "    f.write(\"=\"*80 + \"\\n\")\n",
        "    f.write(\"CLUSTER DISTRIBUTION\\n\")\n",
        "    f.write(\"=\"*80 + \"\\n\")\n",
        "    f.write(str(pd.Series(clusters).value_counts()) + \"\\n\\n\")\n",
        "\n",
        "    f.write(\"=\"*80 + \"\\n\")\n",
        "    f.write(\"PCA VARIANCE EXPLAINED\\n\")\n",
        "    f.write(\"=\"*80 + \"\\n\")\n",
        "    for i, var in enumerate(pca.explained_variance_ratio_[:5]):\n",
        "        f.write(f\"PC{i+1}: {var:.4f} ({var*100:.2f}%)\\n\")\n",
        "    f.write(f\"Cumulative (5 PCs): {pca.explained_variance_ratio_[:5].sum():.4f}\\n\\n\")\n",
        "\n",
        "    f.write(\"=\"*80 + \"\\n\")\n",
        "    f.write(\"VISUALIZATIONS CREATED\\n\")\n",
        "    f.write(\"=\"*80 + \"\\n\")\n",
        "    f.write(\"1. latent_space_comprehensive.png - Multi-view latent space (9 plots)\\n\")\n",
        "    f.write(\"2. cluster_distributions.png - Distribution analysis (6 plots)\\n\")\n",
        "    f.write(\"3. vae_reconstructions.png - Audio reconstruction examples\\n\")\n",
        "    f.write(\"4. latent_space_density.png - Density plots for PCA and t-SNE\\n\")\n",
        "    f.write(\"5. feature_correlation.png - Feature correlation matrix\\n\")\n",
        "    f.write(\"6. visualization_report.txt - This report\\n\")\n",
        "\n",
        "print(f\"   Summary report saved: {report_path}\")\n"
      ],
      "metadata": {
        "id": "clFRiekVfwI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Comprehensive Comparison: VAE vs PCA vs Autoencoder vs Spectral Features\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import (\n",
        "    silhouette_score,\n",
        "    davies_bouldin_score,\n",
        "    adjusted_rand_score,\n",
        "    normalized_mutual_info_score\n",
        ")\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import librosa\n",
        "import os\n",
        "import time\n",
        "\n",
        "output_dir = '/content/drive/MyDrive/clustering_results'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"COMPREHENSIVE COMPARISON: VAE vs PCA vs AUTOENCODER vs SPECTRAL FEATURES\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# ========== 1. LOAD VAE FEATURES ==========\n",
        "print(\"\\n1. Loading VAE features...\")\n",
        "\n",
        "try:\n",
        "    vae_df = pd.read_csv('/content/audio_hybrid_vae_features.csv')\n",
        "    vae_type = \"Hybrid VAE\"\n",
        "except:\n",
        "    try:\n",
        "        vae_df = pd.read_csv('/content/audio_conv_vae_features.csv')\n",
        "        vae_type = \"Conv VAE\"\n",
        "    except:\n",
        "        vae_df = pd.read_csv('/content/audio_vae_features.csv')\n",
        "        vae_type = \"Basic VAE\"\n",
        "\n",
        "print(f\"   Loaded {vae_type}\")\n",
        "\n",
        "vae_features = vae_df[[col for col in vae_df.columns if col.startswith('feature_')]].values\n",
        "y_true = vae_df['language'].map({'bangla': 0, 'english': 1}).values\n",
        "\n",
        "print(f\"  VAE features shape: {vae_features.shape}\")\n",
        "\n",
        "# ========== 2. EXTRACT SPECTRAL FEATURES ==========\n",
        "print(\"\\n2. Extracting spectral features from raw audio...\")\n",
        "\n",
        "dataset_folder = '/content/extracted_data/MyDataset'\n",
        "audio_folder = os.path.join(dataset_folder, 'audio')\n",
        "\n",
        "# Get audio files\n",
        "audio_files = []\n",
        "for f in os.listdir(os.path.join(audio_folder, 'bangla')):\n",
        "    if f.endswith('.mp3'):\n",
        "        audio_files.append(os.path.join(audio_folder, 'bangla', f))\n",
        "\n",
        "for f in os.listdir(os.path.join(audio_folder, 'english')):\n",
        "    if f.endswith('.mp3'):\n",
        "        audio_files.append(os.path.join(audio_folder, 'english', f))\n",
        "\n",
        "# Match VAE dataset size\n",
        "audio_files = audio_files[:len(vae_df)]\n",
        "\n",
        "# Extract spectral features\n",
        "spectral_features = []\n",
        "print(\"  Extracting MFCC + spectral features...\")\n",
        "\n",
        "for audio_path in audio_files:\n",
        "    try:\n",
        "        y, sr = librosa.load(audio_path, duration=3.0, sr=22050)\n",
        "\n",
        "        # MFCC\n",
        "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=20)\n",
        "        mfcc_mean = np.mean(mfcc, axis=1)\n",
        "        mfcc_std = np.std(mfcc, axis=1)\n",
        "\n",
        "        # Spectral features\n",
        "        spectral_centroid = np.mean(librosa.feature.spectral_centroid(y=y, sr=sr))\n",
        "        spectral_rolloff = np.mean(librosa.feature.spectral_rolloff(y=y, sr=sr))\n",
        "        spectral_bandwidth = np.mean(librosa.feature.spectral_bandwidth(y=y, sr=sr))\n",
        "        zero_crossing = np.mean(librosa.feature.zero_crossing_rate(y))\n",
        "\n",
        "        # Chroma\n",
        "        chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
        "        chroma_mean = np.mean(chroma, axis=1)\n",
        "\n",
        "        # Combine: 20 MFCC means + 20 stds + 4 spectral + 12 chroma = 56 features\n",
        "        features = np.concatenate([\n",
        "            mfcc_mean, mfcc_std,\n",
        "            [spectral_centroid, spectral_rolloff, spectral_bandwidth, zero_crossing],\n",
        "            chroma_mean\n",
        "        ])\n",
        "\n",
        "        spectral_features.append(features)\n",
        "    except:\n",
        "        spectral_features.append(np.zeros(56))\n",
        "\n",
        "spectral_features = np.array(spectral_features)\n",
        "print(f\"   Spectral features shape: {spectral_features.shape}\")\n",
        "\n",
        "# ========== 3. TRAIN AUTOENCODER ==========\n",
        "print(\"\\n3. Training Autoencoder...\")\n",
        "\n",
        "class Autoencoder(nn.Module):\n",
        "    \"\"\"Standard Autoencoder (no VAE probabilistic component)\"\"\"\n",
        "    def __init__(self, input_dim=56, latent_dim=32):\n",
        "        super(Autoencoder, self).__init__()\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 48),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(48, latent_dim)\n",
        "        )\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 48),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(48, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, input_dim),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.encoder(x)\n",
        "        recon = self.decoder(z)\n",
        "        return recon, z\n",
        "\n",
        "class AudioDataset(Dataset):\n",
        "    def __init__(self, features):\n",
        "        self.features = features\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.FloatTensor(self.features[idx])\n",
        "\n",
        "# Prepare data\n",
        "dataset = AudioDataset(spectral_features)\n",
        "loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "# Train autoencoder\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "ae_model = Autoencoder(input_dim=56, latent_dim=32).to(device)\n",
        "optimizer = optim.Adam(ae_model.parameters(), lr=0.001)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "print(\"  Training for 10 epochs...\")\n",
        "ae_losses = []\n",
        "\n",
        "for epoch in range(10):\n",
        "    ae_model.train()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        recon, _ = ae_model(data)\n",
        "        loss = criterion(recon, data)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    avg_loss = epoch_loss / len(loader)\n",
        "    ae_losses.append(avg_loss)\n",
        "\n",
        "    if (epoch + 1) % 2 == 0:\n",
        "        print(f\"    Epoch {epoch+1}/10, Loss: {avg_loss:.4f}\")\n",
        "\n",
        "# Extract autoencoder features\n",
        "ae_model.eval()\n",
        "ae_features = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in spectral_features:\n",
        "        x = torch.FloatTensor(data).unsqueeze(0).to(device)\n",
        "        _, z = ae_model(x)\n",
        "        ae_features.append(z.cpu().numpy().flatten())\n",
        "\n",
        "ae_features = np.array(ae_features)\n",
        "print(f\"   Autoencoder features shape: {ae_features.shape}\")\n",
        "\n",
        "# ========== 4. APPLY PCA ==========\n",
        "print(\"\\n4. Applying PCA dimensionality reduction...\")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "spectral_scaled = scaler.fit_transform(spectral_features)\n",
        "\n",
        "# PCA to 32 dimensions (match VAE/AE)\n",
        "pca = PCA(n_components=32)\n",
        "pca_features = pca.fit_transform(spectral_scaled)\n",
        "\n",
        "print(f\"   PCA features shape: {pca_features.shape}\")\n",
        "print(f\"  Variance explained (32 PCs): {pca.explained_variance_ratio_.sum():.4f}\")\n",
        "\n",
        "# ========== 5. CLUSTERING EVALUATION ==========\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"5. Evaluating clustering performance for all methods\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "methods = {\n",
        "    f'{vae_type}': vae_features,\n",
        "    'Autoencoder + K-Means': ae_features,\n",
        "    'PCA + K-Means': pca_features,\n",
        "    'Spectral Features (raw)': spectral_scaled\n",
        "}\n",
        "\n",
        "results = []\n",
        "predictions = {}\n",
        "timing = {}\n",
        "\n",
        "for method_name, features in methods.items():\n",
        "    print(f\"\\n{method_name}:\")\n",
        "\n",
        "    # Standardize (except spectral which is already scaled)\n",
        "    if 'Spectral' not in method_name and 'PCA' not in method_name:\n",
        "        scaler_method = StandardScaler()\n",
        "        features_scaled = scaler_method.fit_transform(features)\n",
        "    else:\n",
        "        features_scaled = features\n",
        "\n",
        "    # Time the clustering\n",
        "    start_time = time.time()\n",
        "\n",
        "    # K-Means clustering\n",
        "    kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
        "    y_pred = kmeans.fit_predict(features_scaled)\n",
        "\n",
        "    end_time = time.time()\n",
        "    timing[method_name] = end_time - start_time\n",
        "\n",
        "    # Calculate metrics\n",
        "    sil = silhouette_score(features_scaled, y_pred)\n",
        "    db = davies_bouldin_score(features_scaled, y_pred)\n",
        "    ari = adjusted_rand_score(y_true, y_pred)\n",
        "    nmi = normalized_mutual_info_score(y_true, y_pred)\n",
        "\n",
        "    # Purity\n",
        "    cm = np.zeros((2, 2))\n",
        "    for i in range(len(y_true)):\n",
        "        cm[y_true[i], y_pred[i]] += 1\n",
        "    purity = np.sum(np.amax(cm, axis=0)) / np.sum(cm)\n",
        "\n",
        "    results.append({\n",
        "        'Method': method_name,\n",
        "        'N_Features': features.shape[1],\n",
        "        'Silhouette': sil,\n",
        "        'Davies-Bouldin': db,\n",
        "        'ARI': ari,\n",
        "        'NMI': nmi,\n",
        "        'Purity': purity,\n",
        "        'Time (s)': timing[method_name]\n",
        "    })\n",
        "\n",
        "    predictions[method_name] = y_pred\n",
        "\n",
        "    print(f\"  Silhouette: {sil:.4f}\")\n",
        "    print(f\"  Davies-Bouldin: {db:.4f}\")\n",
        "    print(f\"  ARI: {ari:.4f}\")\n",
        "    print(f\"  Purity: {purity:.4f}\")\n",
        "    print(f\"  Time: {timing[method_name]:.3f}s\")\n",
        "\n",
        "# Create results dataframe\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"RESULTS SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "print(results_df.to_string(index=False))\n",
        "\n",
        "# ========== 6. VISUALIZATIONS ==========\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"6. Creating comparison visualizations\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# 1. Performance comparison across all metrics\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "\n",
        "metrics = ['Silhouette', 'Davies-Bouldin', 'ARI', 'NMI', 'Purity', 'Time (s)']\n",
        "colors = ['#3498db', '#e74c3c', '#2ecc71', '#f39c12']\n",
        "\n",
        "for idx, metric in enumerate(metrics):\n",
        "    ax = axes[idx // 3, idx % 3]\n",
        "\n",
        "    # Sort by metric (ascending for DB and Time, descending for others)\n",
        "    ascending = metric in ['Davies-Bouldin', 'Time (s)']\n",
        "    data = results_df.sort_values(metric, ascending=ascending)\n",
        "\n",
        "    bars = ax.barh(data['Method'], data[metric], color=colors,\n",
        "                   edgecolor='black', linewidth=1.5, alpha=0.8)\n",
        "\n",
        "    ax.set_xlabel(metric, fontsize=12, fontweight='bold')\n",
        "    ax.set_title(f'{metric} Comparison', fontsize=14, fontweight='bold')\n",
        "    ax.grid(axis='x', alpha=0.3)\n",
        "\n",
        "    # Add value labels\n",
        "    for bar, val in zip(bars, data[metric]):\n",
        "        width = bar.get_width()\n",
        "        ax.text(width + width*0.02, bar.get_y() + bar.get_height()/2.,\n",
        "                f'{val:.3f}',\n",
        "                ha='left', va='center', fontsize=10, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(output_dir, 'method_comparison_all.png'), dpi=300, bbox_inches='tight')\n",
        "print(\"   Performance comparison saved\")\n",
        "plt.show()\n",
        "\n",
        "# 2. Radar chart\n",
        "from math import pi\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 12), subplot_kw=dict(projection='polar'))\n",
        "\n",
        "categories = ['Silhouette', 'ARI', 'NMI', 'Purity', 'DB (inv)', 'Speed']\n",
        "N = len(categories)\n",
        "\n",
        "angles = [n / float(N) * 2 * pi for n in range(N)]\n",
        "angles += angles[:1]\n",
        "\n",
        "for idx, row in results_df.iterrows():\n",
        "    # Normalize values to 0-1\n",
        "    values = [\n",
        "        row['Silhouette'],\n",
        "        row['ARI'],\n",
        "        row['NMI'],\n",
        "        row['Purity'],\n",
        "        1 / (1 + row['Davies-Bouldin']),  # Invert DB\n",
        "        1 - (row['Time (s)'] / results_df['Time (s)'].max())  # Normalize time\n",
        "    ]\n",
        "    values += values[:1]\n",
        "\n",
        "    ax.plot(angles, values, 'o-', linewidth=2, label=row['Method'],\n",
        "            color=colors[idx], alpha=0.7)\n",
        "    ax.fill(angles, values, alpha=0.15, color=colors[idx])\n",
        "\n",
        "ax.set_xticks(angles[:-1])\n",
        "ax.set_xticklabels(categories, fontsize=13, fontweight='bold')\n",
        "ax.set_ylim(0, 1)\n",
        "ax.set_title('Multi-Metric Performance Radar Chart',\n",
        "             fontsize=16, fontweight='bold', pad=30)\n",
        "ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1), fontsize=11)\n",
        "ax.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(output_dir, 'radar_comparison_methods.png'), dpi=300, bbox_inches='tight')\n",
        "print(\"   Radar chart saved\")\n",
        "plt.show()\n",
        "\n",
        "# 3. Latent space comparison (t-SNE)\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 14))\n",
        "\n",
        "for idx, (method_name, features) in enumerate(methods.items()):\n",
        "    ax = axes[idx // 2, idx % 2]\n",
        "\n",
        "    # Standardize if needed\n",
        "    if 'Spectral' not in method_name and 'PCA' not in method_name:\n",
        "        scaler_method = StandardScaler()\n",
        "        features_scaled = scaler_method.fit_transform(features)\n",
        "    else:\n",
        "        features_scaled = features\n",
        "\n",
        "    # t-SNE\n",
        "    tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
        "    features_tsne = tsne.fit_transform(features_scaled)\n",
        "\n",
        "    # Plot by language\n",
        "    colors_lang = {'bangla': '#3498db', 'english': '#e74c3c'}\n",
        "    for lang_idx, lang in enumerate(['bangla', 'english']):\n",
        "        mask = y_true == lang_idx\n",
        "        ax.scatter(features_tsne[mask, 0], features_tsne[mask, 1],\n",
        "                  c=colors_lang[lang], label=lang.capitalize(),\n",
        "                  alpha=0.6, s=80, edgecolors='k')\n",
        "\n",
        "    # Get metrics for title\n",
        "    method_results = results_df[results_df['Method'] == method_name].iloc[0]\n",
        "\n",
        "    ax.set_xlabel('t-SNE 1', fontsize=12)\n",
        "    ax.set_ylabel('t-SNE 2', fontsize=12)\n",
        "    ax.set_title(f'{method_name}\\nSil: {method_results[\"Silhouette\"]:.3f} | ARI: {method_results[\"ARI\"]:.3f}',\n",
        "                fontsize=13, fontweight='bold')\n",
        "    ax.legend(fontsize=10)\n",
        "    ax.grid(alpha=0.3)\n",
        "\n",
        "plt.suptitle('t-SNE Latent Space Comparison', fontsize=16, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(output_dir, 'tsne_comparison_methods.png'), dpi=300, bbox_inches='tight')\n",
        "print(\"   t-SNE comparison saved\")\n",
        "plt.show()\n",
        "\n",
        "# 4. Confusion matrices\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
        "\n",
        "for idx, (method_name, y_pred) in enumerate(predictions.items()):\n",
        "    ax = axes[idx // 2, idx % 2]\n",
        "\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=['Cluster 0', 'Cluster 1'],\n",
        "                yticklabels=['Bangla', 'English'],\n",
        "                cbar_kws={'label': 'Count'},\n",
        "                linewidths=2, linecolor='black',\n",
        "                ax=ax, annot_kws={'size': 14, 'weight': 'bold'})\n",
        "\n",
        "    method_results = results_df[results_df['Method'] == method_name].iloc[0]\n",
        "    ax.set_title(f'{method_name}\\nPurity: {method_results[\"Purity\"]:.3f}',\n",
        "                fontsize=13, fontweight='bold')\n",
        "    ax.set_xlabel('Predicted Cluster', fontsize=11)\n",
        "    ax.set_ylabel('True Language', fontsize=11)\n",
        "\n",
        "plt.suptitle('Confusion Matrices Comparison', fontsize=16, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(output_dir, 'confusion_matrices_comparison.png'), dpi=300, bbox_inches='tight')\n",
        "print(\"   Confusion matrices saved\")\n",
        "plt.show()\n",
        "\n",
        "# 5. Training curves (AE vs VAE if available)\n",
        "fig, ax = plt.subplots(figsize=(12, 7))\n",
        "\n",
        "ax.plot(ae_losses, 'b-', linewidth=2, marker='o', label='Autoencoder')\n",
        "ax.set_xlabel('Epoch', fontsize=13)\n",
        "ax.set_ylabel('Reconstruction Loss', fontsize=13)\n",
        "ax.set_title('Autoencoder Training Loss', fontsize=15, fontweight='bold')\n",
        "ax.legend(fontsize=12)\n",
        "ax.grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(output_dir, 'autoencoder_training.png'), dpi=300, bbox_inches='tight')\n",
        "print(\"   Training curve saved\")\n",
        "plt.show()\n",
        "\n",
        "# ========== 7. DETAILED ANALYSIS ==========\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"7. Generating detailed analysis\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Best and worst performers\n",
        "best_sil = results_df.loc[results_df['Silhouette'].idxmax()]\n",
        "best_ari = results_df.loc[results_df['ARI'].idxmax()]\n",
        "fastest = results_df.loc[results_df['Time (s)'].idxmin()]\n",
        "\n",
        "print(\"\\nBest Performers:\")\n",
        "print(f\"  Best Silhouette: {best_sil['Method']} ({best_sil['Silhouette']:.4f})\")\n",
        "print(f\"  Best ARI: {best_ari['Method']} ({best_ari['ARI']:.4f})\")\n",
        "print(f\"  Fastest: {fastest['Method']} ({fastest['Time (s)']:.3f}s)\")\n",
        "\n",
        "# Calculate average rank\n",
        "results_df['Rank_Sil'] = results_df['Silhouette'].rank(ascending=False)\n",
        "results_df['Rank_ARI'] = results_df['ARI'].rank(ascending=False)\n",
        "results_df['Rank_NMI'] = results_df['NMI'].rank(ascending=False)\n",
        "results_df['Rank_Purity'] = results_df['Purity'].rank(ascending=False)\n",
        "results_df['Avg_Rank'] = results_df[['Rank_Sil', 'Rank_ARI', 'Rank_NMI', 'Rank_Purity']].mean(axis=1)\n",
        "\n",
        "best_overall = results_df.loc[results_df['Avg_Rank'].idxmin()]\n",
        "print(f\"\\nOverall Best (by avg rank): {best_overall['Method']}\")\n",
        "\n",
        "# ========== 8. SAVE RESULTS ==========\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"8. Saving results and report\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Save results CSV\n",
        "results_csv = os.path.join(output_dir, 'methods_comparison_results.csv')\n",
        "results_df.to_csv(results_csv, index=False)\n",
        "print(f\"   Results saved: {results_csv}\")\n",
        "\n",
        "# Save detailed report\n",
        "report_path = os.path.join(output_dir, 'methods_comparison_report.txt')\n",
        "with open(report_path, 'w') as f:\n",
        "    f.write(\"=\"*80 + \"\\n\")\n",
        "    f.write(\"COMPREHENSIVE METHODS COMPARISON REPORT\\n\")\n",
        "    f.write(\"=\"*80 + \"\\n\\n\")\n",
        "\n",
        "    f.write(\"METHODS COMPARED:\\n\")\n",
        "    f.write(\"-\" * 80 + \"\\n\")\n",
        "    f.write(f\"1. {vae_type} - Variational Autoencoder with learned latent space\\n\")\n",
        "    f.write(\"2. Autoencoder + K-Means - Standard autoencoder (no probabilistic)\\n\")\n",
        "    f.write(\"3. PCA + K-Means - Linear dimensionality reduction\\n\")\n",
        "    f.write(\"4. Spectral Features (raw) - Hand-crafted MFCC + spectral features\\n\\n\")\n",
        "\n",
        "    f.write(\"=\"*80 + \"\\n\")\n",
        "    f.write(\"RESULTS SUMMARY\\n\")\n",
        "    f.write(\"=\"*80 + \"\\n\\n\")\n",
        "    f.write(results_df[['Method', 'Silhouette', 'ARI', 'NMI', 'Purity', 'Time (s)']].to_string(index=False))\n",
        "    f.write(\"\\n\\n\")\n",
        "\n",
        "    f.write(\"=\"*80 + \"\\n\")\n",
        "    f.write(\"BEST PERFORMERS\\n\")\n",
        "    f.write(\"=\"*80 + \"\\n\\n\")\n",
        "    f.write(f\"Best Silhouette Score: {best_sil['Method']} ({best_sil['Silhouette']:.4f})\\n\")\n",
        "    f.write(f\"Best ARI: {best_ari['Method']} ({best_ari['ARI']:.4f})\\n\")\n",
        "    f.write(f\"Fastest Method: {fastest['Method']} ({fastest['Time (s)']:.3f}s)\\n\")\n",
        "    f.write(f\"Overall Best: {best_overall['Method']} (Avg Rank: {best_overall['Avg_Rank']:.2f})\\n\\n\")\n",
        "\n",
        "    f.write(\"=\"*80 + \"\\n\")\n",
        "    f.write(\"ANALYSIS\\n\")\n",
        "    f.write(\"=\"*80 + \"\\n\\n\")\n",
        "\n",
        "    f.write(\"VAE vs Autoencoder:\\n\")\n",
        "    vae_row = results_df[results_df['Method'].str.contains('VAE')].iloc[0]\n",
        "    ae_row = results_df[results_df['Method'] == 'Autoencoder + K-Means'].iloc[0]\n",
        "    f.write(f\"  VAE Silhouette: {vae_row['Silhouette']:.4f}\\n\")\n",
        "    f.write(f\"  AE Silhouette: {ae_row['Silhouette']:.4f}\\n\")\n",
        "    f.write(f\"  Difference: {(vae_row['Silhouette'] - ae_row['Silhouette']):.4f}\\n\")\n",
        "    f.write(\"  Analysis: VAE's probabilistic latent space \" +\n",
        "            (\"improves\" if vae_row['Silhouette'] > ae_row['Silhouette'] else \"does not improve\") +\n",
        "            \" clustering\\n\\n\")\n",
        "\n",
        "    f.write(\"VAE vs PCA:\\n\")\n",
        "    pca_row = results_df[results_df['Method'] == 'PCA + K-Means'].iloc[0]\n",
        "    f.write(f\"  VAE Silhouette: {vae_row['Silhouette']:.4f}\\n\")\n",
        "    f.write(f\"  PCA Silhouette: {pca_row['Silhouette']:.4f}\\n\")\n",
        "    f.write(f\"  Difference: {(vae_row['Silhouette'] - pca_row['Silhouette']):.4f}\\n\")\n",
        "    f.write(\"  Analysis: Non-linear VAE \" +\n",
        "            (\"outperforms\" if vae_row['Silhouette'] > pca_row['Silhouette'] else \"underperforms\") +\n",
        "            \" linear PCA\\n\\n\")\n",
        "\n",
        "    f.write(\"Learned vs Hand-crafted:\\n\")\n",
        "    spectral_row = results_df[results_df['Method'] == 'Spectral Features (raw)'].iloc[0]\n",
        "    f.write(f\"  VAE Silhouette: {vae_row['Silhouette']:.4f}\\n\")\n",
        "    f.write(f\"  Spectral Silhouette: {spectral_row['Silhouette']:.4f}\\n\")\n",
        "    f.write(f\"  Difference: {(vae_row['Silhouette'] - spectral_row['Silhouette']):.4f}\\n\")\n",
        "    f.write(\"  Analysis: Learned features \" +\n",
        "            (\"outperform\" if vae_row['Silhouette'] > spectral_row['Silhouette'] else \"underperform\") +\n",
        "            \" hand-crafted features\\n\\n\")\n",
        "\n",
        "    f.write(\"=\"*80 + \"\\n\")\n",
        "    f.write(\"KEY INSIGHTS\\n\")\n",
        "    f.write(\"=\"*80 + \"\\n\\n\")\n",
        "\n",
        "    if vae_row['Silhouette'] == results_df['Silhouette'].max():\n",
        "        f.write(\" VAE provides the best clustering performance\\n\")\n",
        "        f.write(\" Probabilistic latent space helps with separation\\n\")\n",
        "    elif pca_row['Silhouette'] == results_df['Silhouette'].max():\n",
        "        f.write(\" PCA performs surprisingly well\\n\")\n",
        "        f.write(\" Linear projection may be sufficient for this task\\n\")\n",
        "    elif spectral_row['Silhouette'] == results_df['Silhouette'].max():\n",
        "        f.write(\" Hand-crafted features perform best\\n\")\n",
        "        f.write(\" Domain knowledge encoded in features is valuable\\n\")\n",
        "\n",
        "    f.write(f\"\\n Computational cost: VAE/AE require training, PCA is instant\\n\")\n",
        "    f.write(f\" Speed ranking: {results_df.sort_values('Time (s)')['Method'].tolist()}\\n\")\n",
        "\n",
        "print(f\"   Detailed report saved: {report_path}\")\n",
        "\n",
        "print(f\"\\nBest method: {best_overall['Method']}\")\n",
        "print(f\"Best Silhouette: {results_df['Silhouette'].max():.4f}\")\n",
        "print(f\"\\nAll results saved to: {output_dir}\")"
      ],
      "metadata": {
        "id": "SC8H7_TLgHzQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}